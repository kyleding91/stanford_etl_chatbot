 Who you are defines how you build. This is the OddPrinaral Thought Leader Series brought to you by Stanford E Corner. Hello everyone, my name is Emily Ma and I'd love to welcome you to the Entrepreneurial Thought Leader Series today presented by the Stanford Technology Ventures program, which is the Entrepreneurship Center in Stanford School of Engineering and then basis the Business Association of Stanford Entrepreneurs and students. I am so excited to have Alex Wang at NETEL today. It's also his birthday secretly and said he chose to spend his birthday with you, which is the coolest thing ever. Alex is the founder and CEO of Scale AI. He founded Scale AI at the age of 19 while he was studying at MIT. His central insight was that machine learning powered data labeling could really help human beings make better use of AI over time. Under Alex's leadership scale has grown to a $7 billion valuation and serves hundreds of customers across so many industries from finance to e-commerce to US government agencies. Welcome Alex, let's start off with what scale AI does. I mean, you've built this incredible company in three years. Tell us more about the breadth of work that you do. First of all, thank you so much for having me, Emily. I'm really excited to chat today and I really enjoy chatting with you. So I'm excited. So yeah, Scale. So our mission is to accelerate the development of AI applications. We believe that AI and machine learning is, you know, if not the most important technology of today, one of the most important technologies that's going to enable huge amount of goodness for the world and just enable the world to operate significantly more efficiently and effectively enable new customer experiences. And our vision and accomplishing that is building the most data centric infrastructure platform for AI and machine learning. And the real insight that we have or the thing that powers everything that we do is this thought that, you know, data is the new code and that the thing that will dictate the performance of these machine learning systems and the AI systems of the future is actually the data sets and the data that they're trained on much more so than the code that is written to power them. And so, you know, if we were to boil it down to a two sentence, it's the better data results in better AI. And we've taken that sort of core idea and use that to build out an infrastructure platform to power a large number of a large swath of this sort of like AI ecosystem or the sort of like AI use cases out there. So we originally started with data labeling or data notation, which is the problem of converting sort of raw data feeds to useful label tag data that can actually use to train large scale machine learning systems. We actually started in autonomous vehicles. And then since then we've scaled across a variety of different industries, like you mentioned from e-commerce to financial services to the government to work with large tech platforms and sort of everything in between. And what we do with these customers is we help them not only with data notation data labeling, we help them with data management, we help them build out actually algorithm. And so with some customers, we provide algorithms directly to them for stuff like document automation or e-commerce AI or or in the government use cases. And so we've been able to expand pretty rapidly into a huge number of product areas and to a huge number of verticals. But again, essentially at the core, it's all empowered by this concept that better data results in better AI and the most viable thing that we can do to ensure that we have great AI systems of the future is to build incredible systems to build great data sets. So that's what we do. God, that's amazing. And the fact that you came across the seedling of that insight when you were 19, you were even 20. I'm actually curious if we just go back now knowing what scale AI has grown to. When you were 19, what gave you confidence in this concept that data is a new code that you know this that was the basis that was a soil for you know the growth of you know beautiful AI algorithms in the future. And what gave you the courage to jump in and do this. Yeah, so it's sort of a few things. So when I was actually I was at I was at MIT I was studying AI and machine learning. And this was this was the year when Google released TensorFlow and and deep mine released AlphaGo. So sort of this like big seminal moment for AI and machine learning. And it really felt you know was this you know I actually remember there's like those reporter who who was walking around MIT campus and was like interviewing MIT students to see what they thought about about AlphaGo. And so it was like it was a very clear moment like felt like hey AI is actually is going to happen is going to be big. And then I remember both in in some in some projects as well as like in some school projects with some side projects. I and one of these side projects I remember very viscerally was like want to build a camera inside my inside my in my son my fridge that would tell me when my roommates were when we're stealing my food. And I remember very viscerally it's like hey you know there's always great neural networks. They're really really cool. But at the end of the day the algorithm is only as good as the data that it's trained on. And so it was like hey this is a this is going to be a critical almost pillar of of whatever AI looks like in the future. And and and I looked around and I realized like hey there's a big problem that there aren't actually that many people trying to solve or that there aren't that many people focused on solving this problem. And and ultimately the thing that gave me conviction was was frankly the I'd seen sort of the success stories in sort of the US prior of platforms like AWS which enabled everybody to build these large scale internet systems or or sort of like websites and and large scale internet platforms. I seen this as a platform like stripe for to enable payments and enable sort of like you to build businesses on the internet. And so ultimately the realization is kind of hey you know what AWS has done for the cloud or what stripe has done for payments. You know there's an opportunity for a company to do that for AI and unlock this huge amount of potential for the technology by solving one of these critical pillars. And the pattern recognition was that hey data centric AI was going to be just as important as some of these other sort of like foundational pillars. And so that's that's really what what kind of got me excited at the time and and I honestly speak I didn't have all the answers. I didn't know necessarily that that this idea was was definitely going to be as important as I think we believe it is now or I didn't necessarily know that was going to be as exciting as we think it is now. But but the sort of fundamentals were there for it to be like hey this is certainly worth exploration. I have a very important question for you. Did your roommate stops stealing your food? Well that the punch line is actually I couldn't build it because just building that would have required so much data about you know different foods and like different configurations and what it looked like to pull food away from the from the fridge. It was just like literally the amount of data would have been astronomical that like it took me all of two hours to just give up on that idea and realize there's no way. And the building on this question though there's more seriously under that so I hope they didn't they stopped to your food regardless. You actually had some other entrepreneurial sort of experiences you had some other things that you were building with classmates and I'm curious of that sort of helped you feel out with the entrepreneurial journey was like. Yeah I think that there's like you know I often tell I tell everyone this which is that I think this sort of like this creation process of having an idea in your mind and then working with people to like realize that idea into into the world. It's an incredibly empowering process it doesn't always work obviously it's not always the case that like you know built something and it's amazing. But I think it's like it gives you so much confidence to like go from literally an idea that you're dreaming up and you. You're sort of like working on an ice you know you're literally dreaming up to go through this sort of like process of making that a reality and identifying what are all the components we need to build how do you architect it how do we build that and actually build it into into a reality because it gives you so much. It gives you so much power as an individual it's like wow I can I have this ability to like will things that from my from my mind into into my into reality and I think that and I think that's that's that's in you know that's like one of the most valuable things that that you can you can gift to anyone right and we actually we have a value like this at scale we call it ambition shapes reality and maybe one day all sort of publish. Like how we think about this internally but but the core ideas that like you know there's this incredible quality where if you. You know doing something that's ambitious for not ambitious you know they might take literally the same amount of work and so if you if you if you if you are able to like dream up big ideas and dream up big solutions to problems and then you work to build them you can have just like this incredible sort of like. Feedback loop with the world and building great things and continuing to sort of like expand your horizons. I want to do it so much I think there's two things that I took away from what you just said it's. You know I think a lot of times in as especially the students raised like hey you know I don't have this goes to build that yet but like sometimes it's really powerful just get going and to realize that you can manifest right you can code you can build now even if it's not perfect right you can manifest from an idea in your hand to something right and just that prototype is like very empowering it shows that we have. Agency to manifest manifest manifest and then the second thing that you mentioned actually made me sort of think about like my own journey and food it's like wow you know what if I aim for like 100% better I'm only going to get maybe you know 80% they're lucky maybe a hundred percent but my aim for like a thousand percent better I like it 500% right so if we aim further with our ambition we actually get further if we set our you know finish line too close is too easy we actually. Short change ourselves in the so I hope you write that book I really do hope you write that book because it's a powerful message it's it's so true there's we've there's all these examples I collect examples of this in in in real life and and one of the best ones is that like you know the four minute mile for the longest time human sought the four minute mile would have been impossible and then somebody broke it and then all of a sudden all these people broke the four minute mile and it was just this incredible moment of human achievement so. Same thing with high jumps right you know like wherever people are like going over like front first and some dude was like no I'm going to go backwards and then they have the step change and just the mount of height you could get by high jump big so love it love it you know I want to get to the crux of what your insight was and talk a little bit about data because oftentimes I think you know in the world everybody rushes to AI and then they forget actually the foundational element is the data as you noticed and you've done such an incredible job making that. More accessible to everyone so you know one of the couple of things are so top of mind for me in terms of challenges in the data space so the first one is a question of data sparseness so you know some industries you know that have been digitized over the last 10 20 years you know lots of data flowing through right you know financial industry lots of sort of digitization but like there's other industries you know like food and add you know like hell of I know how many farmers out there are willing to spend time. Putting sensors in their fields to gather data so you know what are your thoughts in sort of making sure that we bring along the industries that may not be as digitized you know how to be capture help those industries capture more data or maybe find ways to use less data in order to is a build algorithms or other ways that you thought of. Yeah totally yeah and I think this is actually one of the fundamental fundamental. Problems that we hope to solve and I know like even without scale is going to be solved over the course of the next let's call a decade because fundamentally you're exactly right like this the the way I think about this is that there's a sort of like these two waves. Of technology that are sort of like crashing through the world so to speak the first wave is sort of the internet and more and more computing and more and more sensors and that's great because if you have more sensors and you have more the internet is more distributed you have better coordination data gets saved more easily you have automated workflows like this soft software is amazing for a bunch of reasons and then. This interesting side effect is that as that's happening. You all these pools of digital data get collected in all these interesting industries and all these interesting areas and verticals and then those pools of digital data are actually what creates the opportunity for machine learning systems or AI systems to then have huge amounts of impact and sort of the second wave is is AI machine learning that's going to that's going to build off the shoulders of the giants of like all the technology and sensors that have been deployed in the past. But then but then you enter a problem, which is that like so if you think about the sort of quote unquote old use cases of AI like large scale ad systems or search or ranking for social media. You have those those use cases are very special because they have what are called natural labels you know just by us clicking on things on Google or just by us clicking on a video in our YouTube feed or clicking on something in our Facebook feed or providing labels about what are the things that that interest us were to the things that that that we're going to read or spend time on or look at and in the reality is in almost every other industry in every other part of the economy. You don't have that you don't have these like natural labels that are just automatically feeding into these machine learning systems. We have lots and lots of data and so most industries and most companies whether that be in the healthcare space or in financial services or ag agriculture like you had mentioned agriculture food or in sort of climate you know there's huge amounts of data these companies actually have lots of data but it isn't what we like to say is it isn't AI ready it's not it's not annotated. It's not cleaned it's not ready for the process of machine learning and so that sort of you know in many ways it's like step one of of what we've built at scale is like how do we enable every business to to go from huge pools of unstructured data to towards well labeled on the biased great high quality data sets that are allowed to build great machine learning systems of the future and I think that like you know realistically speaking. There's that's going to take some time and that's going to there's lots of industries but but that's like this this sort of like that's almost as like critical step of this critical bottleneck for AI to be deployed in significantly more areas and the example all pose here or that the example we talk about internally is. If you think about image net which was sort of the first really large scale can be like data set computer vision data set that that faith a lease lab at Stanford helps create you know that was the thing that then led to Alex net and and commercial neural networks and all these deep learning approaches us realizing that they actually would be really effective and they could absorb all this data and so there's this really interesting thing that we can do is really. We're talking about how data will lead to just having data alone is going to lead to really incredible machine learning and great techniques to being used and and that's sort of one thing that we get really excited about the other thing they'll mention is there are plenty of use cases as well where maybe it's difficult to collect data whether that be for privacy reasons or that's for lack of sensors or whatever reason and and these use cases do exist and sometimes. So that's where they're incredibly important and that's where sort of approaches around synthetic data or data augmentation become really important which is how do you take what what little data that you have and and really super charge that to be able to make it really really valuable for building machine learning systems and that's really something that we're we're very passionate about at scale as well as like how do we use synthetic data data augmentation to enable machine learning teams to combine the benefits of real world data with diverse and real. It we are extremely sure that people used to get access to these devices before doing this and so what they are doing is to overcome this. So kind of need be an example of this not琪瀑, it's that kind of was my target is to do a notebook that I've known. what data annotation means. And it's so fascinating to me. Last week we had a speaker come in and talk about data in agriculture and how before artificial intelligence there must be human intelligence. So H.I. before AI, and she's really built her company at Grow Intelligence by hiring incredible experts who can interpret the data and really connect the dots appropriately. So with your work, maybe I could also point out a personal example that I've fascinated by. Do a lot of work annotating through data and the chefs can tell the difference between this lentil stem and a parsley stem. And I'm like, I have no idea. They look exactly the same to me. How do you work with your taskers and how do you train them to annotate huge amounts of data in partnership with your customers? Because they're not necessarily experts in transportation or experts in melanomas on skin. Like how do you then sort of help them train up so that they can do the work to ground truth? Yeah. And so a few things here. One of the fundamental beliefs that we have at scale is that there's sort of like, there's sort of like a few resources that go into producing really high quality machine learning systems. If you think about like, what are the wrong gradients? One of those wrong gradients is compute. One of those wrong gradients is data. And then the last wrong gradient is sort of like human insight, so to speak, or like, and sort of the process of producing annotated data is combining raw data and human insight together and sort of mixing those ingredients together. And all AI systems of the future are going to be heavily reliant on human insight, even if we have incredible advancements in the technology, et cetera. Because at the end of the day, we're at minimum. We're going to need oversight in these AI systems to make sure that they're producing the results that we would expect and producing the results that we think are makes sense and whatnot. And so I think we think this like problem, this sort of like, one of the core problems of machine learning is like, how do you make sure that for every problem that you might not solve a machine, we using machine learning, you might want to have a machine learning system do, they're able to effectively get human insight to sort of like power that use case. And the way we think about it is like, is twofold. I think first is for folks who are trained up, you want those individuals to have as much leverage as possible. So you want, and this is somewhat circular, but it becomes very important, you want machine learning systems to do as much of the work as possible, and then really have humans spend all their effort on almost, almost, quote, with the edges or on the really like high judgment work that's required that enables the almost quality while making the most efficient in their roles. So that's the first piece. And the second piece is sort of this general education problem around how do you enable people to be experts and how do you like train them most efficiently? And one of the almost funny side effects of solving this problem at scale is that I think we have one of the probably the more interesting ed tech systems out there in which we have systems internally which track all the different kinds of, you know, edge cases might be one way to talk about, but all the different kinds of nuances to some of these data problems, right? Like how like this, this cilantro or sparsely example could be one of them and the different ways in which you can tell or detecting a melanoma versus other kinds of, other kinds of growths on skin. So, you know, there's all these different nuances and we track all those, all these different nuances within our internal systems and we are constantly trying to understand for each of the annotators what is, which, which nuances or which edge cases are they performing well at and they understand super well and which ones might be tripping them up and then proactively serving them materials and content and examples that help them elucidate these cases that they might not understand super well. And so it's this, it's all, I really think about as an ed tech system which enables, you know, the, the enables people to really like quickly grok and understand all the nuances of the data and humans are incredible pattern recognition, right? You know, if you think about what it takes to go through medical school and you talk to folks who have gone through medical school, it's an incredibly long process of just sort of like continued pattern recognition and that sort of that same process what we try to distill for the annotators in our, in our, in our system to enable them to do great work. That, that's incredible. So first and foremost, it's interesting that you've actually, it sounds like you build AI to then help your annotators get better faster, which is a recursive, right? You're actually using your own product on yourself to make yourself better over time. And a similar vein, I think for a lot of students, AI can help make AI better, right? So oftentimes, you know, we talk about, you sort of talk about it. We want the humans to pay attention to the thing that actually matters on an image or, you know, in a sentence and AI actually can be used to segment or pull out the part that requires attention. And so again, there's all these recursive loops in here that I find totally fascinating with your work. And let's maybe broaden that a little bit. You know, we had just kind of touched upon the melanoma example. And something that I find fascinating with sort of, a lot of sort of AI systems that are looking at skin, for example, are focused on what's available already, right? So algorithms currently, as I understand it, are much more accurate for fair skin individuals because there's just more data. So, you know, when you think about like helping your customers, that you call your partners, sort of build, sort of fair, balanced sort of AI systems, how do you have that conversation with them? I know it matters less with roads and maybe like license plates where it's pretty unambiguous when you look at numbers, right? But like, how do you have that conversation with a partner when they're solving a problem to aim for being responsible? Yeah, definitely. Well, I think first off to your point, I think responsible AI is incredibly, to have responsible AI, it's incredibly important to build high quality and representative data. You know, I actually think it's critical because at its core, the thing that I talked about earlier is that, you know, the data is almost like the food that you feed to these machine learning systems and ultimately you are where you eat. And so the sort of, the data is sort of one of the fundamental areas where these biases or these kinds of really critical, real world issues can sort of stem from. And really the way we think about it is like, how do we build technology? How do we build tools? How do we build things to enable either our customers or ourselves to ensure minimal bias and minimal harmful results with the data sets of how these machine learning systems and or how do we build systems that are going to flag that or identify when those biases may exist as proactively as possible so that then we know that we have to go fix that problem long before it ends up in the hands of a consumer or a or some sort of critical decision making progress. So for example, we recently worked with like a bunch of medical researchers on automated medical imaging analysis. This sort of exact problem. We worked with the MIT Media Lab and analyzed this exact problem, the invention of tons and tons of clinical images and found there were lot more light skin images and dark skin images. And what we did is we actually basically helped them replenish or sort of de-bias the data set and add more data to the unrepresented classes either with real world data or using data augmentation or synthetic data and we're able to significantly de-bias the output or the outcomes from the machine learning algorithm. And so I think it's not an easy problem in any way. This is actually a sort of like, this is one of the quote unquote hard problems of AI in the sense that there's no easy solution. It's not like, I don't expect that next year we're going to get some crazy machine learning architecture that all of a sudden solves the problem of data bias or machine learning bias. It really is all about the nitty gritty details about, what does your data set look like? How do you know ahead of time when there's bias in the data set and then how do you fix that or how do you proctorally resolve that and how do you keep going through that process? In some ways I was a trick question because in order to unbiased, you have to be aware of the bias and so that is not always easy. So I know on the back end, you can unbiased once you're aware of the bias. Do you work with your partners to gather more data in the case where your initial preliminary analysis is that there may be bias. Do you go back to them and say, hey, you might want to collect more in order for it to reshape this? Yeah, we do. And in fact, a lot of times, going back to this, like a lot of times our customers, they actually are sitting on incredibly large troves of data, but they don't have any of the tooling or infrastructure to help them sort of sift through the noise and identify the quote unquote needles in the haystack or identify the particular pieces of data that are going to dry for their model performance or dry for bias the most effectively. And so we built tooling our nucleus product which actually enables this exact process of like, hey, I know there's a problem with, let's say, not enough of a particular kind of skin growth in my data set. And then how can I then go through all my unlabeled data? Is that all my entire large troves of data to just get more samples of this kind of skin growth so that my algorithms are performing significantly better in the future? And that's really the sort of like, much more so than even getting the data. It's about sort of instilling this sort of philosophy around continual improvement of algorithms through continual improvement of data. And I think that if we can get there, then I think we're going to be able to cope with all these challenges with bias and data issues and all that stuff, model issues much more effectively. That's very cool, very cool. So maybe I can zoom forward. We were just starting from when you were in IT when you came up with SCALII. If we were to sort of look out to 2032, I know you've worked in many different industries, health care, transportation, real estate, and more. What are you excited about? Where do you think we're going to be in 2032? And with that, the secondary question is then given that we have a lot of budding entrepreneurs in our class and beyond who might be watching on YouTube live right now, whether it's going deeper into picks and shovels, as you've done with SCALII or other places within the ML gold rush that are really, really interesting. Looking out to 2032, where do you think we're going to end up and what are the opportunities? Yeah, no, I truly think we're kind of in the golden age of AI, so to speak, where the proliferation of use cases is going to be absolutely massive. Even at scale, we started in autonomous vehicles. And the first few years of the company, it actually felt like machine learning felt kind of, I don't know if the word is lonely, but it was like autonomous vehicles were the big use case. Everything else almost felt like a sort of side project or something much smaller. And then fast forward to now, we see all sorts of really exciting use cases in every single industry. So with financial services customers, like BRACs or PayPal or Square or whatnot, we see interesting use cases around trying to understand, build systems that move money more effectively or identify or understand transaction flows a lot better or identify fraud much better. Or we see use cases with FlexPort, which is sort of a global trade platform and enable just like an incredible amount of efficiency in the process of global trade, which is very important. It's really important that we're able to get goods delivered from everywhere in the world. And it's an incredibly manual process today. And by using machine learning, you can automate a huge number of those workflows and enable the overall economy to just get a lot more efficient. Or whether it's with a large scale autonomous or automotive company and a car company and building not only full sack all time vehicles, but also driver assistance systems, or systems that make drivers more safe, et cetera. So I think that like, we're in this phase, where this massive proliferation of machine learning systems. And I think that like the way, one way I would think about it is, you know, the sort of like software eats the world mindset is that you take like think about any industry in any sort of like any problem in the world today. And just imagine, okay, if you had software, how could you transform that? And I think that we've just seen, this has been this like very long term sort of slow transformation because it turns out humans are sort of like infinitely creative and you'll take any system and we'll be able to identify, oh, you can use software in this way or oh, you can use software in this way. And then you even sometimes even replace existing software with new software. Like, you know, there's like lot like old enterprise systems that are replaced by like new style, more consumery kind of internet platforms. And so, and so I think it's gonna be this continual process where we're gonna look at something, we're gonna look at a problem. Let's say like in insurance, the process by which claims get processed. We're gonna look at a problem and we're gonna think, okay, if you act like, if you use machine learning the right way and not just AI in some magical sense, but actually like, you know, the core fundamentals of machine learning, then you can design this process to be 10x more efficient and we're just gonna keep identifying all those problems and I think you go fast forward to 2032, it's gonna be everywhere, it's gonna, and the opportunity won't have stopped. Like, we're still gonna have like plenty of opportunity to apply AI to these systems. I think maybe more to name a few specific examples, I think these are maybe some of the ones that are quite cool or more exciting right now. I think that there's a few that I think are really important and for those of you with a course or like thinking about what ideas are exciting, I think these are maybe some areas to think about. I think first one is science. Science is, you know, there's actually these papers about how scientific progress has kind of been slowing actually a little bit over the past few decades. And one part of that is that like, you know, if you think about science, let's say, century ago or two centuries ago, you could do so many experiments and your ability to validate your ideas was really, really exciting. And now we're at a point where like, a lot of the cheap experiments, so to speak, have been explored and now we have like ridiculously expensive experiments. You know, like particle accelerators are extremely, extremely expensive or large scale clinical trials are very, very expensive, et cetera. And one of the really exciting use cases of AI is using AI to simulate, effectively, basically simulate experiments significantly more effectively than you couldn't have passed. And where they could using classical methods. And there's already a lot of examples of this in, whether that's something like an alpha fold, out of deep mind, or using AI applied to sort of like fusion experiments or fusion simulations. But I think it's gonna be a huge boon in physics, chemistry, biology, pharmaceuticals. And it's going to transform a lot of the sort of like, it's going to be this base technology that empowers a lot of a lot of future innovation. So I think that one's really critical. Metaverse is a use kit, is something that a lot of people are talking about these days. I think it means a lot of different things to different people. But I think if you think about AR or augmented reality, which is probably one of the forum factors that probably feels most intuitive to a lot of us, which is that, hey, we're just gonna have sort of this digital overlay over our natural lives. If you think about that problem, it is an incredibly complex machine learning problem, an incredibly complex AI problem, because fundamentally you need to understand the world and how these different objects relate to one another and how eyes a person can relate to those objects. And if people are walking past each other and they make a look, you need to be able to understand that kind of stuff. And so you need to have this very fine, great understanding of what is going on in the world around you. And that's a very, very challenging AI problem. But I think that it's one that is going to enable these sort of like very sci-fi like consumer experiences that I think of the future that I think we're all really fundamentally really excited about. And the last one that I'll kind of mention, just because I think this one is really important and it's somewhat controversial, but I think it's an important one to talk about is I think AI is applied to the government's problems and particular applied to sort of national security defense intelligence, et cetera. And I think that we're in a very interesting period in the world where the sort of like warfare is shifting from sort of a previous paradigm to a significantly more digital paradigm. And now a significant number of the sort of like skirmishes of the future are going to happen entirely digitally in cyberspace or via AI systems or via purely digital systems. And I think it's really, really important that if you believe in kind of democracy and you believe in the values that the United States represents, that the United States and other democratic countries are able to utilize best and class technologies to not be vulnerable as this sort of long-term platform shift is occurring. And so I think it is really important that we have some of the best and most brilliant technical minds thinking about how do we build the best and class systems for the future of the United States to enable the United States to be as effective from a defense and sort of intelligence perspective as it has been for the past, you know, call it 50 years, which has really enabled the sort of like modern era of peace. So I think those are some of the areas that excite me the most slash I think are most important. Incredible. So some of that science, Mediverse, ARVR, and then government, it's fascinating to me. I would have tackled that question. I'm almost like, what are the chores that human beings don't like doing, like washing dishes or like dealing with taxes, right? One day, all the things that are taking up our time and could be automated, I see 20, 30 as a point time where all those things are automated. And we are free to actually do what only uniquely humans can do, which is to spend our time being creators and being creative. I hope that that's the future that I look for and I think I would support the comments that you made here. Let's talk about robots for a second. At one point, you know, the early days of some of the everyday robots work at Google, I would have a robot come to my desk and try very hard to clean up my desk and it would fail. Generally, we try to pick up my bowl of cereal but accidentally pour milk all over my desk or like once in a while, it would like steal my bottle of wine and all stuff like that. Put it aside, I'm actually a little bit curious about, with AI and data and sort of tied up the conversation that we had around AR. In the future, there's going to be artificial humans, right? And I heard an interesting podcast recently with Ezra Klein in a viewing Ted Lam, who's a science fiction writer. And he said that before machines become sentient, we will probably end up causing them to suffer a whole lot and it just kind of begs the question, you know, AI, how do we give feelings to machines and are machines going to have feelings and is that a bridge too far? And I know we're sort of sparing away from sort of data that the whole entire purpose of the work that you're doing is to really create this foundation for data to then bring AI into the future to make human life better. Curious how you feel about robots and machines and that space? Yeah, no, I think it's a super interesting philosophical question which is that like, let's take a, right now in a Stanford AI class, most of the students will train some sort of simple neural network to recognize objects and imagery. Is that neural network a, is that, like does that neural network have feelings? Like when you will delete it from your hard drive because you're running out of space, is that, is that, is that, does that cause suffering to that neural network? And I think that, I think these are super, you know, it's like very tough questions to answer. Where are the boundaries? What are the, for each of these edge cases, what does that kind of look like? I actually think that, you know, I think the sci-fi fantasy states in the future where you have AI systems that actually fully resemble humans in terms of their ability to have judgment and, you know, and communicate with us. I think it's actually quite far. And, you know, my evidence point is like, we're still not at a point where an AI system can fully accurately process documents. And OCR, like still, like does not work fully effectively. And the judgment that goes, the judgment that will be required from the AI systems actually like resembles people is so far off that I think that, I think we're gonna be in the sort of, like, limbo state, so to speak, where, where we have AI systems that are very effective and very useful, and can do things that like, maybe we didn't think they could do like three years ago, but you're not gonna get to the point where you have things, AI systems that are, that are, that you would sort of like, you know, where there's like these really deep philosophical questions that are tough. One thing that I do think though is, is going to happen probably sooner rather than later. And this is maybe the sort of like near term problem is that we're going up more and more have AI systems that affect how humans think, right? And this is sort of like, it's already happened to some degree where social media systems or ad systems or even search, you know, these are machine learning systems, they pick content for you, and the way they pick content for you will change how you think. And this is only gonna keep going in that direction, like I think in the future, we're going like, not so distant future, we're going to have children are going to have sort of like AI friends, and they're going to have these chatbots that they can talk with and practice, you know, speech with and sort of like, and learn from and talk about their days and like, basically like true friends, and they're gonna affect how humans think, just like how, you know, phones have sort of like changed the human's attention span probably permanently. And so I think that those, there are sort of these like interesting social issues around what does it mean for AI to have such a, real tangible impact on how we might behave in time, that I think are, I mean, those are, like that's a really important sociological question, and what are the implications of that? How do we get ahead of it? And I think ultimately, at least from our neck of the woods and our view, I think a lot of that comes down to, again, how do we ensure accuracy, quality and efficacy of the data that are feeding these ML systems? So we never end up in like a really, a really bad scenario where the data distribution or the data used to feed in one of these algorithms was so off base that it caused all these unintended consequences of the sort of the people that were using them. And in some sense, I think that like, you know, if you think about sort of like political polarization that's happening, on some level that is a data distribution problem. It's like, hey, you know what's happening is that these ML content systems are favoring more and more polarized content. And the data distribution has shifted so significantly and that's causing all these like weird social dilemmas that are really tough to think about and tough to deal with. And so anyway, long story short, I think it does all come back to data, at least like, I think data is a necessary but not sufficient part of the problem. And I think that, you know, that AI is going to change how we think pretty soon and we're going to have to think about that. That was fantastic. Thank you for being so just genuine in responding to a pretty provocative question that I was asking you. So I know that the students are hankering to ask you questions. So let's dive into that with the final remainder of this time. First question here, what are some key challenges you have had to overcome while running your company? Yeah. That's a like. Yeah, no, it's a great question and it's almost, you know, answering is almost impossible because it's almost like what challenges have I not had to overcome in building a company? I think that one of the things about, you know, I think it's probably like doing anything challenging and sort of this concept of like, you know, whether it's building a new product or building a company or building a team, you know, it was just, you know, it's like, whatever, like you'll deal with so many challenging scenarios in time and there's sort of like this infinite chaos to the world that will cause you to sort of be confronted with the most strange circumstances that you like could not foresee and you're just going to have to figure them out. But I think that like, you know, if I had to distill it down, I think probably the parts about building scale that have really, maybe the most challenging but also most rewarding have been about building the team, getting great people to sort of like join the mission and really see the potential of what we'd be, what we're able to accomplish, whether that be, you know, whether it be people who I work with and the incredible team at scale, whether that be our amazing investors or whether that be our amazing customers. But I think this sort of like, this fundamental challenge of getting people to buy into what you believe the future to look like, I think is one of the hard problems of the world and I think I felt very lucky that, you know, so many people have chosen to take a chance on me. So. Well, you have an incredible vision and very, there's a lot of clarity around that vision. So I can understand why a lot of people have joined you in whatever way they can. I think that's also underestimated. I think a lot of our engineering students here are like, oh, you know, I'm gonna spend a lot of time on the tech but it turns out that spending time on people is just as important if not even more important. All right, next question. At what point during the development of your company, did you realize that number one, it could become a serious competitor in the AI space and number two that you were ready to pursue building at full time? Yeah, no, it's a really good question. I think that early on, you know, sort of, it always is helpful to be wildly optimistic, I should say, or at least dare, maybe the proper terminology is to dare to dream big, which is that even early on, I think this sort of like this thread of thought, which was, hey, you know, if we actually do solve this sort of like data problem for the machine learning community, that is big. And I don't know exactly what it's gonna look like to build from that point, but we're gonna be able to do a lot of interesting stuff if we get there. And so that thread of idea did emerge and it didn't become, it honestly wasn't relevant for us for the first many years of the company because we're just focused on data labeling, didn't intention, we're just focused on solving that. But then you sort of, you know, we solved that problem, we're really focused on what we got scale, and then we picked our heads up and we're like, wow, we're actually at this sort of like the promised land that we thought at the very beginning that like we can, we actually have a shot at like building a lot more, doing a lot more industries to sort of accelerate AI and machine learning development. And so, you know, I would say that it was a, maybe early on it was a pipe dream, and then it was sort of like, you know, many years later before it actually felt like, hey, this is like a real opportunity for us. And then the second part of the question, which was, at what point did I decide I was ready to pursue it building a full time? I actually like, I wish I could say, oh, I was just like so convicted, and so I just, and so I just like went for it. But actually it was, I really started working on it in earnest when school ended. I remember even like, I put, I put working on all of it on hold, to get through like my finals and my final projects and all that stuff. And then the summer started, and I was like, all right, I have nothing else to do. And then, and then I was, we were very fortunate that we got over the course of the summer months enough momentum where it was like, hey, there's kind of no option but to just, you know, keep going at this thing. And so I think it's, I think this sort of like this barrier, this mental barrier feels very large, oftentimes around like, hey, I have a life right now. At one point, am I going to be ready to like, sacrifice my life today and then, and then go do, and then go approach this other life? I think the, and I think a lot of times I'll seem very irrational. I might, maybe my advice is to like, not, not actually be, quote unquote, trapped in that false dichotomy, but actually just put yourself in situations where you have sort of freedom and flexibility to explore. And then, and then like, see how you gain momentum in that, in that scenario. I appreciate that because sometimes students feel like they have to have something lined up with the summer, but it was actually a gift for you not to have had something lined up and to have that space to kind of really dive deeper into something that you care about. But similarly, let's take the next question here. Knowing what you may know now after running your company for three years, you can go back to the first thing you started your company, would you do anything differently? Yeah, well, there's always a butterfly effect. We're like, maybe if I did something slightly differently than like that, you know, all these other things would have gone, gone totally differently. And so on the whole, I wouldn't trade, I wouldn't screw it up too much. That being said, I do actually think that like, you know, the biggest thing that I would say, like if I were to go back and I were to tell myself one thing, it would be that like, you know, it's the people matter so much. And like, you know, however much, you know, I was really focusing on people early on. And a lot of that was guided because of mentorship that I had gotten or advice that I had gotten and also just this sort of like, this like selfish desire, it was like, hey, I want to work with people who like really inspire me and really get excited. And that's, that seems like the best way to live, especially when I'm going to be working on this all day and night. And so that was like, you know, I ended up, you know, getting there a little bit, but I would just, it's like now, I know in my mind state that it's like, however much I thought that people matter to the start, they matter like 10, it's like obviously they matter 10x more now. And I wish you could sort of like, transport that thought back to my, back to my prior self. So that, that's kind of tough. I also think maybe the other piece is like, along the way, there's a lot of moments of like, great self-doubt. And that's just, it's almost like part of the journey because almost invariably you're just getting into a situation where it's like, wow, crap, I've almost like, no idea what to do. And I think probably the big thing I would tell myself is like, it is like totally okay to be in that spot. It is totally okay for that to happen to you. It is not okay to be paralyzed when that happens. And even if you literally take the worst possible action coming out of that scenario, it will be better to have taken that action than to have taken no action. And so it's really the other thing I would tell myself. Ultimately, there are no, I would say one way doors, right? I think by taking an action, we can always course correct along the way, but we don't take any action. We don't have any new information. And so it's super important to actually make a decision act even with imperfect information. All right, next question. With recent scrutiny regarding data privacy, how do you think AI companies who are of course rely on good data should go about data collection? Huh? Yeah, I know. I think this is a super important question because I think that the question is like, and this is spurred, there's been a bunch of examples in the past that have spurred this, but some of them, for example, like the realization that Siri or Alexa are learning from recordings that in the idea that they were going to study learning from those recordings. And so I think it's like a super important, almost like reorientation that the entire technology or ML community needs to take, which is like going from having this thought, is like, however I can get the data, I will use that data and then train machine learning systems on it to, I need to get this data in a very responsible way. I need to do it in a way that is like, where everybody who's providing the data understands that the data is being provided for these AI systems, where I'm collecting it in a de-biased way, where I'm collecting sufficient amounts of it, et cetera. And I think that the answer is that that's gonna make, that's going to make it harder to build the same kinds of AI systems potentially, but it's going, it's the way that technology needs to develop. Like it's not a tenable state for machine that's just developed sort of by taking advantage, maybe like a check box that nobody reads or stuff like that. And so I think it's a very important shift, it's a big shift, it's gonna happen. And we're helping a lot of our customers think through that and make them robust to ensuring that they actually get data for these ML systems that is so responsibly collected. It actually goes back to something you said many times, even publicly, like your customers you partner with them. You're not just providing them with a solution, you're really truly partnering with them. And being in dialogue with them, because these challenges, like privacy are very nuanced and tricky, and you can't, it can't be the same thing every time, right? And so you have to sort of lean in and have the conversation as a partner, as opposed to selling a thing that's finished. And so I'm really glad that my question was asked because it is something that's talked with me for 70 people. Let's tackle one more question, one more question, try to fit it in there. What have been your most significant failures, and what did you learn from them? Or like, let's start with just one big failure that you thought was a failure, and how did you learn from them? Yeah, I think, man, there's so many, but I think, I'll talk about one that is very much top of mind. We need this one, one of our first customers, and really our first very large customer, and I won't name them, but they're sort of like a, they're a prominent company, and they really, in the very early days of scale, they took a huge chance by working with us, because obviously our product was really janky, it only kind of worked. They took a huge bet on us that we would be able to solve this problem for them. And actually, for a while, we had a pretty successful relationship with this customer, and that's what allowed them to grow to be very large, and would allow us to scale up with them and for us to sort of like, to build this great relationship with them. And then one of the, I think it was like, I don't know if it was, I'd call it a failure, a mistake or whatnot, is that we ended up losing focus on that customer, and it was sort of like, okay, let's go find other big customers, let's go do all this other stuff. And in doing that, or in that process, we ended up, we ended up really like, in the ignorance, in ignoring that customer, they, at a certain point, we just, we weren't actually solving their problem, and we weren't actually sort of like, being the scrappy team that they could bet on, that they could actually like, bet on to build an incredible product for them, and they ended up leaving. And I remember there's like this incredibly, is very challenging in the moment. This is one of the examples of like, you know, when I talked about, hey, you're gonna have moments of great self-taught. And I remember asking myself like, hey, is this, do we even have a business? Like, does it even make sense for customers to work with us? Like, all, asking myself all these questions, and, and it was, it was a really tough moment, because it was also one of these things, whereas like, you know, there was almost nothing that we could have done to convince them to have continued working with us. So it was like, this was one of these things, like what's done is done. And, and the big takeaway, where the big thing that we learned from it is like, it's just so, so important to be customer-centric, and it's so important to, to always be focused in your customers and make sure that you're, you're always understanding what, what you need to do, and how you make them just ecstatic about your product, and how you sort of like, exceeded all their expectations. And that moment, really, like, however embedded this concept was in our culture beforehand, it just like, it just made it even more visceral and made it more obvious. And so, I think those incredible learning moments, I'm, the only thing is like, I'm very grateful that it came so early on in our journey. The entrepreneurial thought leader series is a Stanford E-Corner original production. The stories and lessons on Stanford E-Corner are designed to help you find the courage and clarity to see and seize opportunities. Stanford E-Corner is led by the Stanford Technology Ventures Program and Stanford's Department of Management Science and Engineering. To learn more, please visit us at ecorner.stanford.edu.