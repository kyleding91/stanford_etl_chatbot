 Stanford E. Corner presents the Entrepreneurial Thought Leader series. On today's episode we have Chris Gurtees, Stanford professor of mechanical engineering. He was recently the Chief Innovation Officer at the U.S. Department of Transportation and is a world expert on autonomous vehicles. Here's Chris. I want to start off by taking you back to 1995. That may be a pleasant trip down memory lane for some of you and others in the room may not have been born at that time. But if we go back to 1995, we were using Windows 95 on our browser and it was a cool new thing. Netflix, excuse me, Netscape had just gone public with their Mosaic browser. That's how we were getting around on the internet. OJ was on trial. Jerry Garcia had just passed away and some of us were actually working on automated vehicles. But while we were looking at, at the time, wasn't what you think about as an automated vehicle today. Instead, the concept was an automated highway. We would have magnets in the road that the cars would follow. And the cars would follow each other at extremely close spacing. So we could improve capacity and we could reduce some of the aerodynamic drag. So doing my PhD work at UC Berkeley, I actually worked with a set of Lincoln town cars. And my task was to make sure that these things could drive about two meters, about six feet apart from each other, while the cars accelerated or even had a heavy break and to make sure that that distance remained constant. Now, at the time, that was sort of crazy science fiction. And whenever anybody asked us, when do you think this is going to be realistic, we used the typical answer that people have used for automated vehicles since about 1940 and we said 20 years in the future. Well, now we're a little bit more than 20 years in the future. These things are still not exactly ready for prime time, but they're darn close. You can see them actually being tested on the roads around here. And we've gotten an awful lot closer. So things have changed dramatically. In that intervening time as well, I've had the opportunity to work with a whole number of interesting vehicles and a large number of great students to try to move this technology forward and in particular, to try to focus on what we can do to improve vehicle safety. And so what I want to talk about today is to share some of the stories of our work that have come through as we've developed these automated vehicles. But try to turn them away from just technical lessons and into a little bit more generalizable life lessons that could be valuable to people who are thinking about starting adventure, whether that's a company or anything else that you want to get up and running from basically the ground floor. So I'm going to begin with this part out on the racetrack, which is where we've been spending a lot of time. Now this may not make immediate sense to everybody. I've just said we're interested in vehicle safety and we're going out to a racetrack, which may not be the first thing that comes to mind whenever you hear vehicle safety. But in fact, human race car drivers are absolutely amazing at using all of the friction that's available between the tire and the road. They're trying to use it to be fast. They want to be the first across the finish line and get their ahead of other drivers. But we thought if we could learn how they do that, we could use that same capability to be safe. To use all the friction between the tire and the road to get the vehicle out of harm's way as expeditiously as possible and handle situations where I may have very low limits of what the vehicle can do because I've hit a patch of black ice, for instance, where it started raining. So we went out onto the racetrack and fortunately we had a sponsor with a great collection of vintage automobiles, Miles Collier. Now there's a lot of people that have collections of great automobiles. Not many people will actually allow grad students to put funky antennas on the top and measure what these cars are doing out on the racetrack. But Miles was okay with that. So we would go out to the racetrack where we could test cars like a 1960 Porsche Abarth Carrera. We could add sensors to this that you might find more frequently in a modern Formula One car, or modern race car than you would expect in a vintage vehicle. We could then set up actually a differential GPS station so that we could measure the position of the car out on the track to within about one to two centimeters and do that several hundred times a second. After that we installed some cameras in the car so that we could see what the drivers were doing and then we were ready to race. The cars would go out on the track with our sort of makeshift group of sensors on board and we would wait patiently in the pits hoping that all the data would offload properly that nothing had come loose while the car was out on the track. When it did that was a great feeling of satisfaction. We got all of the data and then could sit down and debrief with some of the world's best drivers about what was actually going on out on the racetrack. What were you thinking at that time? What was going through your head when this happened with the car? And I'll summarize very briefly what we learned from this. We learned a huge amount. But what we found was that a lot of the basic descriptions that you get of driving a race car from books on driving are actually quite accurate. That the task of driving a race car around the track boils down to a couple of different parts. The first of which is the path you take, which racers refer to as the racing line. And the racing line in general, what you want to do is to try to make sure that the car doesn't have to slow down. And so usually what this means is trying to get the biggest radius into a turn that you can. And so race car drivers will naturally approach a turn from the outside, then go to the inside, and then back out to the outside as well so the car doesn't have to slow down. That sort of half the trick is finding the path that you want to take around the track. Now the other trick to this is driving at the limits of what the car is capable of doing. There's only so much friction between the tire and the road. Now I can use that friction in a number of different ways. I can use it for braking. I can use it for accelerating. I can use it for cornering. But I can't possibly get the maximum braking in the maximum cornering at the same time. So what I need to do as a race car driver is to learn to trade off among these things as I travel along my racing line. So I'm going to be hard on the brakes as I come into the corner. I'm going to roll off of the brakes as I steer into the corner. I'm going to corner and then I'm going to steer out of the turn as I get on the gas. That's the basic process that race car drivers are doing. So we thought, OK, humans can do this. We're going to take computers and we're going to solve this problem because we have math. We have as much math as we want at our disposal. So what we're going to do is we're going to go and we're going to find the very best path around the race track. We're going to find the single best path that we could possibly take around this race track. And then we're going to drive it pretty close to what the car is capable of doing. And our expectation was that if we could do this, we're going to be pretty darn fast. So working together with Audi in the electronics research lab, we built up Shelley. Shelley is an Audi TTS, which is mostly stock. We made a few modifications to it. We have control of Shelley's steering acceleration due to the throttle, also brakes and gear shifting. Shelley has some precise GPS equipment in her front laser scanner so she can find her way around the track, figure out the racing line, and then change our braking, steering, and acceleration commands to try to act like a real race car driver. And so it's very fun to take Shelley out on the track because she basically figures out the same things that humans do. You go to the outside and then you drop down to the inside of the turn, then accelerate out to the outside. And when you watch Shelley take a sequence of turns out on the track, you're kind of watching from a distance marveling and saying, what? Driver looks like they know what they're doing. And then the car comes around and you look and you go, wait, there's no one inside. The car is driving itself. But if you do take a ride actually inside the car, you realize it's kind of chill. Unless there's something dramatic that happens, the steering commands and brake commands and throttle commands that Shelley is calculating are pretty smooth. So we were pretty happy that we could measure what human drivers did and we could sort of put that at least in a rough form into a car. We then decided to ask, how good are we really? So we thought we would challenge somebody. Now Shelley very quickly got faster than any of us on the research team. We're not professional race car drivers, but all of us have in fact been through a novice race car training course. And this is something that we've proven we're better programmers than we are drivers because we program the car to be faster than we are. But we decided to challenge David Vodden. David Vodden is the CEO of the race track that we normally test at Thunder Hill Raceway Park in Willows. And he's also a spec me on a champion. So this is a champion amateur race car driver who knows the track like the back of his hand. And we thought that would actually be a good comparison. So what we did was we let David take Shelley around the track and then we drove Shelley around the track and then we decided to do a comparison of the way that they actually drive the track, which is a pretty fun thing to look at. So what we noticed is that Shelley takes a different path around the wide turn two that starts Thunder Hill. Shelley jumps to the inside where as David stays to the outside and tries to build up speed and this puts him ahead by maybe about a half a second or so as he comes out of turn two and starts into this sequence of three, four and five. He gets a good jump down the hill and turn five and Shelley is still behind by about a half a second. But now Shelley starts to be very aggressive at some corners. There's some straights that she can accelerate without the weight of a human. And as they start to get to the back part of the track, what's interesting is that David has to wander a little bit because he can't find the mathematically straight as path, whereas Shelley can. So Shelley actually pulls about even as they go into turn 10 and then as they go into turn 11, David decides to cheat. And in fact goes over the line that we have told Shelley to stay within. This buys the human and with their ingenuity about a half a second over the car, but Shelley outbreaks David into the very tricky turns 14 and 15 that in the track and pulls even again. Then Shelley's weight advantage begins to take over on the straightaway and she finishes that particular lap about four tenths of a second faster than David. Now this is a two minute and 17 second lap and we're within four tenths of a second of a champion amateur race car driver. So we're pretty happy with that. In fact, maybe we were a little bit optimistic about how good we were at that point because we decided to throw down the gauntlet to somebody who was a little bit better. J.R. Hilderbrand. J.R. is an any car driver and is actually in addition to being an any car driver is has a fantastic technical mind. He really understands not only how to drive the cars, but how the cars are set up the interaction between the technology and what the driver is doing. He's very understanding of what it is that he's doing in the car does a lot of coaching of driving. And so we thought, OK, why don't we try this against J.R. Well, J.R. was faster. And what was interesting is that J.R. was faster, not just on one part of the track. We didn't have an advantage over him on one part of the track and lose it somewhere else. He was faster everywhere. He was a little bit faster on every single turn. Clearly, we were missing something. There was something that the professional driver had that we didn't have. And this was fascinating to us because this is what we were really setting out to learn. How do we use as much of the capability of the car as possible? Because that difference, which may be measured in 10th of the seconds on the racetrack, can actually be inches as I'm trying to make an emergency maneuver and could be the difference between a collision happening and one not happening at all. So we plotted all of the data and we looked at what J.R. was doing. We looked at what David was doing and we looked at what Shelley was doing. And in fact, there was a stark difference that really stood out to us. Shelley, as we had designed her, was following the exact same path every time because that's what we figured we needed to do. We found mathematically the best path and dog on it, we were going to stick on it. Neither David nor J.R. did that. In fact, they took a slightly different path every time around the racetrack. When we originally looked at this, we thought that was just because they were trying to get to our ideal path and missing. But we couldn't have been farther from the truth. What in fact they were doing was pushing the car to its limits and taking the path that opened up for them at that moment in time. They were prioritizing always being at the limits of the car rather than following one specific path. As J.R. looked at the data and looked at what Shelley was doing, he told us, if Shelley was a human driver, I was coaching. I would tell her she has her priorities exactly backwards. That instead of focusing on this path and exactly where I want to go, what Shelley should be focusing on is how to use the friction between the tire and the road. If she comes into one turn a little bit quickly, she needs to swing a little bit wider, keep the speed up and adjust. If she comes in a little bit slowly, she could make that turn a little bit sharper and needs to turn earlier. But by following this one path, we were kind of missing that opportunity. So as we came in thinking that we were trying to solve one mathematical problem, that we were trying to find this very best path around the track and then drive it reasonably well, we found that the best human drivers did exactly the opposite. They found the physical limits of the car, they pushed the car to its limits and they took whatever path was open to them as they did that. That made them significantly faster. This is a really interesting result. It was an interesting result from a research standpoint. It's motivated a lot of our current research to try to figure out great, how do we capture that capability in the car. But it's also something that after reflection, I realized this was sort of a more general way of living life, which is really to think about pushing to the limits of what's possible and seeing what paths open up when you do. So a lot of times with startup companies, this is sort of referred to as the pivot, right? As you get into the market, as you actually start to flesh out your idea, you often discover that this great plan that you had isn't working quite as well as you think. Or maybe the plan is working fine, but there are other opportunities that are now open to you if you're flexible enough to take them. This is as somebody who programs automated vehicles. This is the sort of thing that we look at humans and just marvel at their capability to be flexible, to adapt, to sort of take advantage of these opportunities that arise for them as opposed to following the predetermined path. And so the lesson that I've really taken from this is to find the things that we like to do in the lab, find the things that we do well, do them as well as we can, but not be worried about exactly what sequence of events we're going to be taking in the future. But to be very flexible about what research paths we take based upon what we've learned in our current path, to adjust, to adapt, to use that human flexibility to our advantage. So this is something that I've found a lot in life. I like to have a plan a lot of times. I'm going to do this, and then I'm going to do that, and then I'm going to do this. But in reality, if you want to be fast on the racetrack, the plan gets you into the corner, your skills get you out quickly. If you hold onto that plan, you're slow. On the racetrack, or potentially in business. What I've also found under reflection is in fact a lot of the coolest things I've done in my life were things that I never planned to do. One of those was going to Washington DC. So I spent 2016 as Chief Innovation Officer at the U.S. Department of Transportation. I got to work very closely with Secretary Foxx on a variety of issues that are very important to me. So I got to help write the country's first automated vehicle policy, which is somebody who's worked on automated vehicles since the mid 1990s, to actually be able to go to Washington DC and help with the initial policy was just absolutely amazing. I got to understand how government agencies work. I got to understand the interplay of how the executive branch works with Congress, and even how the White House and agencies have to negotiate to get anything done. I got to understand how the career civil servants work with political appointees. I got to do innovative classes on innovation and idea generation across the federal government. I got to work with a lot of really amazing people in Washington DC. If there's one takeaway message that I learned from this time, it's how phenomenal the career civil servants who are working in DC really are. We all have working for us as taxpayers, a really amazing group of people who are intelligent, hard working, and very motivated to turn out good policy working in all of our agencies. So it was a great opportunity to work with them for a year. I was not expecting this at all. There was nowhere on my life plan where I said, okay, and now this is when I go to Washington DC and help with automated vehicle policy. I was not expecting a call to say, hey, how would you like to come work at the Department of Transportation? But the work that I had done set me up for that opportunity, and I was able to take advantage of that path that opened up for me. I'm also glad that I did because it is actually shaped the way that I think about automated vehicles in a very deep way. So these are the sorts of things that I think are important that we can learn from the race car driver, this ability to seize the opportunity that opens up. In addition to my time in DC, this is sort of how I ended up becoming an entrepreneur. I wasn't actually focused on, I need to start a company now. It was always interested in it. So actually as an undergraduate, I was in a dual degree program with mechanical engineering and entrepreneurial management. So the idea of starting a company had always appealed to me, but I never really had an idea around which I wanted to build a company. But then one day actually one of my PhD graduates came to me and said, hey, Chris, you know that stuff that you worked on in your PhD where you had cars and they were platooning at close distances to each other? I've been doing a lot of thinking about this, and what if that was applied to trucks? So this was Josh Schwitkiss who said the idea for a company called Peloton Technology that could actually platoon trucks in order to produce fuel savings. It turns out that if you actually allow trucks to draft off of each other, if you can electronically control them safely to decrease the distance, you can save massive amounts of fuel, somewhere between 7 and 10% in each truck. So I was struck by this and I thought at the time, where can I apply my skill set to actually make a difference as far as energy consumption is concerned? And I thought, this is it. This is a real opportunity that we have here. So Josh said to me, hey, do you want to be an advisor to the company? And I said, well, maybe, but do you need a co-founder? And so he said, absolutely. So we decided to form this company and the first thing we produced was a white paper describing this concept. We sent it around to a few people and we got a call from Peter Bill and Peter Bill said, hey, we're pitching some new ideas to Walmart and the people at Walmart who buy all of their trucks. You want to come to Denton, Texas and pitch your white paper. Yes. So off we went to Denton, Texas and we had a meeting with Peter Bill and Walmart to talk about this idea. And the quote that we walked away from this is that the person responsible for buying all of Walmart's trucks said, look, if you can do what you're talking about at the price point that you're talking about, your product is a no-brainer. We spend far more for far lower fuel savings. And so we walked out of this meeting, like, high five. This is awesome. All we need to do now is to go raise some funding and we are off to the races here. We know that our idea has technological merit. I mean, we've actually proved this back in my PhD thesis that you can do this. We know that the companies are excited about it. All we need to do is raise 10 or 20 million adventure capital and we're often going. So we decided to sort of schedule our first meetings with VCs to do this. Now, again, remember, this is 2011. So automation wasn't quite the hot thing. It is now. We came in and pitched our ideas to the first group. They're like, you know, we love the team. You've got a great idea. You're awesome and everything, but this isn't quite the right fit for us. Okay, that's fine. Went on pitch our idea again. We really love the team. You've got some great ideas. We're a little concerned about the government angle. It's not really the space that we're in. Okay, fine. Next pitch. Kind of the same thing. You know, you kind of get to that point where you're having the founding team meeting at Starbucks as you try to plot strategy. And you're having this sort of soul searching moment of, if we're so awesome, how can we don't have any money? And so we sort of realized that actually venture capitalists, despite, you know, the reputation that I had are actually incredibly polite. And so you feel great about your idea and your team and everything as you walk out of the meetings, but at the end of the day, we had no money. So we thought, maybe we need to downscale our ambitions a little bit. Maybe we need to think about a seed round that will just allow us to build up some trucks and get this idea proven. And so as we started to do that, we started to talk to some angel investors and they actually gave us some some great advice. So we had been sort of pitching this idea to VCs trying to get them excited about fuel savings, trying to get them excited about what we saw as industries from the truck industry. But we weren't quite getting our argument across and Monteneewen, one of the angel investors who we connected with said, look, you need to come out at this from a totally different business. You really need to talk to the people in the room and get them excited about what it is that you're trying to do here from their perspective. And our pitch went from talking about trucks and flow fields and the physics and the fuel savings to one that was much simpler, it revolved around the number 2%. What is 2%? 2% is actually the profit margin at many large trucking fleets. Trucking is a ridiculously brutally competitive business. And so 2% to 3% is the profit margin that many of these large fleets are running. Fuel is 30% of their expenses. If you save 7% of fuel, you have effectively doubled the profit margin. With that entry, suddenly people understood what this was about. As opposed to saying trucking fleets are interested in this, it became clear that this is sort of a life or death difference if you can provide this sort of technology. And so with this change in our message, we were in fact able to get a seed round of funding which led then to Series A and Series B. And now Peloton has a large fleet of trucks out developing this and is very close to commercial launch of a platooning system putting in the hands of commercial fleets to really save large amounts of fuel on the open road. So what's the lesson here? Well, I think it could be engineers need to learn to talk business, but I don't think that's actually the message here. And as I reflected on this, it's also not just about pitching to your audience because giving a talk to an audience is one thing. So as I prepared for this, what did I think about? Well, what might be interesting to this group of people? I can just sort of explain some things that I think are interesting to all of you. Hopefully I managed to get that about right. But you're not actually key to my venture. I get to go to continue to do this stuff in my lab regardless of your interaction with me. When I'm actually trying to raise funding, when I'm actually trying to bring on say other founders or other members of my team, what I really need to make sure of is that we're sharing a vision for where this is going. And the lesson that I learned from this is that if you're going to be successful in a venture, you need people to share your vision even if they don't share your motivation. So each one of the founders of our team really had a different reason for doing this. I was doing this not because I really wanted to build a company, but because I thought this would be a good outlet for my skill set to make an impact on energy. That's not necessarily anybody else's motivation involved with this. So the trick here is to basically make sure that you have harmony around the visions. Everybody's moving in the same direction, but understanding that everybody may be coming at that from a very different motivation. And I'm surprised it took me a while to figure this out because this is basically life as a faculty member. I'm raising money for research. One of my raising money for research for is I want to educate students. I want to take my students to a racetrack and I want them to have an amazing engineering education. My corporate sponsors think that's cool, but that's not what's appealing to them. What's appealing to them is that this is going to generate new ideas that are going to get into their company that are going to help them develop better products. Now, although we have different motivations, we can harmonize around the vision of where this needs to go. And so this is something that I think is very important in terms of thinking about it. And it's hard sometimes when we're so passionate about what we want to do and the reasons why we want to do it. That it's often easy to overlook the fact that somebody could be a great ally for us, but their motivation could be entirely different from ours. And we need to learn to find that motivation and speak to them. And I'll say in particular, one of the things that has blown me away in this process is how many people, season and entrepreneurs and other people in Silicon Valley, are really interested in acting as mentors. How many people are out there whose motivation is really to help and to mentor? Now, if you find one of those people, that's amazing. But you also need to understand where their advice is coming from. And the best thing that you can do is to let them be a mentor. Understand that you're passionate about your venture. They may be passionate about mentoring you. You can have a shared vision with that, but it's really important to understand where they're coming from and not to rebuff that and say, you know, I don't really like that idea. Maybe that's fine. Maybe they don't care about the idea either. What they want is the interaction and the mentoring. These things are very important because mentors who have done what you want to do can be absolutely invaluable in avoiding mistakes. So Peloton is now testing out on the road. What's interesting as we've done this is that the basic algorithms are not much changed from my 1995 PhD thesis. The sort of core idea behind this is still pretty much the same. But when you go from something that runs in a closed environment to something that runs in the open road, you need to prepare for every single contingency. So you need to know that all the little things that can go wrong. And so actually moving from the laboratory to a product involves solving a lot of problems that you never thought that you were going to have. I kind of bring up the last thing that I've learned about problems that that seem hard or problems that seem easy as you attempt to tackle them. So for example, just suppose somebody should want to create an automated vehicle that drifts. A car that can actually track a path that can get around while going sideways the way formula drift racers or your average fast and furious movie does. A car that can actually handle in these extreme situations. Why would you want to do that? Well, first of all, it's awesome. Actually, there's a practical aspect as well, which is that the physics are very similar to what you would encounter if you're on ice. So if you can actually control cars that are doing this, you could actually maneuver cars on ice when human drivers might be spinning out to actually have them sort of thread the needle between dangerous situations and do quite well. So let's just suppose one wanted to create a car like this. And furthermore, wanted to do it in a delorean. Because if you're going to actually create an autonomous drifting car, why not do it with style? So this is what we set out to do. Actually, we decided to build Marty an autonomous electric drifting delorean. With the idea of trying to be able to control the car under these very extreme situations to really show the limits of what we could do. To show that in any situation where a human driver would become lost, would start to veer from the path or have the car become unstable, that we could actually very tightly control the car. So we built this. And in fact, we did develop a car that can handle under some very extreme circumstances. So without any human input, Marty can actually put himself into a drift sort of doing donuts around a cone out in our test track. But can also swing wider and start to navigate through an obstacle course. So while the tires are producing copious amounts of white smoke, the car can actually slide sort of sideways between cones, come into orbits around cones, slide through all the time again without the human having to do anything at all. And so the car is basically sideways this entire time and gliding as if it were on ice with the exception of the large chunks of black tire getting hurled everywhere as we do this. This is a level of precision that even the best human drift drivers don't achieve. So we are able to track within usually about 10 to 20 centimeters of our desired path while the vehicle is sideways this entire time. But what seems like just a physically impossible challenge once we work the physics starts to become easy. Now not say this wasn't challenging, not say this wasn't excellent work by John Goen, some of my other graduate students. But it was a problem that we have solved. We were able to physically understand how to do this and then it becomes a problem of math. Now if I were to pose that problem to you, it would at first sound pretty hard. Whereas there's other problems that I could solve to you or pose to you that might sound pretty easy. Let's say I have an automated vehicle and I come upon a vehicle which is double parked where it has no business being parked. Anybody ever encountered this on the road? Nobody? Seriously? Come on. Alright, there we go. That's the audience presentation moment there. Okay, so as you're going down the road and you do this, what is a human driver going to do? Well, assess that the situation is safe and decide to overtake and keep going down the road. Now the problem is, is if my vehicle is double parked and I have a double yellow line, California vehicle code says I'm not supposed to cross that double yellow line. The California vehicle code doesn't actually say you can cross the double yellow line if there's a car that has no business being parked in front. We're making a human judgment of this is the reasonable thing to do. We would expect that the law would back us up that this is a reasonable thing to do. We would expect the highway patrol would look at us and say this is a reasonable thing to do. But now I'm programming an automated vehicle. What is my general rule here? I've just ignored one law because I want to get down the road faster. Hmm, that doesn't sound very general. There's something about this circumstance that we assume is thinker, okay. But now as I start to think about coding this into an automated vehicle, what if that car actually has somebody in and they've just come to a temporary stop? What if this car has actually seen something in front of it and there's a reason it's stopped? There are a lot of situations that start to arise from this very very simple scenario of a double parked vehicle. Thinking about how I overtake that is actually a deceptively difficult problem. What's looking at another problem? And that's a simple crosswalk. As I look at automated vehicles and I look at the way that they sense the world, a lot of automated vehicles will use laser scanners to sense the world. Anything very close to the laser scanner is seen in a lot of detail. As it starts to get further away, the laser scanner has much less detail. It may only get a couple of reflections. So I have some idea that an object is there, but I don't see it very clearly. And in fact, the laser scanners, while they give this wonderful 360 degree field of view close into the vehicle, are not the same capacity as the human eye when looking at objects in the distance. So now let's say I'm in a vehicle, it's using laser scanners to scan the environment and it approaches a crosswalk. It sees something which may or may not be a pedestrian. Now to the human eye, we know whether or not that's a pedestrian. But it takes a while for it to come and focus to the vehicle. The vehicle is looking at all of these reflections trying to understand is that pedestrian going to jump into the road? Or are they not going to jump into the road? How do I handle this situation? Now I don't mean to say that there aren't solutions to this. There are automated vehicles out on the road that have solutions to this problem. But the solutions to this problem are actually sort of fiendishly complicated. Because you think about it, well, what am I going to do as an automated vehicle manufacturer? I'm probably just going to slow down if I think there's any chance of a pedestrian there. And I'm going to play this really conservatively because I want to be safe. But I've made a decision there which has an impact on a lot of different people. I've made an impact on all of the traffic around me. If I choose to slow down the car much more than a human driver would slow. I have to ask myself, is that because human drivers are being unsafe or is my vehicle somewhat myopic in its vision and driving conservatively as a result of that? Am I negatively impacting all these other people on the road who now have a longer route to work because the automated vehicles are sort of preemptively breaking for these crosswalks? And these poor saps and the other vehicles don't just sit back in their automated vehicle and surf the internet, watch cat videos or whatever one wants to do in an automated vehicle. All of these things have very, very strong interactions with other road users. If you think about automated vehicles going out into the world, in fact, many of us will have our first interactions with them not actually driving in the car, but being a pedestrian or being a bicyclist? Or being a car in the lane next to these other vehicles? And the way they drive with us will have really strong impacts on traffic flow, on public acceptance, on all of these other issues. So what seems like a trivial problem, something that we solve as humans every day, you know, approaching crosswalks and figuring out do I slow down and if so, how much? When I start to actually put that in automated vehicles, I end up with a whole host of questions. And every question I answer or possibly answer I come up with opens up a few more. You can say, for instance, well, why don't I just learn what humans do? We've solved this problem, so we'll just look at a bunch of humans and we'll program the automated vehicle to do exactly what humans do. That can work in some ways. But the challenge is, is don't we want automated vehicles to be better? Don't we want them to have fewer accidents than humans? And what do we do about the fact that humans have some negative aspects of the way they approach intersections? People have found age biases in whether or not people will slow down. People have found racial differences in whether or not people stop at intersections. Do we want to encode automated vehicles with the worst aspects of humanity? Or do we in fact want to be better in some ways? If so, how do we do that? So, the sort of takeaway message that I've found from working on all of these things is that sometimes the problems that seem easy are actually really, really hard. They go outside of engineering and touch on many other issues of society. Oftentimes things that we don't train are engineers to be able to understand and handle. And sometimes problems that seem hard are actually very, very easy. Now, some of you may be better at judging these than I am. But I've found throughout my career that I'm often at the beginning of a project a very bad judge of whether something is going to be hard or easy. I find myself continually surprised by this. And the only way that I learn is to get right into the middle of the problem. And so, as you think about this, as you think about ventures that you want to launch, as you think about things that you want to do in your life, I suspect you may find this to be similar. You can plan all you want. You can think about what's going to be hard and what's going to be easy. But when you're right in the middle of it, I suspect it's going to look very different. Things that really seemed like it would be hard to do, like our drifting de lorian, were things that we were able to actually do in a few years. Things that seem really trivial, like how do I approach a crosswalk? And how do I have respect for other road users in this environment? Are actually really difficult to come up with a common answer for. And really challenging. So, hopefully these are some points that, a, relate to fun stories about automated vehicles, but also resonate a little bit. And give you just a little bit of a perspective as you sort of approach things that you want to do. To ask a little bit of, you know, am I adhering to this path that I planned out a long time ago? Or am I actually being flexible enough to take advantage of the opportunities that are opening up? And presenting the car into the corner and then as they say, and racing, going where the car wants to go? Or am I trying to kind of continually force my will about, again, excuse me, upon something and not take advantage of what has changed in my environment? How do I get other people on board with me? Can I accept the fact that people are going to have very different motivations than I have? Well, I may be passionate about something. I need to work with other people who may have completely other passions. But we can often find a common vision that moves those things forward. And finally, with all these sags, it makes sense to get right into the middle of a problem. Because when you're in the middle of a problem is when you understand it. When you're in the middle of a problem is when you will figure out what's hard about this and what's easy. And where you want to put your resources. If you want to go after the really hard problems or do you want to take a slightly different pact that avoids them? You know, as researchers, we often go after the hard problems because we can do that for research. From a company standpoint and a startup company standpoint in particular, when you see the cash balance decreasing every month. You know, oftentimes it's best to steer a path around some of the hard problems towards things that seem much more doable in the short term. Knowing which is which is tough. And figuring that out in my experience has only been something that we've been able to do when we're right in the middle of the problem. So hopefully these provided a little bit of insight what we've learned from automated vehicles and how that sort of impacted my decisions. Hopefully it's useful to you and I'd love to spend the rest of the time with any questions you might have. Okay. So, our time of the vehicles, first of all, how far in the future do you really go really deep before we have the new vehicle that's there on the road? What are the potential unintended consequences that you see as results? Okay, so automated vehicles, when will they be on the road and when what are the potential unintended consequences? So I think automated vehicles are already on the road. And so you see companies like Waymo, like Uber, like Lyft, GM actually testing increasingly on the roads and getting increasingly farther away from having a safety driver directly in the cockpit. And some of the Waymo tests they've now been moving the safety driver into the backseat and have talked about in the near future, removing the safety driver entirely. At that point, we have fully automated transportation. Now, I think one of the things that people think about is in their mind that I'm going to buy an automated vehicle and it has to handle every drive that I take. And in reality, the quickest path to market and the one that makes the most sense is to think about a vehicle that can serve a very local area, something that has is able to go over routes that are of relevance to enough people to sort of make that operable. And maybe it doesn't work in bad weather. So maybe I send a human driven vehicle to come pick you up when I need to do that and when not, I send an automated vehicle at a fraction of the cause. What we're talking about is actually a matter of months to low numbers of years, a lot of companies are talking about 2019, 2020. And I suspect that you'll see some of it before then as well. Now, this won't be a vehicle that you can pop in anywhere in the country, hit a button and have it drive you to another part of the country. But if you think about it, public transportation doesn't work that way. It's all fixed routes. And this will be, in fact, more flexible than that. I think the answer is very, very soon, but maybe in a more limited sense than people normally think about. What are the unintended consequences? So this is one that I enjoy playing around with a little bit. Because if you work through the math about how much transportation needs to cost or could cost per mile. Let's say that I have developed my software for an automated vehicle. I can now replicate that with very low incremental cost. I can actually move electric vehicles. I use some shared mobility. I can, in fact, move people around town potentially for about 10 cents a mile or so. And we're a magnitude cheaper than I do today. Okay, so if you want an idea about where adventures may be in the future, play that out a little bit. What happens when transportation costs for individuals dropped by a factor of 10? So the cost associated with moving people or potentially the cost associated with moving spaces changes a lot. That could have a huge negative consequence, right? If something becomes much cheaper, I'm going to want to consume more of it. Maybe I actually don't bring people to places. Maybe I just send rooms to people because I can move that around. Maybe actually transportation at this point is provided for free, so long as I can actually get the data of where you're going. Maybe data actually becomes the gold rush and not mobility in some ways. Maybe actually what I will even pay you to go somewhere if I can kind of curate that experience that you're getting in your automated vehicle with whoever the advertiser is. If you look at costs per clicks, well imagine instead of having somebody click on their home computer, see what people are willing to pay for that. Think about 10 cents a mile of transportation. People could provide free rides to give you a much more immersive experience with advertising. I think there's all sorts of different places that this could go. And I think those will have either positive or negative consequences. So I think it's a great exercise to sort of play out what are the industries that are relying on these transportation barriers or in fact profiting from this and how will this reshape our world? Yes, I sometimes worked on Paul. How do you think automation is specifically the truck industry is going to affect the economy and people's jobs? Great. So as somebody who's worked on the policy side, what about the impact on jobs that in particular in trucking? What's interesting is that trucking is often used as an example of where we're going to expect huge job impacts. The interesting thing is that there's a shortage of truck drivers right now. We have in fact a truck and trailer combination which we can use to get all of our vehicles up to the track at once. And we're having the darnedest time hiring somebody to actually drive that truck. There's a very interesting demographic wave in truck drivers and at private fleets, I think the average age of truck drivers is about 53. That's average. There are more truck drivers 65 and older than there are truck drivers 21 to 25 in the US. So there's this sort of big demographic bubble that's moving through. I suspect that people who are in that demographic wave will have a job driving a truck really as long as they want to have a job driving a truck. Because there will be those opportunities available. Trucking has not been able to get younger people into it. And so I think what you're going to see is that that demographic wave may move through and not be replaced. So that's trucking. So I think it's interesting that people use that as an example. I do think that artificial intelligence, I do think that automated vehicles are going to displace a lot of employment overall. It will create some new opportunities for maintenance, for understanding logistics of some of this. But I think it is going to displace a lot of jobs. And I think from a policy perspective, this really is a conversation that we need to be having. Because we sort of built our system right now on the idea that you can contribute your labor and expect a reasonable days wage in return. And our society is kind of built on that pillar. And the question is, if that starts to not be true, because so many of the jobs or the tasks that we need can be automated, then how are we going to restructure around that? And so I don't have the answer to that, but I think it's I'm glad that you're asking the question because I think that's exactly the dialogue we need to have. Can you talk about public destruction and for example, people who are rational in years of dying in an airplane, rather than a car which is much more common? Have you had sort of a career and think about the previous seconds of the matter? So one of the things that I find is interesting is that they will... Oh, great. So what about the public perception aspects of this? People often have irrational fears of safety, for instance, thinking more about dying in an airplane crash, which nobody did in a commercial airline last year. And there's not a single fatality in commercial aviation last year versus thinking about the risk when you get into a car where in fact over 45,000 people lost their lives. So how do we deal with this with automated vehicles from a communications standpoint? I think it's very interesting that a lot of times there are interviews with people about how do you feel about automated vehicles? And people will report that 70-some percent of people have this concern about automated vehicles. But what is their basis of reference? What have they know about automated vehicles? What have they learned? It's something that they've read, it's something that they've seen. People tend to be hesitant at first. We've seen this with our cars. People often are unwilling to get in at first, they're a little bit hesitant. And then even with the race cars, after a couple laps on the track, people are relaxing and going, yeah, cars got it. You know, you do know this was programmed by like grad students and a professor. The fact that you've actually safely made it around the track twice doesn't really imply that you're going to continue to make it around the track safely. But people's fears go away super quickly. So I think that's also irrational. But helpful in terms of people wanting to have automated vehicles out there. So what I really think is going to be key, and one of the messages that I've been giving to manufacturers is the very first pilot deployments. The very first vehicles that are carrying people around are going to set people's expectations for this technology. And so I think companies should be really smart to think about what is it that they're doing with these initial deployments. Who are they moving? Because if there are, and there will be, accidents with automated vehicles, I think people will look at that and say, well, do I see this as something which is only available to a small percentage of the population? Or do I see this as a technology which maybe not today, but in the next few years will be available to me or will be helping my aging parents move around. And that sort of connection will be really important, I think, in building public support. So I think it's not a question of going out to the public and trying to convince people that these cars are safe and that they should like them. I think it's incumbent upon the manufacturers to produce something which is safe, which interacts with the public in a good way, and in fact is available to a large segment if not all of our population. And I think if they do that, then the public perception issue will be much less than people commonly think. How do you think the liability issues are going to be resolved and who ultimately is responsible for an accident occurred and something gets come? You have a lot of people now saying a lot of the companies that are developing this are really making the claim that, okay, we understand if we're developing the software for this, that we have liability for the software functioning. I think one of the interesting questions is when you start to get into the liability question. Right now, we think about driving situations and how the law handles people, whereas if we have an automated vehicle that has a crash, is that a product liability? In case at which point, product liability law and traffic law are really different aspects of the law and how you can sort of go back and forth between the two of them is an interesting question. Actually, I'm working with a student in the law school on that question at the moment. So I don't have any answer for that, but understanding the different parts of the law and how they might apply is a pretty fascinating question. So the automotive industry is very, very competitive space and it seems like a lot of the major gains that you can realize are from things like, as you said, convoying or whatever you're used, you seem to have a lot of cooperation between manufacturers that's going to be necessary to make those systems work. Is that happening now? Is that going to have to be a policy enforcement kind of thing? How do you see that bill? Good question. So the question being that given how competitive the automotive space, the automotive industry is, can we get to a level of cooperation that might, we might need down the road in terms of standardization? Is this something that government will lead or how do we get there? I do think that there is a lot of competition, but a lot of these questions about, you know, how do we establish, for instance, that automated vehicles are doing a good job? We have metrics right now around safety of vehicles, but these are largely fatalities. And measuring fatalities is not really the best way to go about understanding whether a vehicle is safe or not, because we have to wait until something horrendous happens to have any measure of that. So there's a discussion right now about, well, what would be other measures? And that discussion, for instance, is one that involves government and involves different manufacturers. And so I think talking about some of these issues is something that the manufacturers are willing to do as a group. Interestingly enough, there was recently an issue in Germany where, in fact, the German auto manufacturers were accused by one of the government agencies of acting as a cartel because they got together to share technical information. And their argument back was essentially the point that you made is how are we going to move into this future where we've got these sort of intermixed vehicles if we don't share information with each other. So there really is an interesting balance there where I think there is a willingness to work together. Obviously, people don't want to give up their competitive advantages. And sometimes it can be really hard to work together, particularly in the presence of government regulators or agencies sometimes. I think it's a big difference if you just program a cartel to be able to be helped in a smart based on mathematical models and all, over then you actually use artificial intelligence which allows the vehicle to make its own assessment of the situation, make its own decisions. So if you share your vision on heart, you would like to use artificial intelligence. So the question is there's a difference between whether I program vehicles explicitly to do certain things or I use artificial intelligence to let the vehicle learn. Now one of the things to understand about artificial intelligence is that it really is essentially a form of pattern matching. So basically you feed training sets of data into a neural network and it learns the outputs from that and then when faced with something different essentially matches that pattern and takes the appropriate action. Now one of the difficulties with this, particularly from a regulatory standpoint, is that if you introduce new information, you don't quite know what the neural network is going to do. When you take a more mathematical approach, you can pretty much have a good idea of well these are the inputs that are going to result in these outputs, these are the sorts of things that can mess it up. On the other hand, that approach really doesn't take advantage of the huge amount of data that you're bringing in. And so I think really a merger of these ideas is where we're going to find ourselves going forward where you have certain things that you may want to prescribe. There may be certain things that because of the law or because of certain standards, we really want to tell the car how to behave in a certain situation. There's others where we'd like to be much more adaptive in match these patterns. I think one thing that's interesting to see Google recently released some stickers that you can put in images and it totally blows up neural networks that are doing image recognition. It's a really interesting example of you have this neural network which in general does a fantastic job. But a malicious actor with a little bit of knowledge can cause it to do entirely the wrong thing. And so those are things that we have to be a little cautious about. I think there can be a great sort of merger of these two fields but honestly within academia a lot of times learning and model based approaches are almost different religions in some ways. And so what we've been trying to do is to figure out where are the interesting intersections and how can these technologies play together. The Oddware Thought Leader series is a Stanford E Corner original podcast supported by the venture capital firm DFJ. The stories and lessons on Stanford E Corner are designed to help you find the courage and clarity to take action. Stanford E Corner is led by the Stanford Technology Ventures program and the Department of Management Science and Engineering in Stanford's School of Engineering. To learn more please visit ecorner.stanford.edu.