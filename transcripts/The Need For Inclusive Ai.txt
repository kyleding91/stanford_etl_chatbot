 Who you are defines how you build. This is the Auditorial Thought Leader's series. Brought to you by Stanford E Corner. On this episode, we're joined by Laura Gomez, founder and CEO of Atepica, an AI platform that seeks to remove bias from the hiring process through applicant tracking, recruitment, and visual diversity dashboards. Laura is a founding member of Project Conclude, a nonprofit working to accelerate diversity inclusion in the tech industry. Here's Laura. First, I want to talk about my path to entrepreneurship. When I was an undergrad at Berkeley, I wasn't really thinking that it could ever be a founder. I didn't see founders like me. I didn't hear about entrepreneurship. All the entrepreneurship has been very key in almost my family. My mom is an entrepreneur, a small business owner, yet I didn't see myself to actually be on this side. Other things I will share with you are my journey on building Atepica, being a Latina founder today's Latina equal pay day. Latina only make $0.50 per dollar that men do. So we're severely underfunded as well. That only is in Silicon Valley, but across all the tech and entrepreneurship ecosystems around the world. So what is Atepica? We basically power analytics for teams to understand really how they're doing on diversity. We do things outside of self-reporting because not everyone will self-report. I'll go into it. But we really believe that this is the most key and pressing business issue out there. And we have a lot of different, belonging, diversity, employee activism, ethical tech. All of those things I will touch upon during my chat today. And obviously I will leave some time at the end so that if you have any Q&A, you'd be more than happy to ask me some questions. Actually, this is really funny. I will start here. Atepica was born on this campus, ironically, exactly five years ago. I was asked by USA Today to do a close event at Stanford Law to talk about this pressing issue of diversity and inclusion with leaders of Facebook and Google, VPs of diversity and inclusion and the Reverend Jesse Jackson. I'm Stanford Law Professor Richard Thompson to come and speak on this issue. A background about me and I'll stay here. I usually do have a slide. I grew up. I have an immigrant. And I grew up in Revwood City. I was a child. I tell people that my culture and my birthplace is in Mexico. But my hometown is Revwood City. I lived through blocks away from your mom. When I was probably your age, I didn't think I would have lived near my mom in my 30s by here I am. And Revwood City is my home. I grew up there before a lot of the changes I you're seeing around the Bay Area. I tell people that I knew Mountain View before there was a Google and that the only reason I would go there to shoreline to go see the few geats play a concert. It's important for me to acknowledge that even as a child that grew up in the Bay Area, I never saw myself being an entrepreneur. My mom was a house cleaner and was also an auntie to a lot of tech executives during the 90s. Yet I didn't think that I could play part of that ecosystem, but here I am and I'm very feeling very grateful and fortunate. But also I know that I have fought a long way to come here. I was also, I cannot deemphasize that although there's certain identities to my intersectional existence, I was also a non-documented child. So everything that I embody and I'm actually at is because I grew up in Silicon Valley. Whether it was a cursor of blessing, I grew up here. I worked here in high school, actually I worked here at Stanford. The reason I didn't end up coming here is because I didn't want my mom to show up with a pot of beans at the dorm and I thought, hey, let me look at other ways that I could be near her but still work. I had my first internship at the age of 17 before I started college at Hula Packard, right on Page Meal Road. And I didn't see, again, no one that looked at me. And once I started my first internship in class, it was, by the way, that I decided I didn't want to be in this industry. Ironically, because of how I grew up here, here I am. Also I think this picture is really important because I believe I'm the only founder that had their mother, their future investors, future clients, their friends, be present when I spoke about why. I looked at Facebook, I said, you have the largest facial recognition data set in the world with the best, probably brilliant data scientists. Why are you saying that you can't get more women into your engineering roles or you can't find more people of color either brown or black people to intern at your company. And the same for, I held them accountable that they had this talent that they weren't really tapping it into actually creating more inclusive workplaces. They didn't answer me, so I said, okay, well, I was supposed to travel around the world. And I decided to postpone my travels to fund this company. I was just explaining to my friend two weeks ago that this has been my longest job in tech, five years in county. But it is when you're a founder or an entrepreneur, you're passionate enough, you keep going. I've worked on a lot of tech companies. Another thing that is very interesting to me has been that I founded an enterprise startup, even though my most of my career has been in consumer web. But also, I sit on a lot of the boards that you probably hear of, like Anita Borg on the Diversity Council, the Women of Color Council, they put on Grace Hopper on code.org, I believe I just got an email for their annual dinner. So for me, it's really important not to just talk about it, build a company around it, but actually do something and contribute back. Why this matters to me? And to everybody. Everything here is changing. Whether it is a demographic, I was just reading about an app built by women, house cleaners in New York for themselves, where they actually, it's part of the gig economy. They're actually, they deploy all of their apps to make sure that there's a livable wages to all the house, to all the sort of domestic or house cleaners in New York. So people will use technology to unionize, to really make sure that they live in a world that is just unfair. Other women are entering the workforce, as we all know. Ten years ago, I wouldn't have imagined a room like this. I was also wouldn't have imagined like the changes I haven't made by all of the women that have contributed. Some of them, alumni of here, but otherwise, people, a lot of women that have paved the way so that everybody feels that they have a fair chance. And also we have to think about all of those different paths, where I find really interesting and is that a lot of my clients understand it, but it's not necessarily a way to think it's good, it's ethical, which you invest in diverse and inclusion. It's a business imperative. Four hundred billion dollars are lost in PR nightmares. I mean, how many times do you hear about someone who walked a famous rapper who walked into Sephora and was discriminated against or Beyonce walked into a re-buck meeting and there weren't any people of color so she walked out. So a lot of it is related to PR, but employee attrition to satisfy shareholders. We see all of the sort of movements that happened a couple years ago by women in tech are still affecting companies that have gone public and they're still not doing well, that their culture has not really healed from those things. So we really, I do believe that this is not necessarily, it feels good, that this is an business imperative for the future. A lot of this data is fragmented anecdotal and broken, everybody will just say, hey, I ran a report, I feel like this is enough and we tell people that it's not enough if you're centralizing all your other data. The number one field right now in data science within a business organization is actually people analytics. Seventy percent of all companies now have people analytics where when I started a topic five years ago, it was less than 5%. So they're looking at how people are being paid, what the benefits are, the engagement, how they're being hired, who's being hired. So people analytics is something that is very, very profitable and I was being used. That being said, who's building this tool since we have to ask ourselves that and with a topic that is what we're aiming to do. I also believe that the future of the workforce and not just on race and gender or any other or age, it is a non binary workforce. How are we adapting to how people identify themselves or don't identify themselves? I spoke here at Forbes CIO Summit where CIOs of corporations both financial and media companies like Sony Pictures heard me speak time and time again that a CIO's role is to actually gather more information around their people. They're going to the CIO's role 10 years ago with probably about information and IT, but in the future it may be around what information and what data you gather for your own workforce. The market is quite big. The market is quite big. If people don't know, like visual analytics, I say it's queen because I'm a big feminist, but they are all, this is where it is. Tableau was acquired by Salesforce where I believe $18 billion earlier this year and look at it for a lot of data and visualizations are happening right now around how to make business, business is adapted to what is needed from their consumers to the key performance metrics, any of that stuff. For me, I just focus on people. As I said, people analytics is growing. I give the stats because I think it's important to know that this may change and by the time you graduate or some of you are in the workforce, midway through your career, it could be three times as that. It didn't exist when I started at TIPPICA. Imagine me being a founder going up San Hill Road or talking to investors saying I want to build a platform based on inclusive ethical and responsible AI, diversity and analytics. This is five years ago. They thought we don't get what you're building. But those are the things that we have to adapt really quickly and we have to be part of the conversation, especially women, especially women of color. I put this picture, I did not put the logos of this man, but as you can see, I have received about $3.8 million in funding. I raised the largest seed round in the history of Silicon Valley by a solo Latina founder. I have raised, I have raised about the same in the five years that TIPPICA has been around. In the space where I'm at, and I know Sarah spoke here at also, she works in HR tech and the recruiting platform we integrate with her product. In the space that we're at, I have seen men in the past year receive more than $300 million in funding. I received 1.4% of that. Even though I've been in the market, now a lot of these tools are saying they're building inclusion into their tools into how employees are happy or all this stuff, but it's really important to think that the bandwagon is there that Antidseh needs to be there. Does it hurt? Yes. Not easy, especially when a lot of other founders are talking about inclusion and putting it into their own tools and placing $7,80 million off it. But where the only ones that are focused on this, I tell people you can hire. A lot of people analysts, and this might be a project for them, but for us, it's not a project. This is our livelihood and this is what we are very passionate about. What is a TIPPICA? So a TIPPICA, we have a platform. As you can tell, I'm a product manager because I built it three products. I built an API, the diversity intelligence, which is proprietary and also how to mitigate the biases that are in recruiting. I've started out with a TIPPICA thinking, it's the recruiters. They need to, they have biases. And we realize that data shows that it's not the recruiters, that there's different ways to understand where biases come from. You first need to give them the data. The diversity intelligence was actually something that leaders asked me. I want to see reports based upon how people are moving throughout the funnel. We want to see who came in. Did this event really pay off? So we built that as well. And then one of our clients, Netflix, and I decided that hey, we already, we don't need a different product, can you build an API so that we can just use your technology and layer it on internally or dashboard. So we did. How are we different? And you can ask me how is this ethical, not ethical, whether they're some of their legal. So we actually, I decided that a lot of, in recruiting, you'll see what is your race or ethnicity or your gender. And that's the EOC, the Equal Employment Opportunity Commission report. That is voluntary, you don't have to answer it. Some people answer it, other people don't. Some people answer one aspect of their identity. I may answer that. Okay, Latina, but I mean, I don't answer that one woman. It depends. But there's a lot of data gap. But people are making goals around this. So 30 percent, if you fill out 30 percent of the top of the funnel, then 90 percent, then 70 percent of that, like you don't know, and you're making goals or the business are making goals. I also decided, I know exactly how automation and recommendation systems work and what aspects of your identity are being taken. Obviously, data privacy, we were just talking to the professor and I, on the importance of data privacy. So how are typical ended up getting a 96 percent accuracy rate on gender? Our training set is very diverse. We take government data, everything from the EOC to census. So it's really important for 2020, I want to volunteer for the census as well. Campus location, universities and the university demographics. So Stanford probably looked very different 10 years ago than it does. It will look like in 2020. And then we learn from it. We use our own ML models to actually think, okay, if someone's name Laura and the last name is Gomez, most likely Latina. And A, Latina names usually end with being attributed to females. But in Southeast Asian, like persona is one of our visiting scholars and he is Indian. So how do we make sure our models are here are ethical, they're very localized and they're able to be able to validate them. We do the same with race. I got my master's in the social construction of race. So when people say internalized to the UK, we cannot. Because then we need to look at census data in the UK. We need to look at what people identify as. And that is very nuanced. So we don't do that. We've done this here based upon what my knowledge is of the racial component of the United States and how people are self identifying. So yes, we are 96 percent accurate in inferring gender and 91 percent, and then we're 100 percent on top of the funnel. A lot of people think that it's based just on names, that's a foundation, but that's only about 67 percent accurate. There is, we've really worked on it over the past five years. Here are some roles that you can see that we look at it on the data science, on how long it takes to hire for tech roles and how many days. And what this analysis was early on, you see some trends and then you see some differences that are coming across on whether it's the market that people take more time to hire or less. So we do this type of analysis. If you go to our blog, we just did one on referrals. And it was very interesting. Women did really well in smaller teams when they were referred by anyone, but as soon as they were referred into a larger organization, they actually did not do well into tech. So we did a lot of referrals. We did referrals on black and brown candidates and how they get into the funnel. And then we also did, as I said, on what we called the bamboo doorway. We saw that Asians in general had a harder time being hired through the referral system. And we did the same for operations for gender. So we look at all of this information. For us, visualizations are really important. The way we say, yes, data is, you can have data driven, but you have to have data purposeful. My goal in vision really is in general with a typical, is to foster growth and innovation through DEA. I must DEA diversity, equity and inclusion. So to become a brand entrusted for attracting talent and retaining it, but also to protect businesses from liabilities. I do have, I talk to many lawyers who ask me, is this legal? And I say yes, because we don't say, we don't pinpoint specific people. We use aggregate information, like tens of thousands and not millions of applicants. Another, my first angel investor was an employment lawyer. You will see time and time again. I think LinkedIn just published something yesterday or the day before that a lot of these tools are recommending applicants or recommending candidates. They will be audited in a court one day, because who built this recommendation systems, for example, eight? Some people, like myself, when I got into the workforce, maybe my major didn't exist or now it's equivalent to something else, right? Maybe statistics now, it is data science. But if I recommend this to you, systems, we're only looking for data scientists. It's actually being agist. So a lot of the tools in our space are actually going to, and you see this time again, even in consumer, you see recommendation systems. I spoke at women in the world, one of the largest conferences opened the stage, and then I was on that stage the next day that was really amazing. But we talked about automation and artificial intelligence is going to disproportionately affect women, especially women of color around the world, not just in the United States, because those are the ones that are manual. It will also think about ethics, facial recognition for black women. Obviously, we've seen the studies time and time again. And then finally, responsibility, even if my AI, even in my drone, is a responsible AI tool, what if someone gets hands in the hands of the wrong people? I just read. We know the founder and CEO of Ring, Jamie, I met him once, but I just read that ring that the police can actually ask if anything happens, a crime occurs within two-block radius. The police can actually keep that information from Ring for 45 days, even if you had nothing to do, or your home had nothing to do with the crime that was committed. So discussing this implications of access to data, privacy, artificial intelligence, is really important to understand that people cost them liabilities. I will end there, but I want to just take a step back and put my email here in case anyone doesn't want to go into the Q&A. For me, I want to talk, I spoke a lot about my product, about my company, about the space that I'm in. I want to speak really quickly, and I don't like having as many slides there, because you can never really understand what it is to be a founder nowadays. It is hard, everybody is always talking about the recessions coming. Davien said, I feel it's the greatest equalizer as it relates to building something out of sheer passion. I never saw myself on the stage, I never saw myself as a founder. But my friend, he built this very awesome oven, smart oven. What he wants is people eating healthier and making sure that food doesn't go to waste. So when we go through, and he does not, anything look like me, or is within the circle of like, what my activism is, but we're all founders. We all started building for some reason, something that we wanted. We went through fundraising process, we went through entrepreneurship, for whatever reason. I always like to tell this story. Mine has a lot of purpose because I'm very passionate about it. But everybody has passion, even when you don't know or you read. There might be some founders out there like, I just solved a business problem and that's okay too. But I remember I talked to this entrepreneur from South America one time and he was really passionate about having access to air fresheners that he can control remotely. And I was like, okay, but we talked. And I realized that this was based upon some sensitivities that his wife had, things that he really wants, that smell is actually really important when you go into your home after work. And he did a lot of studies on that, but he was so passionate about it. And so I honestly do believe that entrepreneurship is something that I hope anyone here, whether you are, you don't may not become an entrepreneur, I studied working at startups right after college. So I've always been part of smaller startups that grew. When I was a Twitter, there were less than 50 employees. I was the first Latina there and then I ended up heading localization and left when there were almost 2,500 people. So, but I saw what entrepreneurship was through all these early experiences. And so for me it's really important to talk about importance and just to how amazing it is right before I came here. I would look at my phone and I probably got one, like if not, I can't divulge a lot. But if not one of the most important emails of my career as a founder and for my team and for my investors. I also chose wisely my investors. They're very at my board members. All entrepreneurs will be faced with taking the money from certain people that you may not agree with. Or backgrounds or firms that didn't do so well on being respectful or not supportive. But I really thought long and hard. I turned down money from people that I just couldn't really imagine to be in my board. So those are some of the learnings that I had. But I don't take away that it is sad to me that Cecilia Corral, who was actually in the undergrad here. And she went through YC that she had to make her own list of how many Latinas have gone over $1 million in funding. And so far we have 25 that we found across the United States. And that statistics are not keep the same. So definitely the struggles there. But we all have the solidarity of whether we build something out of passion or we are in the same circle of who we are to come here. Finally, to me, when people come and I don't know who here is local. But when people come from other places to Silicon Valley, I explain to them why this is so important to me. My family still lives here. I am the face of a lot of, you know, I was a Cooper cafe and I invited. Like I don't mean my coffee to come and hear me speak. I said, but it will be online because it's really important that the communities that serve as the communities that I'm a part of. Or actually are seen. So I tell people that my nieces, Ellen and Natalia, they can't be where they can't see. And so if we're made important to speak at events like this, it's important to actually talk about the activism that I do. Not only through being a founder and through the tools I'm building, but also through just sheer existence. To be, to move forward. And so for that, I will leave it open. There is about 20 minutes or 19 minutes for Q&A. Any questions that you may have, please feel free. There's a lot of questions. You can ask me anything. Go ahead. You showed a lot of graphs about race and gender and you touched on ages. You talk about the work you've done on that and how, I mean, in Silicon Valley, there seems to be a definite bias. Oh, the bias is there. So one of the things I did talk about was what we said if someone graduated 20 years ago in statistics, and now it's really just data science to be quite honest. But they have a degree that the machine learning. So we did some of that. We also have looked at, we actually looked at something very interesting. We looked at in the summary section where people say over 10 years of experience, just 10 years. But imagine if you're 21 or 22, you're graduated. But at the time you have 10 years of experience, you're going to be 31, 32. That's not, that's actually quite young. That's not even ages. But we noticed that the drop off of calling them, with calling those individuals was really high. And then when we noticed where people put, even the length of the resume or where they put their education, and if they put like two or three more degrees, I have to, well, I have technically like four. Because I did double undergrad and double masters. But if they listed more than degrees, they would seem that they're too overqualified for them. It would be tied back to age. So we've done that work. It's really interesting to see how we can really push forward that work. We're still a smart startup. So definitely want to talk about that. Another thing that we've discussed is looking at ways that were people's zip codes are located because you know San Francisco is mostly young people. They said there's more dogs than kids in San Francisco. So there might be ages in locations. And so we're looking at all that. And it's kind of semi-related pronouns on resumes and social media and LinkedIn are a whole new thing. I didn't see this five years ago. So pronouns now on binary and non-binary folks are really coming up. Project include the nonprofit that Ellen Pouruns actually did a survey among startups. And 5% of all the tech workforce identifies as non-binary. So we're doing different types. Definitely, I feel like the older I get, the more I'm very passionate about this. I also talk about looking at data points that are meaningful to the workforce. So I explain this to a very, very powerful woman. I mean, she flies private jets with a very famous CEO. I wouldn't say, I'm always in a meeting with her and I say, as I get older, I still want my female counterparts to have access to and my male counterparts to have access to maternity leave, maternity leave, fertility, thoughtfulness on what matters on reproduction and family. But as I get older, I mean want a benefit on how to walk my mom through retirement. Or most women end up taking care of their mothers. And so like, how can we support women as they're getting older in the workforce with their parents? And so those are all aspects that I think about on ageism. Like that, even the benefits sometimes are age-est towards not including what people are in the state of their lives. I have a question about your room. So when you were kind of out of college and you were at the most companies as a fresh brand, how did you think through some of the ethical dilemmas or problems where you either asked you something or a couple of doing, or you don't know? Did you have sort of a friend that I grew up then you were able to talk with or how did you think you could compete with your career? Yes, so I will repeat that question. So as I enter my career into tech after I graduated, how did I really think about the ethical goals or the social responsibilities of working at these companies? And did I have a support system? That's an excellent question. I worked as a contractor, the little red badge at YouTube when I started off there. They had just been acquired by Google and then content moderators were like the most depressed people and you can see the same now in other tools. They would tell me some of the videos that they would see and I would purposely not walk in that direction and there were only 300 employees. I looked back and I looked about also part of this other, like I don't have enough time, but I'm also part of this other organization called Build Tech With Trust where we saw a radicalization online not being held accountable by the tech companies, by the content that they're providing. And so after the mass shootings on around diplomacy and radicalization, a bunch of women of color CEOs here in the Bay Area, we came and built a build tech with trust as a coalition and then we even submitted questions to Congress when Mark Zuckerberg went there a couple weeks ago on the questions around the ethics. Going back to your question, if I could go back, I would have taken more ethics courses in college and thinking about what I'm building to complement my more technical or my more social degrees. Then I worked at Twitter and the first time a dictator started tweeting on Twitter was Hugo Chavez, which is a dictator of Venezuela. And I was in charge of Twitter in Spanish, so I went to the general council there and I said, should we have a policy on how leaders or dictators should tweet on this platform if it threatens the citizens' lives or does. But it was kind of like a passing thought. Do I wake up and think about it? Yes, especially given nowadays. So I do believe that I did not have that system and so maybe this is my way of atonement of working for all the tech companies to try to reverse a little bit. I think after the 2016 elections, one of my colleagues at Twitter tweeted at what have we done. And I just remember that tweet and I was crying. And then my partner worked early at Facebook. So he has been, he worked through the API at Facebook. So he knows everything that happened there on data and the Cambridge analytic stuff. So I think we're all, everyone in this industry is really torn on how we can make a change and hold ourselves accountable. I always tell people I have a love hate relationship with tech, but I love the industry enough to want to change it and stick around for a while. So thanks for that question. Yes. How do you foresee including military veterans in your diversity? Great. How do I foresee including military veterans? I have. I was actually on the board of a veteran organization. I had to step away once I started building out the company. I was in the same code. And we did at the same study, but what we realized that veterans actually self report themselves are very high that we don't need models to include them into the process. What we need more is understanding transferable skills. So we neutralize the taxonomy of skills among veterans to know like if you are a program manager in the Navy, how does it translate into something similar. So we neutralize that. We didn't need to really fill in the gaps on reporting. I wish I had more funding and I would definitely have little subsets of tackling age, tackling veteran inclusion. Also was likely LGBTQA and disabilities more into our product. Yes. The statistic that you shared about just there being only 25 Latinas who have been able to raise that much funding is shocking. And what that made me wonder was where did you find confidence in yourself to feel like you could do it and how have you worked through moments where that was tested? So I had a very high profile job mostly at Twitter, just very high profile. And so annoying a lot of the early employees there ended up as venture capitalist. So I thought it would be easy for me. Little did I know. 2014 loud I was very realistic. It was I didn't prepare myself. I didn't understand like cap tables. I didn't understand a lot of things. I read a lot. I'm a speed reader. How did I get the confidence? I don't think I don't know if anyone has talked here about the value of despair that founders go through. It's like this value where I can't get out of bed. I don't know what's going to happen. I really believe in this. And then you kind of get up. I believe the value of despair for underrepresented founders fundraising is really hard. Anyone fundraising. I remember I was coming back from an event with a friend of mine who's a founder and he's like I hate downhill road. Coming up here. As the experience that people just have, I do believe that it was hard. That there were many tears shed. That I was telling that Ravi was one of our investors that actually gave us a bloodline to try to get more fundraising. But it always seems like it's towards the end that you're like okay I give up and then something keeps you going. I remember a friend of mine emailed me and she has a PhD. She has a co-founder her CTO and said you're the trifecta of difficulty like your solo, female Latina founder. It was hard. I like to share this because I think it's important and people get shocked. Earlier this year I was at a board meeting and I started getting a headache and I was like this headache is weird. I was flying between New York and here. The headache didn't go away and I was at a board meeting and it felt really weird. Then by Sunday my board meeting was Friday morning Sunday. I was actually here at the ER here at Stanford. I was diagnosed which we did not then but with a benign tumor. About a couple months ago I actually wrote a blog post that says I survived Silicon Valley and brain surgery and brain surgery was easier. And it was. Nothing against Stanford here but I looked where were the best neurologist and specialist with what I've given. All this stuff. And I realized that I see you out of my self out of that situation. Very quickly got second opinion. I got three opinions with the top neurologist within two days. I was texting. I was everything my mom was like why are you in your computer? I was in my computer at the hospital. But it honestly it was able to teach me that if I hadn't been a founder I don't know if I would have probably would have gone into a despair mode when you are diagnosed with those things. I just like so yeah I definitely do believe and that being a CEO and a founder and entrepreneur has shaped the way I interact with challenges every day. But I bring to them where probably not every day challenges. But you know we're here. Anyone else? Yes? I'm not a data person or a tech person. But I'm curious like when companies are faced with the data that provide them they change and their core practices to be more inclusive. Do you talk a little bit about culture shift being really challenging? Do you think that data helps to create some of that culture shift? So the question is how do business leaders and companies actually react to the data and whether there's a shift in their behaviors? It's different. Some people will focus only on one thing like gender. Other people will want to see more detailed information like our reporting tool is just like literally I pulled the report the other day for a client. I was like this is way too much data but here it is. Like it goes so granular by source, by location, by event, how do they do it? It depends where people want to take that step. But because we learn their behaviors as well over time or recommendations are very different when they start off then when they are at six months into our client. I've seen I've had conversations with some of our clients, ex and current clients around getting their lawyers in earlier in case there's something surface that our tools not very capable of doing. But that we're very, what I like is to be empathetic in the approach is not like hey you're doing this I can't believe you I can't believe what happened in the last three months. It's much more about like why are the tools that you need to change. We saw a lot of women withdraw in sales in an organization and when we actually dived in we realized that the recruiters were putting in compensation at the offer stage but men were actually asked compensation at the technical screen. So we said you might just want to talk about compensation in just the set amount of inclusive. So talk about also questions like instead of saying hey we have free food come and work with us and look at our awesome food think about hey we like to make sure that our employees are nourished that means that we are also very responsible on food waste. There's a woman outside of Atlanta Jasmine Crowe who's doing the gritter she is actually does all about food waste because it actually saves companies millions of dollars through text sort of breaks and so think about all those inclusion components that are important to people nowadays definitely. Other things that we're seeing a lot of is employee activism. So now we're asking our clients to actually ask about what are the things that are important to the candidates earlier on. One more. You mentioned that you saw the majority of bias wasn't coming from the fooders. You can talk a little bit more about where that bias is coming from the hiring process. Yes definitely so where the bias is coming on in the hiring process and the tools. So if anyone here either whether you're technical or not technical if there's a tool that people are giving you for example if you're applying for a business role they might use a tool like a spreadsheet or something like that but that's not very there might be some biases in the way that they present those numbers to different types of groups. For technical a lot of the tools they we tell them to audit the tools because that's where the bias is it's the tools at the earlier stage and it's the people at the later stage specifically hiring managers. So even when candidates get in and they interview in a panel if the hiring manager is asking questions that are not very inclusive we see withdrawals and rejections at a higher rate. It's, it recruiters will do too but we also publish a blog post about again in data engineering and I'll leave it with that. Women with more education and the same experience as a man were actually rejected at the application review so we worked with those recruiters and they the reason that it wasn't knowing tension the reason they were like oh they're too overqualified but if they want to know what I want to work here. I said well you shouldn't make the decision you should ask the candidates. The entrepreneurial thought leader series is a Stanford e-corner original production. The stories and lessons on Stanford e-corner are designed to help you find the courage and clarity to see and seize opportunities. Stanford e-corner is led by the Stanford Technology Ventures Program and Stanford's Department of Management Science and Engineering. To learn more please visit us at ecorner.stanford.edu.