 You are listening to the DFJ Entrepreneurial Thought Leader's series, brought to you weekly by the Stanford Technology Ventures program. You can find podcasts and videos of these lectures online at eCorner.stanford.edu. It's a real pleasure to be introducing a yostee here in the co-founders. Briefly, I'm going to give you the titles of the gentleman sitting to my right here. This is Gunner Carlson, who is also a professor here at Stanford. He holds the Anne and Bill Swindell Professorship in the School of Humanities and Sciences. And this is also Gerjit Singh, who is the CEO of Iostee. To tell you a quick story about Iostee, I met Gerjit back in 2010 and 2009. And he had a friend of ours, a mutual friend of ours had sent me four math papers that Gerjit had written asking, you know, is there a business here? And I just started off my career as a venture capitalist at this point. And I was also simultaneously trying to finish my PhD. So I was in this mode of reading papers and started going through Gerjit's papers and realized that there were some really interesting insights that he had. And I felt like there was a business there. I then met with Gerjit and became further enamored with the business and with him as a founder of a business. And then went on to meet Gunner. And at that moment, I just felt like this was the business that I had to invest in, that no one else was allowed to be a part of this business at the seed stage. And so I managed to chase Gerjit down to a classroom at Stanford and then offered him a check for a million dollars. And he was disciplined enough to say no, because he didn't really know what he was going to do with the money that I would give him. We proceeded to work together for a little while. He would do some customer development, come back and make me even more tantalized with the business. And eventually I wore him down to the point where he would take an investment for me. And since then, I've been so glad to be a part of investing in this company, seeing it grow. But the story here is really one of some real, real amazing technical insights coming to fruition in the form of a company. And especially within this audience of people who have background in math, engineering, the sciences, this story is very much relevant to you. And so I hope that in speaking to Gunner and Gerjit today, you'll get a flavor for what it takes to take some real technical insight and turn it into a company. So to get started, I'd love for you guys to tell us about what is AYASTI? Awesome. So we are, by the way, thank you for inviting us. It's a real pleasure to be here, speaking with everyone. I remember sitting in the audience for pretty much two semesters that was incredible. And I'm just so happy to be able to speak with everyone. AYASTI, so we are trying to solve a pretty big problem. We're trying to solve the problem of turning data into knowledge. So the standard way in which you turn data into knowledge is by this process. So you have a smart analyst. They come up with an idea or a hypothesis. And then they might convert this hypothesis into some sort of query, some sort of code. How they might use some business intelligence software that converts it into a query or a code. You run it against a database and you see the results and maybe you are correct, maybe you are not. And that's the standard process by which we turn large amounts of data into knowledge. And there are a few problems with this process in general. The first problem is people. So usually you need really specialized people who can come up with these hypotheses. They are really complex. If you look at the search volume for the term data scientist, this is of what the Google trends will tell you. In 2011, no one knew what it was in 2013, everyone wants 10. And the other thing about being a data scientist is that you can't drop out of school to become one. You have to have some sort of an advanced degree. You need to know some combination of mathematics, some statistics, and some computer science, and some domain information to be able to become a data scientist. And the second problem with this picture is hypotheses. And if you think about just a very simple tabular setting, hypotheses are essentially a subpart of a large table. And if you think about how many hypotheses exist in a table, it's usually exponential in the number of the size of the table. So there are too many hypotheses. And that's a big problem. But we have developed at AAC, and what are point of view, is to use a much more automated methodology. So we basically take large amounts of data, pump it through many, many hundreds of machine learning algorithms. We're able to combine the results of these algorithms based on our research, bracket Stanford, that we might discuss during this talk. And the first time a person enters a picture, they already have some answers to begin with. So that's the basic idea. Our business is about turning data into knowledge automatically, in close to zero time. Does that make sense? Great. Okay. Well, Gunner, I know that this was a result of a few decades worth of research for you that finally came to fruition here with Niosty. Can you give us a little bit of that history? Sure. So I started out, I'm a mathematician. And for most of my career, I've been a pure mathematician, that is to say, in particular in the area of algebraic topology. I did my PhD here at Stanford, and worked in that area, which is, it's a very old part of the subject. It's also gotten very esoteric to the point where people outside the small area don't always understand what it's about. For my point of view, there was always this idea that we should keep our eyes open for opportunities for using some bits of it, some parts of the subject to try to do something more immediately useful. And so for me, the PhD, I did that in 76, sometime in the mid 90s, that was doing some things in the pure math side. But it looked like maybe this could have some value. In terms of understanding something, understanding a data sets. Now as you probably know, people have ideas and daydream all the time. I do it all the time and never have any follow through on it or often don't have any follow through on it. But fortunately for me, I managed to sort of talk my chair into funding one postdoc for half a year. And so we got a little bit of a start on making this topology, this abstract subject into something more applicable. And then we grew, we got other funding and so I developed it into a much larger project and DARPA project ultimately. And it's from that DARPA project that the spin-off came and it's that project where Gurgit and I work together. And Gurgit, you got your PhD in ICME here at Stanford. Can you tell us a little bit about your path into the PhD program and how you ultimately met Gunner? Yeah, I'll try to do it in five minutes or less. So I grew up in India and I was an electrical engineer there. I used to work at this company called Texas Instruments. And that was good. But I had this sense that if you're in, and I think many engineers might relate to this here. If you're an engineer, you know math, but you know that you don't really know math very well. You can, you know, maybe you can factorize a matrix or something, but that's pretty much the extent of the math that you know. And I had this idea that if I somehow knew more math, then I would be able to do more things in life. And luckily for me, I found this program at Stanford. It was called scientific computing back then. The department changed its name actually recently. And it was a combination of computer science and mathematics and I hedged my bets. I said if I don't do well on the mathematics part, at least there's this computer science, I'm pretty good at that. And so I applied and I got to Stanford with pretty much a quarter's worth of funding that my family sort of took great pains to put together somehow. So my sense was, you know, it's not a big risk I'll land up at Stanford and we'll see what happens. You know, if I'm able to survive and find some way of financing my studies, then that's okay. If not, life was not that bad in India. So I got here and you tell me if I'm allowed to, I guess I'll just say it and then we'll see what happens. Let's go for it. So I got here and I wrote a program to crawl the Stanford website, find out all the professor's email addresses and then spam them saying, I'm this Indian student, I'm here, I can code my way out of many problems. Sign of a great entrepreneur, Sam. And it turned out that over the next couple of weeks, I met with a bunch of professors and there was one in particular in the Aero Astro department, Anthony Jameson, I showed up to his office and he was working on this computational fluid dynamics problem and I didn't know nothing about computational fluid dynamics, right? I could program my way out of pretty much anything but I didn't know anything about computational fluid dynamics. So I showed up and I said, look, I'm this Indian student, I don't have money, you know, I need to sort of work and if you are able to support my education, that'll be pretty awesome. So he said, you know, he proceeded to ask me like a million questions over the next hour about computational fluid dynamics and of course I knew nothing. So I kind of just interview, I'm sitting there with him and he's like, so you don't know much about computational fluid dynamics. I get that you can code and you know how the whole thing is going to work out. And I had an idea that I was working on at TI back in India, which was around using clusters of DSPs to pull together a supercomputing capability that you could put under your desk. Because in computational fluid dynamics, you pretty much solve very simple problems over and over again. And so I proposed, look, I don't know much about CFD but I know enough that, you know, it's a numerically simple problem that you just need scale to be able to solve. So I pitched that and he said, okay, so he, you know, I agreed, he agreed to sort of work with me and that's how we basically stayed here for the first year. We took it to, after we were done, you know, building a prototype and some research, we basically took it to Boeing Phantom Works and you know, we met with the CEO and we said, look, this is really great. You spend all this time acquiring, acquiring computational resources which are expensive. And this way you will sort of enable all of your engineers to run simulations very quickly. So you should finance some research here. And we got told, you know, you can't really do it even though we had a bit of a prototype. So I was basically out on the street again. Then I basically started working with Eric Darwin, the mechanical department and it was a similar idea except it was not computational fluid dynamics anymore. It was computational mechanics and right around the time GPUs were becoming available and their computing power was becoming apparent. So we started, I started using those. So we took it to NSF after about a year and NSF was like, you already have it working, why do you need money? So I was basically out of financing after another year. Around the same time I saw an email from Andrew Ing in the computer science department. And he had this program to build a four-legged autonomous robot. And I was pretty good at robotics. That was something I had a passion in mind. So I basically started working with Andrew. We built a prototype of this four-legged robot. It did really well actually that worked out pretty nicely. But Andrew didn't really like me. So I guess he threw me out after about a year. Around the same time I saw an email from Gunner and he was talking about using algebraic topology to understand large complex data sets. And in his note, he was talking about using the same core set of ideas across many, many disciplines. In vision, in computer vision, in neuroscience, in cancer research, in protein folding. And that was really exciting to me because it was a new area of mathematics and you nothing about sort of satisfying my math geekiness there. And in machine learning, in working with Andrew, what I had realized was that to solve every problem, you basically had to reinvent the wheel. If you were going to solve a vision problem, you were going to have to learn about image processing and keyboard filters and wave-light transforms and so on. If you're going to solve a locomotion problem, then you had to go learn about locomotion and inverse kinematics and so on. And here I saw this note from Gunner, which was about using the same core set of ideas across many fields. So I wrote to Gunner and I was pretty lucky that he agreed to take me as a student. For the next year and a half, I basically ate his head off asking the same questions over and over again. And anyway, that's sort of my story into the ICME program. So Gunner, you take a three-time failed grad student into your lab and you basically adopt this orphan grad student. What was different about Gurgit? So what's he different? First of all, let me say that Gurgit has misrepresented the interaction that we had in that first year and a half. Actually, I don't agree that he knew nothing at all. In fact, he was absolutely one of the very sharpest students that I've seen. But you see many sharp, smart students around Stanford and other universities. But there's another aspect to things, which is not only do you need to be smart, but you need to want to do something and to carry something out and to actually solve a problem, as opposed to writing a paper or finding a pretty piece of theory. And that's what I saw with Gurgit, because I started talking about these ideas, which I'm a mathematician. They're sort of only formed to a certain extent. And Gurgit got them right away and then said, furthermore, I want to implement this. And not only that, he'd come back in two days and there'd be some kind of prototype going. And so I found extremely impressive. And to me, it's something that I've now understood after the fact in pure math, that stuff doesn't apply somehow. In pure math, you're just trying to do something clever. Someone's clever, they'll do whatever they can do. But now when I look at students, I think about a lot of different aspects of what they do. Yes, they can be smart theoretically. But also, it needs to be, yes, I want to do something. I want to do it quickly. I want to prototype. Maybe very rough and ready prototyping. Let's just get out and see how this theory works a little bit in some simple situations. And that's the thing that's, for my point of view, it's often missing on the math side. And other sciences, we want to build up the science in a very pretty and systematic way. But without checking at the end, whether things are going to actually work and do something. So what I would say is the better idea might be to, let's do a little bit of theory, just make some guesses at it. And then let's try to see, does it actually work or does it get close to working or does it capture anything that we're trying to capture? Well, that's interesting. I mean, in electrical engineering, computer science, particularly at Stanford, you see a lot of startup companies coming out at the undergrad level, at the graduate level. What do you think it is about math, or the sciences that have prevented them from really doing that? Yeah, well, so one of the things you should understand about, and I'll speak about mathematics itself, the core way that you value contributions in mathematics is often how hard is it? How technically deep is it? And I think in some of the engineering disciplines, that may be a part of it, but the other part is more directly goal oriented than saying, what can it do for me? Even if it's a simple bit of theory or a simple bit of math, if it's useful, let's go do it. And so I think that that is a situation in there that sometimes we tend to value scientific research the way we would athletics, that is to say, how powerful are you? What kind of tough calculations can you carry out, or what kind of heavy duty theory can you do? I think that's going to change, actually, I think you're kind of even seeing it now in some of the math places. People are getting a bit more opportunistic. And the thing I think about math is that although we've got this way of evaluating things, there's a huge amount of available math out there where one can take rather simple bits of it and try to apply it to a lot of different situations. And people usually don't because the subject is esoteric, so there's only a few number of people who can recognize the opportunities. Well then, how did you- Just like to be fair, is that for all the budding entrepreneurs in the room, there's a bunch of low-hanging fruit in math. It's worth you spending some time trying to fish it out. And well, Gutter, then how did you get from this state where in your department, it's very unusual for someone to go from this theoretical idea to something that's a little bit more applied and starting a company? How did you traverse that journey? Well, it's interesting. So, you know, again, my starting point was very theoretical math even in my teens as an undergraduate. I did have a father who whenever I would come home for Christmas or holidays, he'd ask me what I was doing and then he said, and what are you going to do with that? What's the good of that? I'm sure no one in the room has ever had that experience before, right? But so he would do that. So it kind of made me sensitive to it. I was also sort of fortunate to have a friend from graduate school, you know, contemporary of mine who's a co-founder of ours, Harlan Sexton, who, after he did his PhD, he went off and worked in Navy Labs and then ultimately in software startups and finally at Oracle. And so we had a lot of contact and we would talk back and forth. So he kind of knew the math and we kind of tried to figure out, you know, is there something that we can do? And we did some fun work, interesting, even useful work with, you know, certain kinds of communication networks back in San Diego when I was there and so on. And so he was sort of natural for me to get in touch with when we were starting to form this company. He had influences in your life. He had influences, yeah, that's right. Did you ever feel amongst your colleagues or from the other people within either your department or your surrounding area where you felt like kind of a sell out for heading in that direction and starting a company? Yeah, well let me talk. So actually I have to say not really. No, I was kind of anticipating feeling that but no, they've been pretty appreciative of it. I think people have enjoyed it and liked it. They liked the fact that it's out there. But the other thing I would say is that of course it's not actually being a sell out. In my view it's kind of like this, there's a whole spectrum where you start, you know, on the one end is the theory and on the other end is the actual application. And you know, you can choose to work on the theory end here and maybe move a little bit in the applied direction and then when you've done something that looks like it could be published in an applied journal you can declare victory and say, now I've done an application and you go back and do theory and so forth. The other point of view you could take is actually I'm not going to insist that the math be, you know, the most colossally difficult. But I am going to insist that there be something useful. So I start off on this side and I say, look, can I do some simple testing things and then gradually grow the sophistication of the math that I applied to it. And I think that's that second part, that realization of that, that I find, you know, is pretty powerful. It's kind of like you want to just, you want to be able to prototype things quickly and and try things against actual applications. Can you give us a quick understanding of what topology is? Yeah. So topology is the part of mathematics that deals with trying to describe and represent shape. In fact, it's actually a form of pattern recognition. So it was started in the 1700s by a Swiss mathematician, Leonard Euler. And it's actually thrived on the pure math side. What it does is it actually introduces invariance that allow you to measure shape. So measuring shape is sort of a, that's a funny sounding concept because shape to me is kind of a, it's an ill-formed or a kind of a vague notion. And so the idea of measuring it with numbers, you know, is a little counterintuitive. But it turns out that there are ways of doing that. Actually very, you know, very interesting and powerful ways of doing that. The second part of it though is, and I don't think it's usually talked about this way, but topology is about compressing shape. It is about finding, if you think of a circle, for example, a circle is infinitely many points and infinitely many pairwise distances between those points. Now if you're willing to sacrifice a little bit of detail, like the exact nature and so on, you can represent it by say a hexagon or an octagon, which is, you know, say eight nodes and eight edges, which, you know, can be represented in a single bite. I mean, so it's very, very simple. And that notion of trying to sort of combinatorially compress the notion of shape into, into something much more understandable is the second thing that topology is about. And so in this area, what's, what happens starting in about the year 2000, you know, a lot of people started to have this idea that we should say these techniques in topology, which are about pattern recognition and representing shapes and sort of getting at, getting really precise about what, what means by shapes, should now be transported from the pure math world, where you're dealing with things where you have complete information. You know, you have all the points, sort of, you know, or your, or your description in terms of equations, to something where you only have sampled information, which is really more like real life. And so that's what's been going on in the last 15 years, porting all those techniques from understanding shapes. And I mean, here even higher dimensional notions of shape, not just two and three dimensions, porting them into what we will call the point cloud world, which is data, which is where data lives. Great. Now, so then, Gergie, take us through then the history of that going from this four sets of papers, sets of papers that you've written that are more mathematical in nature. And how does that turn into the notion that you're going to build a company? Yeah, absolutely. So just sort of to back up, right, as Gunner said, around the year 2000 or so, actually DARPA and NSF realized that the way people did science had changed. They realized that people had started doing science by creating new large complex data sets, right, as opposed to the past where people would create conformatory data sets, people had started creating exploratory data sets. And new science would happen when they discovered something new from those exploratory data sets. And so they had this idea that people who were doing the best science or creating the best data sets were probably not the best people to analyze those data sets. They felt that they might draw incomplete or incorrect conclusions. And so they sort of wanted to find a brute force way of approaching this problem. They said, could you compute your way out of this problem? And so to that end, they started financing research efforts in fundamental mathematics. And topological data analysis, the research that we were involved in was one such effort. So academically, as Ann pointed out, we were very successful based on the same course set of ideas we published in areas as broad as image compression to neuroscience, to cancer research to protein folding. And so by the time we were done with the research, we were pretty certain that we could actually have a meaningful impact in the world, right? We knew that the sort of the process of taking a more automated approach to taking large sets of data and converting it into insights would have a lot of value. And we knew that we did not want to do it within academia. So we published all of our research, left Stanford, at least I did, with the Harlem or other co-founder, and we started building IASC. And when we started out in 2008, we did not have a product, right? So we had all this research. And it was a challenge to see where might we apply this research. So basically for the next two and a half years, we did not grow the company significantly, right? We were still, we remained as small as possible. And I met Ann during the, during our first, I guess, second year of operations in 2009, because at one point, the three of us basically, you know, we had the decision as to who's going to be the CEO. And no one wanted to be it. So I guess I was stuck being the CEO. And I realized that I knew nothing about running a company. So I started taking the Stanford ETL lectures. You should pay attention. It actually helps. And we took a class by Steve Blank, which was talking about entrepreneurship. That's how I met Ann. And what Steve Blank, the one thing that he said which stuck with us was basically get out of the building. And as soon as we had a prototype ready, we got out of the building. So I wrote another program to spam, Stanford alumni at this time. We went out and met with anyone in a business setting who would take a meeting with us. So over about a three month period, we met with some 40 or 50 art people in a large number of industries and got thrown out of roughly half the offices. And to their credit, actually, you know, those people that we would go meet, we were not the best at explaining what we did. And so we would go into these meetings and talk about a bunch of math and people wouldn't get anything. And the other half of the meetings were very significant because we came back with a prioritized list of use cases and people would say, oh, if only you could make this work for this problem in my organization. It's going to be worth this much. This is what I spent. These are the resources. And after like three months worth of searching, we had a long list of use cases. So I remember there was one point where someone said, wow, you know, I'll write you $50,000 or check if you'll just give it to me right now. And the point where from a venture capitalist perspective, you start frobbing at the mouth is, Gerjit said, I think this is worth far more than $50,000. And then he left the room. Yep. In fact, that contact, I actually had met after an ETL lecture. So your customer may be in the room. Yeah. So at that point, I went back to Anne. We said, look, we've had a lot of fun working with you. I've learned a lot. I certainly learned quite a bit from Anne. And at this point, we are ready to actually start pouring some resources into the company and growing it. I know what to do at this point. But to your credit, it wasn't just theoretical. There are a few example cases that you had actually created. Absolutely. And so can you tell the audience a little bit more around what were some of the use cases that you showed, those to me and to these people that you were talking to, so that you could show the power of what this math could be. Absolutely. So we had built a few use cases. One of the big ones was in the pharmaceuticals around drug discovery. So we noticed that pretty much every biotech or pharmaceutical company at some point or the other ends of dealing with this type of data called gene expression data. And the problem that they're struggling with there is it has a small number of samples, very high number of dimensions. And you want to discover information from it. You want to discover subgroups, you want to just say what defines these subgroups and so on. And our software did that pretty naturally. So that was one of the use cases. In fact, that was the meeting we walked out of. It was a biotech company in the area. And they said, look, this is great. We would like to buy here's $50,000. And your GTS actually being quite modest here because some of the use cases that I saw, were cases where people would say, this used to take us 18 months, 24 months to actually perform this exact kind of analysis. The knowledge that you gain from our data set in a day or less than a day was something that used to take us 18 to 24 months. And so that degree of difference in terms of impact that you're having was pretty tremendous. Absolutely. And that's why we walked away from 50K. I did the math. I said, it saves you 24 months of work. There's probably four people working on it. And you pay me 50K. That doesn't add up. So we had other examples in the financial industry in which you could take sort of index data and you could predict the microstructure of the market as it's evolving. We had other examples in carbon capture of all things. How do you design a molecule that can capture a lot of carbon dioxide computationally? So these were some of the key examples that we would sort of show in these meetings. How did you think about when to take venture financing? Because I mean, it felt at least for my end you were being very thoughtful about it. Most people that I approach with a million dollar check bills, they sure all take that. But for you, you were one of the first people that ever said to me, well no, I can't take it right now. So what was the impetus or what were you looking for before you actually went out for venture financing? So for me, I have a very scientific approach. So for any action, you should be able to say what you're going to do with it. So the first time when we met after the class, I had, you know, I did not know how I would accelerate what we were doing at IASC with more money. Like more money did not equal more success at that point in time. And after we had these meetings and we had these start as use cases, at that point, the equation was particularly clear. You use more money, develop the product, the output's are clear. So that was for me, it was a very structured way of approaching this problem and saying, if we were to take this action at this point in time, then this would result in these outcomes. So that was my thought process in approaching. And to Anne's credit, actually, when we approached Anne for financing, she was like, you know, you don't know much about venture capital and running a company, you should go meet with a bunch of other VCs. So that was also, that was a very fun time meeting with a bunch of VCs, getting perspective and just applying here for floodgates, they give awesome deals. Yeah. I paid him to say that. Literally. Literally. Well, so big data has gotten a lot of hype, right? And AYASD clearly fits into that sector in some way. So what's wrong with the term big data or is there something wrong with the terms big data? And how do you describe that market? Yeah. So big data in my mind is a meaningless term, right? It has, I'll give you an example. I met someone at a party recently and this guy was building a small business in which they would approach big companies and make product videos. And he was trying to raise financing. And so he was picking my brain as to how do you go about it. And he said, I have an idea. I think I should raise it, like I should spin it as a big data company and then I'd be able to raise financing. And so I say, how is this a big data company? He said, well, video files, they are pretty large. It's like, I think this whole big data thing is at a stage where you go to an investor and you just whisper big data and they might give you some money. Right? So it's a meaningless term, right? I think the far reaching impact of this movement, I don't think there's a name for it yet, is pretty large actually. And I draw my inspiration from science fiction. I grew up reading an out of science fiction. And if you read enough science fiction, you see two types of futures that our species seems to have imagined. There is a one type of future in which everyone kills themselves and either the technology runs them or people are just not that great. And then that's not very interesting. There is this other type of future in which it's a post abundance world in which you have free time and a lot of work is taken care of the machines and people basically just contemplate the universe. And in that future, you don't see people writing SQL queries or you don't see people using business intelligence and software. You see a world in which autonomous systems deal with large teams of data and inform your life to make it better, to make it better. And I believe that's what we can achieve with data. I don't believe that big data in itself actually is trying to achieve it. Big data is just database. We were trying to sell more database software. Where does topology then fit into that? I think so from my perspective, topology is something that allows us to marry a very, it allows us to take a very computational approach. It allows us to build autonomous systems with much more ease than previously possible. And that said though, there is still a lot of work. What we are doing at ASC is still just the tip of the iceberg and we have had a lot of success doing what we do. What are some use cases that you're most proud of today? That's funny, you should ask. We are, I can show you a few. So this is a use case from a bank. And the idea here is that every, this is a network in the computer science sense and that there are nodes and there are edges. These networks are created automatically without ad hoc parameter selection or anything of that sort. Every node in this network is a compression in the sense that it's a group of transactions that are similar across a bunch of characteristics. And two nodes are connected if they actually share some transactions. So you can think of this network as a giant wind diagram, that's what it is. So in this example, one of the big problems with financial systems is fraud. And detecting fraud, you would be surprised if you go into a large company, they will have hundreds of thousands of rules to sort of that are built manually over a long period of time to flag possible fraud. So in this example, we basically took a bunch of transaction data and the idea was could be automatically detect the failure of the rules engine. And the regions which look, which are colored red in this picture, basically show you those regions. Another example, this is from a hospital, it's a triage model. So if you, someone walks into an ER, usually the practitioner will go over a small set of questions to try and assign you a score. And the score is supposed to be, so is supposed to say, are you going to do well or do you need urgent care right now immediately. So on the top is basically this network in which every node is a group of patients and they are grouped together based on their similarity across all these cores. And what you can see is the color of this network shows the predicted value for what's going to happen. So blue is good and red is not that great. While if you actually color it by what actually happens, that's a picture below it, it turns out that there are systematic problems in this predictor model that's trying to predict what's going to happen with people. And in fact, there is a population that circle there which contains people that the predictor originally said are going to be okay, but actually, they don't end up doing all that well. And the last thing in this case is giving you a map of that data. That's correct. And it turns out that these people were the people who were too groggy to fill out the from properly, properly right. So they just didn't, they were not able to answer some of the questions. That should have been a feature that goes into building that predictor. Another example, this is also from a hospital. So hospital administrators have this problem that under Obamacare, if a patient walks into the hospital, they get treated. But then if they are re-admitted in short order, then the hospital doesn't really get compensated in Medicare. Is that Medicare? Well, it could be Medicare, but it's also other insurances. Right. And so from an administration perspective, they want to be able to figure out what are the characteristics of doctors and what makes a successful doctor in this hospital system. And so what we find, the reason that's highlighted there are basically two groups of doctors that are very distinct in their patterns. They operate very distinctly for the same disease. And both of them give very high prescriptions. Now I can't disclose the details as to what happened here and why it's just because of confidentiality. But this is one of those insights that has worth $100 million dollars to a hospital. Great. So after seeing some of these use cases, so it's pretty convincing. The product is pretty interesting. But what about the difference between being an academic, which you both were, to then running a company, building a company? Are they similar? Are they wildly different? How would you characterize them? Well, they're wildly different. But in a very interesting way, I found that a great experience to sort of find out what running a company is like. But I would say that the difference is a little bit, is the following. In academics, you're allowed to pick and choose the problems that you work with. So you can deal with the problems that you can find clever solutions for and publish them. And that's very valuable because there's information out there about what works and what doesn't. But in terms of the company, no one cares about how hard or how interesting the underlying technology is, it has to solve problems. So you're forced to get much more focused about what you do. And I think that's the biggest difference. But then that's been very instructive and very interesting for me to find out. I think one thing that I would add there is, if you, at least in the venture capital world and in the world of startups, academic is almost a pejorative. Would you agree? And that's really weird. Your technology in search of a problem. Yeah. But you're certainly that. And a lot of companies that start with a bunch of research are like that. You have a solution and you might not actually know the exact problem. So you might actually have to go out and find the problem. And that's okay, right? If you take a scientific approach and you're a rational person and you're not sort of married to your only one idea that you had in the early on, then things can work out. It's actually okay to have a solution and then search for a problem. It can be made to work. Great. Why don't we spend some time taking questions from the audience then? Yes. Yes. Hi. Thank you for the talk. I was wondering if you could elaborate a little bit more in the process of getting people to share their data with you. And what are some of the caveats and recommendations that you would give if we would try to do the same thing? So the question is, what is the process by which you get people to share their data with you? So look what we did, which really worked very well for us as we basically went out and got as much public data as we could get our hands on. So that basically allowed us to demonstrate the power of our software without needing someone's private data. And we also operate a, roughly half our customers are cloud-based. We operate a cloud-based service and roughly half our customers are on-premise. So for the cloud-based customers, when we first went into pharmaceutical companies, the average cost of our data set in pharmaceuticals is in the half a million dollar range. So it's really expensive data. And they were not ready to part with it. And so we said, here's some public data. Just go play with the software. You already paid. Just play with the software. And if you like it, then we'll talk. And within three days, people were uploading their own data. So that was a trick that we followed. I would say also on the academic side, an approach there where there's not commercial interest is to offer to collaborate. That is to say, people don't like to say, well, send me your data and I'm going to do some analysis on it and then I'm going to publish it. But if we say, actually we'd like to work with you and see if we can apply our techniques if you can get something new out of it, people are usually pretty open to that. So you talked about the case of fraud in the banking system by the customer. The government aimed the software at the bankers to find the fraud that they got institutionally that they're not even aware of. The question is, detection of fraud within the banking system, have we pointed it actually at the banks to figure out what fraud they're committing? We have not. Some of our government customers are contemplating doing that. But in some sense, we don't have any control over that. We have not looked at that ourselves. I think you have that. Yes. I have a little bit about your graduate work, some of the hard renovations that you worked on, so FPGA's. And then in the talk, you talked a little bit about some of software innovations. Would you say, is Iosd a mix of software and hardware innovations and in particular, what hardware innovations have you? So the question is, in terms of Iosd, is the innovation coming from the hardware or the software or combination of both? We chose to be a purely software oriented solution. And the reason for that is because we, so when we started out, we didn't know if we would be completely cloud based, that was a primary motivation, but we were not sure whether it would be on premise. And if you are going to sell custom hardware for on premise customers, the type of compliance problems that you get into are not worth dealing with. At this point, when we have an established footprint and the company is growing nicely, at this point, we are actually investing in some hardware innovations. But even at this point, it's mostly using GPUs and using computer, upload cards like FI and so on. We are not building our own FPGA based solvers on anything of that sort. So just to take a step back from the technology set of things, I was curious when you are dealing with a clientele that's so diverse from hospitals to banks. As a company, when you think about how you want to progress and develop, how do you take into account the needs of such a diverse, raised clients? And then, I guess, in a sense, determine what trajectory by which you want to grow the company and develop the company? The question is that Iosd is actually targeted a variety of different verticals from financial services to pharma. And so how do you actually take into account the needs of all these different types of customers to really focus the company as well? So we raised our series of financing from Coastal Avengers. And Vinod Coastalized, someone that we worked with pretty closely, one of the pieces of advice that he gave me early on. He said that anytime you have a technology that's applicable across a lot of verticals, many companies make the mistake of choosing a path very, you know, too early. So he said, you should go around the roundabout a few times before you figure out which path you want to take. So last year, we actually did not care about the vertical at all. If you would go into any vertical, we would talk to them, you know, if you would see if our technology was applicable or not, our price points are pretty high. So you know, that tends to be a very good filter. This year, going into this year, we have learned a whole lot about where the sales cycles are shorter, you know, where our marketing is clear and so on. So we are spending roughly 80% of our efforts in the verticals that we've learned about. And only 20% of our efforts sort of scotting around. Yes. So I have a question that, you know, the big case, Bernie Mado, who we thought a lot about in this country for almost 30 years, and nobody knows about it until 2008. And suddenly he ran out money. And I follow it very carefully. And the SEC sent people to this office numbers of time to check the record. But the SEC still couldn't find it until he couldn't find it at all until he admitted. And now the court came out and his people said, how did it fall even though SEC come into the office and they have practically changed all of the fake numbers to be fought this whole country for almost 30 billion dollars. So I wonder now with your blessing of your software, could we prevent this thing in the future for everyone? You know, this case, Bernie Mado? Yeah. So hopefully the SEC will come to you and bless you with lots of revenues. Yes. I don't know. So we all have to offer. That's right. Very sense. So it's a very difficult question to answer, definitely. Right? So the question was, take a case like Bernie made off and whether or not a company like Ayausti and the software therein can actually prevent something like that from happening again. Yeah. So like I said, the answer is that it's very difficult to say definitively that it really depends on the traces that they leave in data. It's certainly possible. I mean, certainly in our interactions with the financial community, whenever they've used our software to look at large sets of data, they've actually found interesting things in every case. Right? And looking for anti-money laundering and looking for fraud and looking for patterns of organizations in general from the government side. So it is very, it's possible, but I can't say it's a 100% guarantee. So I'm going to, you know, I'm a PhD in engineering. And so I'm one of the people who always looked over at the math side and knew that I didn't know as much math as they did. And so for my simplistic point of view, when I look at what Ayausti does and the power of what they do relative to questions like Bernie made off and data analysis that's been done in the past, the power of what Ayausti is doing the magic therein is that it removes a lot of the human components of data analysis. Right? So a lot of times when you see the flaw in what's happened in the past in data analysis, it's because a person got involved and decided that certain parts of the data set weren't relevant or they decided to use a certain algorithm on analyzing that data set. And Ayausti is essentially removing those two elements. They're allowing all sorts of algorithms to be tested across the board. Plus, it's allowing more of that data to pass through that analysis. And the power of that is that a lot of times what we've seen in the past, the problems have emerged because people got involved. And the more you are able to use mathematics to then allow us to understand which algorithms do actually work best and get rid of the notion that there is bad data. There's a real magic in what happens on the analysis side. That's the investor point of view. Yes, back there. Are you planning on releasing anything that we can use that's free, that's open source or a question? Are you planning on releasing anything that's free or open source that we might be able to use? So there is already a free and open source set of software that's available on the Stanford website. It's not quite as powerful as what we have developed at Ayausti, but it has all the basics of what we do. If you search for, I'm trying to, by mapper. Maybe, yeah. Yeah, I can, if you follow up with me, I can tell you where to find it, but it'll get you started at least. Back there in the blue. So if you were to receive, maybe like hundreds and thousands of documents, not necessarily tag, some have numbers and numbers and others don't. And let's say they were all describing the particular industry. What kind of knowledge would Ayausti be able to get out of this? Like would I be able to answer, would I be able to answer, okay, here are one of the big opportunities in this industry are, and would I have to go through the data and really start editing people, like tagging these documents, like what I would say. It's text data, maybe someone has charts. So the question is, you have a bunch of data that might be text, that sort of industry based, is that correct? Maybe it's industry based, maybe it's a particular area. Can you like, is it, can Ayausti summarize it and answer specific data? Can Ayausti summarize and analyze this data? Absolutely, so funny you should ask, in one of our, one of our early customers was the company, the pharmaceutical company. And we were in a meeting at work at one point in time, and there was a lawyer in the meeting who happened to be in the wrong room. But the presentation was visually interesting, so we ended up staying for the whole, for the whole presentation. At the end of the presentation, he walked up to me and he said, look, this is all great for our drug discovery programs. But I have 40 lawyers who work for me and we spend all of our time on Google patents. Trying to search for patents, I click next, see another 10 patents, click next, see another 10 patents. And wouldn't it be great if somehow your technology was able to summarize all of that, all of that work and people could easily sort of understand what was going on in all the patents, all advance. And you know, we came back and we shared the feedback with the team and one of our engineers, I think his girlfriend was away over the weekend or something, right? So he basically, he built up prototype, which is what this is. It's a search tool for patent spaces. So you search for something, it pulls out all the patents from the US patent database and it organizes them into this summarized form. Every node here is a group of patents that are similar to each other textually. And I'm not sure if you can see, they're probably too small to see, but there are labels on the visualization itself, which summarizes sort of what those patents are all about. So a flare here might contain patents about the display of images on the computer screen. Another region might contain patents around the interaction of a mouse with a window on a computer screen and so on. So this is exactly what this does. A lot of our government customers use similar capabilities for large corporate off-text. One final question. Yes. Yes. Talk about Yosti's work in treating disease specifically for cancer. I've read out some words that you've had in the past. So this is the question is, what is a Yosti done in mapping cancer? That's a great question. I also have a great story behind it. So right, in one of our 60 or 70 odd meetings with people in the industry, we had met with Anne and Anne sort of had sent us around, go meet with other VCs and get some perspective. So one of the VCs that we met, more David Owl, they basically said, this is a great piece of technology. We would like some deeper diligence. So they basically had us meet with this lady. Her name is Peck and I met with her in downtown Paul Orton in for NIO and I was showing her some work that we had done on breast cancer at Stanford and half a through the, I'm not a biologist, I'm a mathematician computer science out of a guy. So half a through the meeting she stops me and says, you know, this is great, but you don't know why this is great. So she basically stopped me and proceeded to lecture me for the next half an hour about the specifics of cancer research and how this was great. And we ended up publishing that work. It's out in the open now. But in general, our work in drug discovery, a lot of our work with our commercial customers is around drug discovery for oncology. And the problem there is that it's a very difficult disease and the way, obviously, and the way people approach that today is sort of very hypothesis oriented. I do would be scared if I told you the number of people who use Excel to research cancer. And that's not a good thing. So a lot of our customers actually do use our software for drug discovery and the idea is basically understanding subpopulations, you know, the genetic causes of why they are different. And constructing diagnostics. Does that answer your question? I think he's underselling it. So what he showed actually in that demo, I actually saw it as well, was that you could actually see spots of patients who had had a certain kind of breast cancer where they were told that they would die within a relatively short period of time. And for some unknown reason, they actually survived. But though that set of breast cancer tumors were actually quite close to people who did pass away relatively quickly. And so that begs this question, okay, if they're actually fairly similar, is there a way of turning the more fatal version of that tumor into the one where you can actually survive? So there's some really interesting questions in there that I thought were pretty powerful that Gerjita's glossing over here. But like there are some really interesting questions that you can actually now pose as a result of this type of analysis. And then the last thing I would just say is, and Tina's creeping up here on me, but this is a story of one of her students. So in Mayfield Fellows Program, we convinced one of the students to actually do a summer internship at Ayosti. And in that period, he did this great analysis on basketball athletes and the data set therein. And through this summer internship, he discovered there's 13 different positions, not just five. He presents this at MIT at some athletics forum. And as a result of that, he's now in the 30 under 30 list on In Forbes magazine. Two years running. For two years running, not in high tech and being analytical or the fact that he's at med school, but rather in sports. Right there next to lots of sports athletes whose names I don't know, but I know they're very famous. So I've been telling all my students who really want to be athletic. Well, if you really want to be in that list, you don't have to go and do sports. You don't have to be athletic. You just need to be really good at math. On that note, let's thank our incredible guest. You have been listening to the Draper Fisher-Jurvis and entrepreneurial thought leader series, brought to you weekly by the Stanford Technologies Entries Program. You can find additional podcasts and videos of these lectures online at eCorner.stanford.edu.