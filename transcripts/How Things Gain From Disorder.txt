 You are listening to the DFJ Entrepreneurial Thought Leader Series. Brought to you weekly by the Stanford Technology Ventures Program. You can find podcasts and videos of these lectures online at eCorner.stanford.edu. Today's speaker is a wonderfully special guest to Stanford. He came to us from New York, but he's been flying all over the world. Now, Seem Teleb is a, with a trader on Wall Street, where he spent 21 years really understanding the financial markets. And then he became a scholar. He has written three books. Is it three books? Yeah, five books. Five books. OK, sorry. Five books. The ones I know about are fooled by randomness, the black swan, and anti-fragile. These books have been translated into 33 different languages. He has been considered one of the hottest thinkers in the world. Please join me in a warm welcome for Nassim. OK. Thank you very much. Thanks a lot. So I'm going to be this lecture corresponds to book four of anti-fragile. So I've written a book that has different sections. The principle one at the end is about ethics. And there's one on optionality. I'm going to be talking about as innovation as optionality. I have to explain one option is what innovation is. All that was in, I guess, 45 minutes. And then it can take questions. But please, during the Q&A, at a respect for the other person, don't make a lecture because it takes time away from the other person who wants to ask another question. So the next 45 minutes, I'm going to be reading from page 423 to page 485. Is it okay with you? So of the book. And then you can ask questions. OK. So page 420. OK, I'll do something else. So let me give you my sort of biographical story and my obsession with what I call fat tails. To explain fat tails. What you have here is the performance of an option portfolio, the variation in price of an option portfolio, daily variation, over 57 years. So all of the money options, options that are remote. It's about 12,000 days, something like that, 14,000 days. And as you can see, there's a big spike. For that portfolio, that day represents depends on what you've been doing. Between 80 and 99% of your total lifetime variation. If you're an option trader one day in your life, should represent 98% of the variation if you're involved in remote payoffs. This in other words is what I call fat tails. And this is, of course, if you don't get that day right, you're not going to get anything right. And it's not predictable. They tell you it's predictable. If you go to a finance building, they think it's predictable. If you go to economics buildings that convince it's predictable, it is not predictable. So that's the problem. That there are events that have a huge impact. And we can't tell how the time when they're going to come. And we have no idea about the structure. And people fool themselves thinking they have an idea about the structure. So you have to understand what domains are affected by these large deviations. And also, I don't know if someone here is from Brooklyn, but in Brooklyn they say that you should make lemonade every time someone gives you a lemon. So you've got to make lemonade out of it. So this is the idea that we have, there's a huge amount of these events, the rare event, representing a large share of the pie. Now you live here at the epicenter of rare events. Google represent this spike in its own business. Microsoft, on Microsoft, was Microsoft. It's still Microsoft, but even more Microsoft than it is today. There was 50,000 computer companies, and it had more than half the sales in that segment. If you take the stock market over the past 100 years, a lot of companies joined, a lot of companies left. There are about 12,000 surviving companies that are listed. Of these 12,000 companies, how many companies represent half the capitalization? What do you think? Sorry? Well, when I was trading some years, it was 50 to 100. Some years, it was 300 to 400. There's no structure. Another example, for example, is a book business. I don't know if you know about the book business. There are a million manuscripts in the English language on the market today by people who call themselves writers. But typically, in the US, they work for Starbucks. In Europe, they do other things. They work for the government. So they call themselves writers their novels. Of the million novels, literary novels, about 20,000 would be published. Of these, half the sales would come from how many books? 20%. Sorry? 20%. No, between five and 15. Some years less than five. It's not 20%. It's very, really. We are in what I call extremist at. So let me give you an idea of what is extremist at? If I can figure out how to work this computer, if you imagine that you have a convention here and you bring in a random selection of people from the planet, 1,000 people, bring them to Stanford, nice weather. This is a great way to convince people to come. And put them on a scale. You weigh them. You add to that sample the heaviest person you can find on a planet who can still be called a person. How much of the total of that person represent? Sorry? OK, so this is three times the average, as we say in finance, 30 basis points, 0.3%. And if you move from 1,000 to 1,000, how much will that person represent? Nothing, three basis points. OK, so the maximum you can get will affect your average very little. This is commonly known as the law of what? Large numbers. About everything you do, the statistically basis is based on that law. That as your sample becomes larger, no deviation is going to mess up things for you. You agree? I eat, I don't know, I consume 800,000 calories a year. Not a single day is going to make me double my weight. Thank God. But unfortunately, not a single day will make me lose half my weight unless I have surgery. So the problem is that, but in finance, can you lose half your fortune in one day? Of course, when I became a pit traitor, there's a walk then. There's something called new member, a badge. Means rookie. So you get abused by all traders who are bored, want to give someone life advice for life, so they grab you. So one guy, he come over here, kiddo. He said, OK, I showed up. He said, that was before this event incidentally. He said, listen, you see the guy over there? He said, yes. He said, his name is Ed. He said, yes. He said, at a time, there was a lot of money. He made $7 million in seven years. He said, yes. He lost them all in seven seconds. OK, kiddo, now you can go. That was his advice that you can, you know, that your extreme is standard. The reasoning is different. So everything is moved by extreme in economic life. And visibly, you're here for that to understand that point. And we're going to take it to its conclusion. And extreme is standard. OK, things are unpredictable. And mediocre standard, you can predict things. All right? So that's point number one. Unpredictability is a problem in, of course, in the real world, unlike the textbooks. I've seen, I guess you've seen this before. You recognize this item? This is commonly known as what? A wheel. What was it discovered? Sorry, long time ago. How long ago? But at least 6,000 years ago, all right? Babylonian technology, all right? So this is technology. So let's see, moving from this technology to this technology, you guys are too young to remember the days when it had to carry our luggage because then have wheel. How long did it take 6,000 years to discover? All right? OK? So you realize that there is unpredictability. Not only that, but now we're going to look at something else, there are domains that are entirely dominated by the unpredictable. Medical discovery, for example, entirely dominated by the rare event. They don't know it. And we're going to talk now about luck with a caveat. It's not really luck. It's a function of luck. How to exploit luck by which you get more upside than downside of luck. So the idea is you know what this is, windmill. The two approaches in life. The first one is that you hear that there are going to be winds. And the conservative attitude is to build what a wall, to protect oneself from the wind. A better attitude is to build windmills, if you hear that well. So the idea is to milk uncertainty and try to exploit the sort of. But before getting there, we're going to have a little excursion into what I call fragility. There's something interesting that I discovered that took me about 21 years to figure out. 21 years, I was an option trader for 21 years, and didn't realize something I knew unconsciously, but only became conscious of it one day as I was looking at this patently ugly teacup. We have a definition of fragility, very simply connected to what we saw about options. And let me propose a following. Is fragility what doesn't like volatility? If this teacup is on a table, and there's an earthquake, will it benefit from it? No, you say? Very simple. It is, it wants a fragile, because it wants calm and a predictability. It's harmed by this order. You guys have earthquakes in California. It doesn't want an earthquake. It doesn't want to be in California. Rather than in New York, you see? Very simply. And now from this concept of fragility, we're going to get into innovation and optionality. So the way I see it is short optionality. And let's look at what short optionality is. This is a payoff of a financial structure that is very vulnerable to phone calls at night, when the middle of the night, the chairman of the company gets the phone calls in other event. So this payoff, this package, you make or lose some money. But typically, the losses are very large, and the profits are very small. Exactly like the coffee cup, except the coffee cup has no variation, except for the loss. The coffee cup will never improve. Let's see if you can connect this. This package is robust, and this package has an opposite payoff, where all the gains are large. The kind of thing that only people in California seem to understand. People in New York, they don't get it. Because people in New York have this payoff. And let me explain. The banks are in a business of hiding risks. So they make small. They have no volatility most of the time. And once every 10 or so years, guess what? They lose everything they made. And then they come to the taxpayer for support. They have the setup for people to give them monetary policy to help them and all that stuff. And meanwhile, they keep their bonuses. Because it's a very efficient strategy where you make, you make, everybody think you're smart. And then when you lose, guess what? It was a bad environment. It was only a quarter when you lost. But visibly, you've lost more than you ever made. Banks lost in 2008 more than history banking. And of course, they paid themselves a lot of money. They didn't return it to us. So this is a payoff that's very similar to a short and option. You sell an option. You have very little return. You earn some money. But then something happens. You have unlimited losses or very large losses. That payoff resembled the fragile. The opposite of that payoff would be something that's long volatility. So when I went to try to explain this, people were understanding that the opposite of fragile isn't robust. It's not solid. It is not the opposite of fragile. The opposite of this is not the straight line. It's not a payoff where you end up unharmed. You agree? If I'm sending a package to say Mongolia interior, and the package is fragile, what do I write on it? Fragell. All right. OK. If the package is robust, what do you write on it? Nothing. So if the package wants volatility, wants to be harmed, wants something, wants restores, wants disorder, wants earthquakes, all right. It's not the same as robust. It would be something on which you'd write, please mishandle. I am antifragile. It's the opposite of fragile. So the opposite of fragile is not something that is robust or something solid. It's something that wants disorder. And guess what? There's something called the cluster. And if you like one, you like them all. Uncertainty, variability, and perfect, and complete knowledge, trans scales. These, if you benefit from all of these, you are classified as antifragile. And it's very similar to someone who owns an option. So we're going to talk about how you guys can milk randomness, because that's what you do in California, all right. And we're going to be a little more technical and a little more rigorous in a way we analyze an option payoff. So there are things. Now, let's do the world and three categories. There's a fragile, like this computer. You pull water on it, it's gone, all right. You understand? And now we have to give a lecture maneuvering with a mouse and maneuvering. So it doesn't blow up. And hope it can, doesn't blow up before the end of this lecture, all right. That's a fragile, OK. That's a definition. There's a robust, you hammer it, nothing happens, but it doesn't benefit from it. And there's the antifragile that likes the solar and benefits from the solar and benefits from error. So it happened that now we can identify the fragile, where there's a method to figure out what is fragile, and there's a method to figure out what is antifragile. How? Very simple. Something related to convexity. Let me explain what I mean by convexity or concavity. If I jump, I am fragile. My body is fragile. If I jump 10 meters, what would happen to me? You guys are engineers and smart people who you would know. What would happen to me? Sorry? So we shot you. I die. I'm going to say it. This is, you die. Your hospital here won't be any good, right? You die when you fall 10 meters. But if I fall 10 times 1 meter, what would happen to me? Nothing. It means that every additional meter, harms me more than a previous one. No? Aha. Everything fragile. We saw it in time series space. But if you look at it as a response, everything fragile has to have accelerating harm at some point. And we can actually show that everything that has accelerating harm doesn't like volatility. And the opposite of it is something that has accelerating benefits. The nonlinear is harm more. You see this accelerating harm. It's harm a lot more than the linear. And visibly, the linear for small variation show more response than the nonlinear. This is an easier to understand if you look at it this way. You saw that the harm I get from hitting the floor. It has to be nonlinear to be harmed at 10 meters, but not to be harmed at 10 times 1 meter. You agree? It has to be that way because walking on campus would kill you otherwise. Because being harmed by that large, but you get the if the thing were linear, you'd be killed. So harm for anything that has not been broken has to be in a nonlinear. The coffee cups sees thousands of hits very small intensity, like very small pounds per inch hits. It doesn't really care. But one big hit and it breaks. So things that are fragile have to be nonlinear. And this is what's central about this idea. You have to be accelerating and harm. Another example is look at the world around us. If we were linear to harm, we'd blown up long time ago. The world has three to four million earthquakes every year of low intensity on a guy-girl scale. You see? It would be like a Fukushima every few minutes if it were the harm or linear, but it's not. You see? Yeah, yeah. So this is quite central because now we can figure out whether it's fragile from nonlinear and look at its opposite. Simply, we have the following. If you have more gain, say if the market goes up 10%, you make more money. Then the market went down 10%. Then you lose it. The market went down 10%. You're convex, you see? And otherwise, you're concave. The best way to figure it out is with this. This is convex. This is concave. If you want to remember, this is convex. And this is concave. So if you look at the payoff of the convex, you make more than you lose. You're here. You make more than you lose here for an equivalent one. Or you make more the second time than you make the first time. If the market goes up 20%, you make more than twice. It's a market one up 10%. If you are in that situation, then you're light volatility. If you're in that situation, then you are benefiting from randomness, what I call the disorder of others, uncertainty, all these things. Let me take one or two questions here before continuing. And as you're asking the question, I can look at, I can see if I can fix the computer. Yes? You can see there's only the sloping upside of the convex curve. Because it seems to me that on the other side of here is my other face. You would lose. No, no. The increasing. It has to be increasing. But you're not going to be here also. I mean, it's not going to be hard. Here, this is f of x. And this is x. And if you're here, you see, or the decreasing, but not very at the decreasing rate, you see. For the increasing, all right? You make more than you lose. And for the decreasing, it slows down. Any other question? The idea is for you to see the connection between convex, the idea to see the connection and likes volatility. Think about why the convex likes volatility. You can do it here. Instead of getting x all the time, you're getting x plus 50% sometimes, or x minus 50% sometimes. The linear combination is much better than just getting x. So you like volatility, you like variability. I did a very simple experiment. On my computer, I generated two kinds of series. One where a person knows where he's going. Very intelligent person who knows where he's going. But doesn't have any convexity in his payoff. The other one of a person who doesn't know where he's going has no idea but has convexity in his payoff. You see? Look at the difference between the two. Tryland error is an option. Why? Look at tryland error as something like this. You lose, lose, lose, lose, lose, lose, lose. And once in a while, you make a lot, you see? Exactly like the opposite of the coffee cup. Like what we saw before, something that gains from the soda and gains from black swans. That's tryland error. You're in a business of tryland error. Someone who does tryland error versus someone who's directed ideas is going to perform extremely well when you have randomness. And what we're going to see is why, when you have tryland error, you outperform someone who knows because convexity matters a lot more than knowledge. You don't know what's going on. You keep tryland error and rational error, rational enough not to make mistakes by doing the same trial twice or having a result and giving it up. So we can generate rules from this. And I was thinking of seven rules because people like the number seven. Look here, seven money rules for life. There's seven rules for success, all right? Seven rules for weight loss, all right? You can do that as well. And seven rules for change management, OK? So I also said, OK, I'm going to come up with my seven rule. But then I realized you guys will not remember the seven rules as you leave this place. So you have to understand how an option works. And once you understand how an option works, then you understand one rule. How to milk, how to be in a position where you are antifragile and benefit from randomness. It's a big, big, big misnomer that trial and error or luck benefiting from luck, all right? Is a good, the word trial and error is a misnomer. We should not say trial and error. We should say convex function of randomness or trial with small error. Trial and error have to be small. So the antifragile, your environment or the errors are small and of small cost. And the gains are large and unlimited. And then you are positioned properly towards the blacks one unpredictability, all these things. This is what's central. And you can model it exactly like an option. And an option increases monstrously in value when there is volatility. Now there's some good news and bad news that people don't quite understand that optionality concept. In this book four, I'm attacking the notion that we got to where we are because of the superb intellect and brilliance of the ancients. That's not the case. We got to where we are thanks to people who were taking risks involved in trial and error. The problem is I call it lecturing birds how to fly. People, birds, if you lecture birds tell them, this is how you should be flying. And birds will fly according to your principles. Then you can claim credit, you agree? And then everybody would believe that because you never say it's called epiphenomenal, because you never see the birds flying without someone lecturing it. Now it's the same thing with the problem we have with education. People have this idea that science creates technology. So if you take a book, any book, you have this idea of science, technology, all right? Practice. It looks like it's exactly backwards in history. But the problem is that birds don't write books less than I checked. Who writes books? Those will lecture birds. So we have an extra generation of people who will forget, you know, how it was before. Now let's take the history of technology. To me, it comes from optionality, discoveries. And then someone formalizes it and dresses it up as you know, this is directed research. This is from a top down. But in fact, it's all come from trial and error. You don't know what you're doing. You don't know where you're going. But the harm is small. So it's much closer to cooking, you see? How do you cook? It's trial and error, you agree? You don't take a chemistry class, even except if it's with Tina, because she wrote a book on a chemistry cooking. But you don't really take a chemistry class, then work out the equations that come into it. And then get your perfect dish. How does it work? You try, you taste. The harm is small if you're wrong. And by little by little, after three or four generations of trial and collective trial and error, you get a good dish like Shukut or you get whatever, or sour, no bread, or kind of thing you have here. You see, this is cooking. Well, it looks like technology or examples cooking. But we read the wrong books and a matter of investigating how things were derived, you see? Whether it's optionality or whether it was knowledge. In book four, I stopped book four with this story by Aristotle. He was talking about talus of militaries. And talus made a killing. He was a philosopher. And he was tired of the people who were telling them, listen, you're a philosopher, you're a smock. You get the idea. You can't make money. Plus the guy was Phoenician. So you can't make any money. Who is tired of these people? He wanted to prove that he was philosophizing because he loved that business, not because he was incompetent. All right? Now, how is this moving on itself? As moving left, if you've noticed, going backwards to the seven rules. So what did he do? He went in and put some money, some bets on olive presses. Sweet loss business. OK. So he put some money on olive presses. He went in and made a bet that it was going to be a demand for olive presses. He put a little money on it. And of course, there was a lot of demand. The season was great. And he made tons of, he made a fortune. Now, what does Aristotle write that Tallas made a fortune because he read the stars and predicted a great season for olives. High demand for olive presses. But in fact, what the Tallas have, he had an option. He had a down payment, a call, like the right to use the olive press, by putting very little money on it. He said, had he been wrong, would have cost him nothing. So he'd have tried 10,000 times, or not 10,000 times, maybe 10, 20, 30, whatever, high number of times, at no big harm. You see, he would have been breaking even, you know, breaking even, breaking even, breaking even. And making killing was on a while. And that's really what he had is a big payoff. That was what Tallas had with a big payoff. The problem with the story of Tallas, is that they were convinced, people were convinced, that all this great thing came from, knowledge, when in fact, it was from trial and error. And then if we continue, what I did here, and I can find it here, probably in the book, which also is wet, but you see much less fragile, because you can still, the wet book doesn't play tricks on you. You can figure out that in a history, all right, there are a lot of things that were discovered by trial and error that later, masqueraded as coming from top-down research. And then nobody gets shredded for trial and error. We've known, for example, a lot of things, think of Euclidean geometry. You think that we need geometry to build things, no? That's what people think, no? All right, we had Euclidean geometry since the second century, okay? All right, did people use it to build, you know, these big, did the Romans use it? No, nobody used it. They had their own heuristics, their own tricks. Come in from trial and error. And they only used it later, okay, after the 15th century, by the 15th century, there were only four people capable of doing making a long-hand division in Europe. So I take that example. Another example is another example, patent example other than, sorry? Which one? The pyramids? Pyramids, by the pyramids, yeah, we're built before. You take a lot of things, sorry? Penicillin. Penicillin, well, penicillin was discussed, we know everything in medicine is discovered, like Viagra, by error, side effect of something else, and then people, you know, Viagra as the nurses were complaining from behavior on the eighth floor, on the trial. So you get the idea for eight, and it was a blood pressure medicine. So the, there are a lot of examples of stories backward, even cybernetics, the thing is weiner, nor weiner, in fact, just someone sent me a book as I was writing this, that it was practiced by technicians way before, and of course, no credit for them. So let me take some questions here as a computer, as I find my bearings. Let me take a few questions on this, yes? I said, isn't there in general a mix of knowledge and luck? That is true, so there's something called, yes. The, the bacterium in the stomach that causes ulcers, it was always believed that there was no bacterium in the stomach. Well, this covered quote unquote by chance, by two guys, went on vacation, left things, nullab, came back, but it was not by chance that they had left the stuff in the stomach, so there's a mix of the two. There is a mix coming for optionality, is when you mix the two, but effectively, there is some kind of improvement in scientific knowledge built from optionality, you see, improvement that helps you conduct other experiments. But typically, the role of knowledge is highly overstated, so we have this impression that things were driven a lot more by design than they were by luck, you see. But the point is it's not luck, it is a convex function of luck, it is by thinkering, it's a convex function of luck. This is what is quite important in this, is that you have more upside than downside to whatever you're doing. The biggest improvements we had in drug discovery were when people had no idea what they're doing, but knew that, the cap-trine dies, till they found something. And today we're directing, and we haven't been able to find much. Now we know that you know, we know so many things, we understand, bacteria virus, so we haven't been able to find as much as we did in a period with purely trial and error. So, we continue with this idea of trial and error, that has optionality leads us to remember the seven rules, to maybe you can make 77 rules, you can make a lot of rules, but the principle should always be to be on the right side of convexity, because convexity will pay you a lot more in the long run than direction. So, what do you do it? The first thing is make sure that you have optionality, you're not locked into a business plan, it's like you're not locked on a highway with no exit. Yes? So, I'm pretty, I think people know that if you're convex, you're benedict from extrogoldism. Yes. But you can now popularize this idea, right? This is not, I mean, I mean, I mean, people knew about it before. So, who are you going to buy these options from, to be part of interest in this? This is very interesting. Now when we talk about antifragile, it's gains from randomness and volatility. The, in financial option, you buy the option from someone, you agree? But in real life, you don't buy it from anyone. Tryland area, you're not buying it from anyone. This is not the financial option. This is a real option. That's number one. Two, you still have an option that you're buying very cheap, whenever you buy, if you buy a house, and you have a mortgage, you already have an option. You see, people don't understand you have the option. And for a long time, for a long time, people were getting even greater option from banks. So, the built-in, the explicit option is not what I'm talking about here. What I'm talking about is embedded option in things or option like characteristics and things. And if you take the formation of wealth and history, it all came from this optionality. Other questions? Yes. How do you, are you for trial and error in the industry, for the airline industry, where the errors are costing with cost? OK. There is explicit trial and error where you are willing to take the error. OK. There's explicit trial and error. With the system, the explicit trial and error where you think are voluntarily. And you have to maintain your error small and make sure it's not like a lottery ticket, where the upside is known, someone's overcharging you for it as a financial option, and it's open-ended, you see. But also, there are businesses where you make mistakes, in which case you want to make the mistakes as small for the system as possible. And never let them, as they go, to waste by exploiting them. So let me give you an example. You just mentioned the transportation industry. Every plane crash, which is an error, leads to the improvement of the safety of traveling. We haven't had a plane crash in America, commercial, the commercial plane crash in more than three years. And before that, it was more than three years. So or a lethal one. So you realize that there are businesses that even if they can have a large error to make sure it's one at a time, not like monetary policy, where you have big mistakes or politics, where we have one person make a big mistake that costs so much in lives and money, like a war, you see. You want your mistakes to be small. When you can't avoid having mistakes, you want them to remain small. And typically, top-down things make large mistakes. This is what my idea of decentralization of, you have to decentralize the errors by making sure they remain small and distributed. But when you're willingly making errors, because they're small and because they're not of huge cost, when you willingly, then you want, you see, then you want to make error. You want to make a lot of errors because they're not at harmful. You see, and the payoff comes from it. But remember one thing. You saw my first graph where I was showing you the returns in this business. OK, the strategy that immediately comes to mind from that is that you can't be directed if a lot of your returns are going to come from one. What are you going to do? What do you need to do? You have to be as broad as you can in your strategy. That's number one. But you can't do it if you're an entrepreneur. An entrepreneur by design is not broad. And if you're going to have trials, you can probably, you can't have too many trials in a lifetime. But collectively, society has been benefiting from this army of entrepreneurs. Very few of them managed to buy the big houses around here. I hear real estate. She's telling me it's hugely expensive, you see. Very few win. And then the remaining people are like soldiers who fall in battles for the sake of the system. Which is why I was calling for a national entrepreneur day. And suddenly it happened, by the way, right? But didn't get credit for it. It happened on publication on the public day of the book, by the way. So the call national entrepreneur day, because hey, you know what? We salute fallen soldiers as some because they're needed for the system, for the collective. They're needed for the system to prove the system. We need soldiers to fall. We should do the same for entrepreneurs, because realize how few win. And you don't want the other ones to be demoralized. You want to thank them for getting involved in their side of trial and error without having anything but errors all their lives. But they're doing it for the sake of the system. And this is what it is. You see there's something moral about what you're doing. If you try to prove the system, something moral, even if you fail, especially if you fail. You see? And this is what people don't understand. We bail out. We tend to bail out corporations that are rotten and fragile. We don't bail out entrepreneurs. We should be bailing out entrepreneurs. We should also make it more honorable. The only place I'm honored to be here, the only place on a planet where it's honorable to fail is here. Before that, it was used to be guess where? Couple of centuries ago. Where? The battlefield. No, no. An anthroponorship. An anthroponorship. Sorry. England. England that pulled out of industrial revolution thanks to these aggressive thinkers, you see? So you have, that was when, and now the problem is, look at England, what happened to England. The minute you get rich from tinkering, you have the illusion of being able to replicate it through Whitehall, an economic policy, and Whitehall, a research policy, and this, and minister of policy, and stuff like that. They didn't have that when they pulled up, you see? And the minute they had that, of course, they went to the realm of the client compared to other places. So you see, you have to let the things develop organically on their own and tinker the max, because that's how systems operate. Let me take more questions. Yes, I'll conclude with a question. If you go ahead. Monitor policy is going to go in today. They had a leak of this dead man to talk about ending quantitative easing. And they quantitative easing. Which is the leak that's been approved with the sum. Sorry. He's asking me, he's telling me that something not related to this talk, but he knew that I'm very interested in the topic, which is federal policy today leaked that they're ending quantitative easing. No, I'm not involved in journalism or commenting on events, but I'm going to talk about monetary policy. If you've done that, it's easy for people to think about monetary policies. Shouldn't they be raising their own? We should. The thing is what the Fed has been doing, the idea of the government, they don't understand antifragility. They don't understand that when you have a crisis, you should come out of it better than you were before. You guys had your crisis in California, remember? 2000. You weren't born many years. OK, so over the most, right? So you came out of it better off than before. No, it cleaned up the system. So you should never let the crisis to waste. Now, what happened in Japan and here and in Europe? They have a crisis. Now, they shoot to establish the system to bring it back to what it was before. Without letting what is fragile break, and new things come in its place, you see? So the monetary policy aims at preserving the Satokuo. And then also, the side effect is, of course, to enrich those who were involved in the crisis, right? In causing the crisis. And of course, it's not good to have very easy money, because you don't want people to take money and go gamble with it in the stock market. You want it to go use the money for what you're doing. The real thing, the trial and error, that you don't get respect for losing a little bit all the time. Other questions? Yes. I didn't know. Then how would you think about chapter 11 bankruptcy, which essentially grants the original proprietor or is the ability to just keep on doing what they do? What do I think about chapter 11? I have written two things about the notion of limited liability. If it's used for this trial and error, then it's very good, the limited liability. If limited liability is used to transfer your losses to society, so you get the bonus, the upside, and society gets the downside, then it's not good. You see? And what has happened in the catalystic system is instead of having incentives and disincentives, we have some people who have the incentives. And then when they lose money, take banks, they make bonuses when they have good years. And then when they have a bad year, they transfer it to society, to the taxpayer, and they keep their bonuses, as we saw before. Again, remember, the two kind of payoff, the payoff where you lose a lot to make small. And the other payoff, which is what you have here, where you lose small to make big. You see? Now, those who lose a little bit, who lose a little bit to make big, are not gaming the system, because the taxpayer doesn't bend you out. Have you heard of a bailout of any company in California? No. Because you guys, all your big volatility are the upside, not the downside. You see? But the other ones have their big volatility to the downside, and they lose more than their capital. And someone has to pay for the losses, and something in the taxpayer. Other questions? Yes? Let me say, yes. What do you think about the rise of money? So you have all these things to say about the nature of probability and being able to predict things. But we also use probabilistic AI a lot, and we're using it more and more in every field. He's saying that I'm skeptical about the use of probability to predict, and he's telling me that in AI they predict. In mediocre stand, you can use probability very well. It works very well. Outside, in mediocre stand, when you have things dominated by rare event, these things fall apart. And they fall apart. I just put a text, because nobody was understanding my black swan. They would read it and comment and write articles. I'm not even wrong about it. My point is that large deviations occur. They are unpredictable. No matter how many PhDs you put on it, they're unpredictable. And all the people who relied on predicting rare events have blown up. And this is how, actually, you can make money on Wall Street. Identify those who rely on probabilities to compute the risk of rare events, and make sure they're going to go bust, like Fannie Mae or like others. And you can make a buck and celebrate being right with these guys. So I'm saying, but for AI, you can apply it for small problems that don't have big tail effects. Yes, you can definitely apply it. We use probabilities for anything. For insurance on your house. For insurance, medical insurance, they are probably worth beautifully in these domains. And in casinos, it's perfect. Yes. Can you comment on the convex function of law in drug discovery, given the fact that the average drug in the US cost about $1 billion and 25 years of discovery? So do you have any insights on that? Probably not. Yes. When you have a, OK, how did we get to where we are today? You lose small to make bait. So because you have to have a lot of trial to get to destination. If you are what I call teleological in a slide that I can show and think you know where you're going, then you can bypass the trial and error because you have great scientists and great scientific understanding. And it looks like Pharma got to where it is today through accidents, the side-effective drugs, side-effective things. And now suddenly, they woke up and said, OK, now we're going to target results. You see? Well, in fact, it's a collective effect of a lot of firms trying. And those who succeed thought that they succeeded because of their brains, not that they succeeded because of their taken advantage of luck. You see? That's the problem of Pharma today. And Pharma has more problems than that. In the past, you came up with a drug. OK, you had to look at side effects and probably a few other drugs. Today, we have 850,000 authorized drugs. Something like that. And 100,000 existing drugs. So every time you introduce a drug, you've got to look at side effects on a patient. And you've got to look at co-side effects. And then you have to look at tri-side effects with three and all these drug interactions that you have becoming more and more unpredictable. So Pharma is in trouble in that sense. Plus, there's another thing in my book here that I discuss about the subsystem that sometimes curing people is much easier to do by subtraction. Subtraction is much easier. CZ7 rules. All these rules are positive. You do this, do this, do this. As much, the charlatans typically have nothing but positive rules. People who are scientists or philosophical have negative rules. OK, don't do this, don't do that. It's much more rigorous, actually. And they don't have side effects. So instead of curing people by giving them drugs every time, we look at subtractive methods, remove things. Like, for example, remove cigarettes from society. You save more, it's more effective than anything we're spending on drugs. And cumulatively more than anything done since Penicillin. You say, I didn't believe the statistic when I saw it. And in fact, it turned out to be true. If you just remove cigarettes, if you remove corn sugar, OK, you remove by removal. If you remove diabetes, the first thing people do is give people drugs. If you send them to Siberia or didn't have the money, put them on. 500 calories a day for three months. You come out of it fluent in Russian or conversant in Russian. And it's more effective than any drug initially. But what the protocol, instead of starving people, because it's a stressor that someone needs, we are antifacial to variation. If we derive, if we are deprived of these variations, we get weaker. So people, the first thing they do is try to give you a drug instead of removing food, try to give you something. And effectively, now, epileptic seizures, the first thing they do is give them drugs. Whereas the most effective treatment is removal of all sugars. And we know we've known now for 70 years. But pharma doesn't make any money removing things from your system. Nobody's going to make any money if you stop smoking directly. If you stop smoking, they're not going to sell you something. Unless they sell you method to stop smoking, you see? So this is the problem. There's a gentleman in the back. The fields where it's hard to listen to a lot of individuality such as trading, kind of advice, effective compensation. I believe in something I call skin in a game. Skin in a game is a defined skin in a game. It's most moral and effective to remove risks. Is that nobody should ever put someone else at risk. I don't really care about compensation. I don't really care about ranking because you can't have a trading competition. Because someone has a strategy that pays off very rarely. He will lose in the competition. He will lose every battle and win the war, you see? So I can't really rank traders. There's one rule I have I call skin in a game. Is that nobody should put others at risk without having harm to himself. In other words, if you lose money to your clients, you should be exposed to the same risk. That's sort of it's most moral and risk management rule. Risk management because in Hamurabi's code, it was simple as an architect build the house. And the house is fragile, but hidden fragilities in a basement. You get the idea, we're in the foundation, like in a bank system, banking system. They look very stable, but they have the cut corners that nobody will see to make the bonus. And if the house collapses, the architect is penalized. That was in Hamurabi's code. Actually, it's put to death if the house collapses and kill the owner of the house. So this system is the best risk management rule because as Hamurabi discovered, but something they forget today in Washington, the architect or engineer knows a lot more about the risks. He doesn't know a lot about the risk, but he definitely knows a lot more than the inspector, you see. So if you make people eat their own cooking, you see they're a lot better off. And someone sent me a read my book and sent me something, a story in Brazil, where they discovered that they could lower the rate of helicopter crashes by forcing helicopter engineers, rather than they could take a ride, half an hour ride, once a month, and a helicopter. For example, something the Romans knew and Victorian knew that you make engineers sleep under the bridge. So in trading, what you do so long as, whoever is involved in a strategy has losses, small. It doesn't matter. Has losses. If he can harm others, in other words, he has some incentive, but some disincentive, then we should be OK. It's when people don't have this incentive when they lose that the system blows up. Yes? Sir, the outcome systems are move to errors and mistakes. Politics today is thought out. There's your trivial anti-fidility, have some implications of some sedition and how politics should move forward. OK. The idea that I'm proposing is very simple. Along the rule, if you look at these rules very simply, that you want mistakes to be small and gains to be large. And on the mistake side, you want to distribute mistakes, then you necessarily need decentralization. You see, the most stable country in the world, the Switzerland, where nobody knows who the president is. They can tell you that there's cadaphi's presence of this. I saw the president, but they don't know their own president. The system works well. It's solely centralized. It's completely bottom up. You see? So mistakes are small. So this simple concept, preventing the book, convexity means mistakes are small. OK. Concavity means mistakes are large and rare. You see? And that simple system. So we don't have any more time. I have another lecture. But thank you very much. Thank you. Thanks a lot. Thank you.