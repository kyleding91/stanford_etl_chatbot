 You are listening to the DFJ entrepreneurial thought leader series, brought to you weekly by the Stanford Technology Ventures program. You can find podcasts and videos of these lectures online at eCorner.stanford.edu. We have great panelists. Let me introduce them to you. First of all, Christina Smolke. She is the associate professor from Stanford School of Medicine. She has her lab is focusing on new molecular biology and genetic tools. I am now going to show my age and put my glasses on so I don't blow my intro of Christina and others. Computational approaches and the measurement technology looking at transforming our ability to study and manipulate biological systems. More to the point, Christina has one NIH Director's Pioneer Award. She was featured in science, which sounds like a fascinating article, on genetically engineered yeast and how that relates to medical painkillers. So she is doing some exciting things. She is also a CEO of a startup and the, so thanks a lot for coming, Christina. Next up we have Astro Teller. He is head of Google's moonshot factory, formerly known as Google X and now called X. As most of you know, Google X has brought us the self-driving car, Google Glass and some other exciting audacious breakthroughs. He is an engineer and scientist. He is uniquely qualified to oversee Google's moonshots. He has grown five companies of his own. He holds numerous patents in hardware and software technology, five companies and so forth. So Astro, thanks for coming. Third, we have Steve Jirvitson. He is a general partner in the venture capital firm, J. Prophyshire Jirvitson. It is named after him, not his mother. Who is right here? I have heard Steve's mother is in town. I also heard that she says he talks a lot as a child. So we will see. And in the event, Steve has been an investor with Hotmail, Interwoven Skype and of course with Tesla and some other companies associated with Elon Musk. He has been named one of Forbes tech's best venture investors and has been included in Fortune in its brain trust of top minds. Steve is very jazzed about space exploration and sits on the boards of SpaceX, synthetic genomics, Tesla and I believe Planet Labs. I think that is one of yours as well. In the script it says to say that he was also one of my students back in the day. That is actually true. He is one of my undergrad. And he has always talked a lot. I agree, Mom. I think that is right. And finally, moderating today's panel is Persist Drell. Persists are esteemed new dean of the School of Engineering. She holds the James and Anna Marie Spilker Pressorship. She is in the Department of Material Science and Engineering and material science and engineering. And she also in the physics department. From 2007 to 2012, she directed the Slack Laboratories here in our neighborhood. She really moved Slack from being a high energy physics shop to a broader range of innovative technologies. So Persists will be asking the tough questions to our panelists today. Just so you know when this is all wrapped up, I do hope you all stick around for refreshments outside as well as a look at the Deslan, Delorean cars together. So that is kind of a cool thing to look at. So we are looking forward to a continuation of a fabulous day on the future with some of the greatest minds of the world to think about it. So thanks a lot everybody and have a great time. So I get to have the fun of asking the questions to this really great panel. With three, I'd like to point out really different points of view. Steve's venture capital funding, cool new ideas, Astros running probably one of the most inventive labs. So I think is it fair to say managing a lot these days, maybe still there inventing. And Christina, she's in the lab making the future happen. Though the future is the theme and so I want to start out by asking our panelists to look back. Now because back to the future came out 30 years ago, I was going to ask them to look back 30 years and then I realized that all of you in the audience weren't even in existence 30 years ago and that wouldn't mean anything. So we're just going to ask you to look back maybe 10 years and maybe I'll start with you Steve. Name one thing that didn't happen that you were sure was going to happen 10 years ago. Wow. I knew you were going to call calling but I still didn't prepare a thought. There's a bunch. 10 years is tough because there have been so many mistakes that I'm trying to timestamp them. I thought Amazon was going to be an inachronism and totally made obsolete by distributed federated personalized systems. I thought Netflix would fail because clearly videos are going to come over the internet and not these DVDs they were mailing at the time. So these industry transitions like a company that starts in one area but expands or pivots or grows. I just didn't see those coming. And I think I was maybe at the tail end of being wrong about nanotechnology and the rate at which it would impact the world and how it would and whether the term meant anything to anybody but me and a few geeks like me. So that was a whole section of mistakes leading up to 2005 or on that sector. So Astro you get the flip side. What did you predict that is happening? What did you get right? I was Steve. I think it's more interesting. I'll answer your question. I'll pick something. I want to start with one or two things that I've totally got wrong. The one that sticks in my mind I think of this all the time because I have this mantra at X about how almost all of my ideas are wrong, how all of your ideas are wrong, all of our ideas are wrong, almost all the time. It's how we claw through all of the piles of ideas that we have to find those gems. That's the real trick. And the thing that I use to remind myself all the time how wrong I can be is I remember seeing the first phone about 10 years ago that a camera on it. And I just thought people are not going to take pictures with their phones. And even if they did there's no way they're going to be like obsessed sending pictures to their friends. It's like the dumbest thing I've ever heard. And I was really sure that that was not going to make it. I just remember very viscerally being certain about that. It was a good humility moment. So was there something that sticks in your mind that you got right that you could see the future 10 years ago? I think that so my background is artificial intelligence. And 10 years ago was a so called AI winter. And we are out of that winter now. And that was one of the things I was incredibly confident about because AI has been on this very predictable sort of exponential increase in its abilities. And that people were saying AI is dead or that it's never going to actually accomplish anything really never change that trajectory. So that was one of the things where I felt like, yeah, we'll see. And in fact, AI has continued to make really steady progress in a bunch of areas like machine translation and speech detects and computer vision and robotics. And a bunch of the areas in which it's just continued to churn out benefits over the years. So I feel like I was right about that one. And Christina, something that you couldn't have even imagined, didn't think about, didn't think it was going to be right or wrong, but it's happened in just changing the world. Biggest surprise. Well, I guess I would say, let me just say two things. So something that I didn't even imagine people would want to work on beyond sort of fantasy and movies that is not necessarily here yet, but people are seriously working on is de-extinction, right? And again, it's not that we've achieved that yet, but people are inching closer to that, and people can kind of see this happening with different creatures and animals. It just wouldn't have even entered my mind that that would be something that we'd want to spend our time doing. The other thing though that is now here, that I wouldn't have predicted or thought about is the idea of cloud laboratories within biology, right? So really now, you know, thinking about outsourcing, you know, our experiments and the way that we do experiments and examine things to companies where that can be more systematized would not have been something that I would have even thought, you know, was possible, or that was even really a market for it. So now let's turn to the future. Steve, what's the coolest thing in the pipeline? Oh, what time frame? Like right now, cool, or? You call it. Oh, God, it's all of the blitz. So the high level of observation would be that when I started in this business of investing start of 20 years ago, it was all in a few industries of software, semiconductor and biotech, and we didn't do biotech at the FJ. So it was software, semiconductor and variance, computing, and photonics. It all felt the same. And today it's like a whole variety of industries that are treating transform because of deep learning, machine learning techniques, everything from rockets and drones and robots and satellites that used to be really bad industrial business, they're not becoming software-centric businesses. So in every one of those sectors, it's kind of a recurring theme of how they're doing it, using off-the-shelf hardware from cell phones, repurposed in new, interesting ways. And that's exciting. And then, closer to Christina, this area of focus, the whole revolution of learning going on in life sciences and how that percolates back to IT in general, like how do we build complex systems? How will we build these AI's in the future? I think we'll be informed by the way biology has done it, both as an existence-proof and metaphorical inspiration for how do you iterate on an algorithm and compound intelligence over time or complexity over time. I think those are the metaphors of the future for how we do engineering. I'm going to interrupt you for one second. Can people here raise your hand in the back if it's OK? Good question. It's OK. Hand is OK. Good. It's rare for me. All right. No, because I think this morning it was tough. So thanks for the checking. And so I think the field that excites me the most is biology. The technique is machine learning and deep learning across all fields. And then that leads to all kinds of new things, like satellites to observe the Earth every day and broadband everywhere on the planet via satellite and building new life forms that do interesting things, building organs for transplant that are not going to trigger the immune system. There's just, like, probably 18,000 different student projects that would have seemed like a fine-suffiction even five years ago. So Astra, can I ask you that question? You just did. Ah! I mean, obviously there are specific things that I can't answer. But one of the things that excites me, which is related to what Steve said, is when I look at the commonality across a lot of the things that we're doing at X, I notice that a lot of the projects are both non-traditional in being robotics, but in fact actually are robots. So we're trying to get the other four and a half billion people who don't have a good internet connection today, an internet connection via a network of stratospheric balloons. But in fact, those balloons have to do a lot of sensing. They have a lot of actuation. They can rise and fall. They're trying to pick the winds that they grab and cause themselves to sail, to keep themselves into useful places. So if you have sensing, you have computation and you have actuation in the very general sense of your robot. Our airborne wind turbines are actually this shift from a huge amount of steel to mechanically solve a problem to essentially a very small tether and a super-hard control system problem, which is essentially bringing robotics much more centrally to this issue of generating energy. Our cars, self-driving cars are kind of the poster child for non-traditional robotics. Our self-lying vehicles for package delivery are very centrally sort of robots. So in the sense of robots as walking mechanical people, I don't know how fast that's really going to change the world, but I see a lot of these issues about bringing techniques from machine learning, from mechanical engineering, from ways of embedding intelligence into products as an alternative to making them mechanically safer or mechanically cheaper. I see that as a very general thing that we're going to be able to do over and over again to solve problems in the world. That's cool. Given this revolution that's going on, all the changes, Christina, you work in a lab, you do your research. How do you choose from that whole menu of really exciting things? What to focus on and what you do? So I think the first thing for any of us is to really ask yourself, ourselves, what are we passionate about and what do we want to be doing? When you think about what problems you want to work on and what type of world you want to live in, there are many different routes to take, but you want to choose something that you're going to want to put your whole self and your whole sort of heart, body, and mind into. So that's the first thing I think that really drives that decision. The second thing when I think about problems that I want to work on is, and especially operating within an academic environment, I think our role is to not just think two to five years into the future, our role is to think 10, 20 years into the future, we should be doing things that are going to build the foundational technologies and advances that then eventually will move on into industry. So I think we want to look 10, 15, 20 years into the future and ask ourselves, what are the big problems we see? What type of world do we want to live in? What is either the foundational research or the applied research that we want to focus on that we believe is going to sort of make an effect of transformative changes in the world around us, right? And then you pick what problems you want to work in on and you dig in and the great thing about working in an academic environment is you have so many people around you to work with that are going to bring their creativity and spirit into it and take things in entire, you know, in directions that you couldn't even imagine and you have to be able to give them the freedom to do that. Okay. Steve, how do you think policy? It's going to play into the future innovations we're talking about here. That government policy? Yeah. Gosh. Oh, it's kind of like the Hippocratic policy. First do no harm, I guess comes to mind. Does that mean you don't work on things? No, we're almost, let's clarify that. No, no, no, no. So our company's interact with policy a lot that we rarely, if ever, bet on policy swinging our way with possibly the exception of autonomous vehicles. We don't know how it'll happen, but it's just seemed so compellingly obvious that all vehicles would be autonomous and electric in the future and will marvel at the present day that we let people slaughter each other and others. And I'm one of those high-risk categories kind of people in myself and so, you know, that in plain sense. We know that's the future, but in general, let's say in the energy, clean tech investments that we made, we never count on policy making the investment work. And so we generally are pretty hands-off in the comes of that. Government could play a big role, obviously, in sponsoring projects with a NASA helping space, get it start or, you know, a big loan to Tesla, obviously, at a critical juncture. There have been really important moments, but rarely is it one of, sort of, company picking. That's the rare model, usually it's, you know, NSF grants and government grants to universities that are the bread and butter of how we see government helping the tech world. And in policy, we just kind of hope they don't make any more. You know that's wishful thinking. Well, I know. I just kind of like, try to keep my head low and help they don't bat them. We've had sort of the opposite experience at X, which is we're trying to pick things that we want to fix about the world, whether it's cars that drive themselves or, you know, the contact lenses that we built for monitoring people's bodies, putting computer and sensors inside contact lenses. So, you know, whether it's the FAA or the FCC or the FDA or the Fish and Wildlife, like we've had to talk to all of them. Fish and Wildlife? Well, for our airborne wind turbine. Oh, yes. Okay. Like, there's no part of the government, the National Highway Traffic Safety Administration that we haven't had, not just to visit once or twice, but like pretty much go live with them. But our experience has been that if you wait until you're done making something and then you go stand in front of them and you say, is this okay? And you don't really mean is this okay? You mean this will be a complete meltdown in my life and the life of lots of other people if you say anything other than yes? Because you're not going to get a straight yes. Then you don't get the straight yes. And then you come away feeling like these people are against innovation. Which I don't think is fair to them because they're trying, you know, in an ideal world of regulators would have a membrane that prevents all the bad snake oil from getting through, but let's all of the good innovation go through really fast. But of course, you can't tell ahead of time what's the snake oil and what's the good stuff. I think they do a pretty decent job. Our experience has been if you go to them several years before you're done and you say, this is what we're working on. What do you think? Here's the goal that we have. This is actually the problem that we're trying to solve and we're not hung up about our solution because it's not done. We're actually really hung up about solving this problem in the world. And the regulators universally are like excited about the fact that we're trying to solve problems for people and then they can engage with us in a creative process of saying great. How do we help you to get these things done so it can be safe for everybody and you still don't feel like you're being stymied by us. So I think it depends how you go about it. I agree we would never bet on regulations changing. But then again, we almost always bet that regulators can work with us to change in ways that are going to be necessary in order for the world to be a better place. I love the optimism of that answer. Having spent quite a few years going back and forth with Washington, I can't quite be that optimistic but I'm going to subscribe. I'm going to subscribe because it's the right way to do it. No, absolutely. So I'm going to switch the topic now because this room is filled with students. And I'm anticipating that you three might have different views on this but I'd kind of like your thoughts on how do we educate the engineer of the 21st century. What's the view of a broad education versus, you know, should we just become Stanford tech? I mean, 30% or 36% of our students are graduating in engineering. Let's just let why not all of them. And what do you think is important about what one learns in college and carries forward from it? And so maybe I'm going to give it over to Christina for the first try on that one as the educator who's actually in the classroom teaching and then I'll go to Steven Aftow. First and foremost, especially if we're talking about engineers, I think and I know a number of my colleagues also believe because we have a lot of conversations about this. That one of the most important things we want to teach our students is how to choose what to work on. Because you are going to go on and continue to learn and continue to add to your knowledge. But being able to kind of make decisions about this is something that is, you know, something good for me to invest my time in. This is something that is not. These are the implications of this particular technology that I might develop. You know, here's the ethical implications, here's societal implications. Here's implications in terms of access and how will that affect the world around me? Those are really important things to learn, right? And where to spend your time on? So we try to structure a lot of our classes to bring those elements in, right? That's the first thing. Second thing, I actually do think it's important for students, especially now, right, to be able to work in teams, interdisciplinary teams, right, and leverage each other's expertise and also be really good and effective at communicating with each other and handing off tasks and being able to pass off knowledge in that way. So that's another thing that we try to bring into our classes. And the third thing that I will say, which is just sort of very broad in general, and this came up in a earlier discussion we were having today, is, you know, I think many people would agree, and I might be biased in this, but you know, many people would agree that, that there really is sort of a revolution happening within the field of biology, right? Especially with sort of advances that we see in genetics, genomics, the way that we treat DNA as information. And I think traditionally biology has been almost sort of a niche, right? Many of us, many engineers, you know, only take biology, don't have to take biology class, right? We might have to take a physical class, we might have to take a chemistry class, but there's not a broad, even basic literacy in biology. And I think we really need to change that and treat it as something that everybody should be broadly literated and to really be able to move, you know, into this next realm of technological advances that we're going to see. And that will also allow us to think about how we bridge biology with computer science, with information science, right, with mechanics, I mean, et cetera, and allow us to move across these disciplines. And I think that's very important in something that is a deficiency right now and how we train students. So Astra, do you agree with her? I think that that's exactly the right set of stuff that we look for, how great are they at communicating? How great are they at learning? How practiced are they at working in groups? So that's the stuff that we should be training people to do. I'm actually not a huge believer that you have to pick what it is you're going to be an expert at now, study that really hard, and then go out and shop that expertise for the rest of your life. You know, the bad news is that the stuff that you're learning now is going to be fairly irrelevant in 10 years. Seriously, I mean, just get prepared for that. It is going to be irrelevant. Yeah, remember that when you're doing your homework sets tonight, right? I don't know. But the good news is that the skill of learning things quickly, figuring out how to understand first principles and be able to reconstruct your knowledge even after you forget 90% of it later, those skills are critical for the rest of your life. And picking up those through those homework sets matters actually way more than the actual knowledge that you're taking in. I just had someone sit down with me who used to be a tank battalion commander. His first job after being a tank battalion commander was to come to X, and he was doing field ops for Project Moon, the stratospheric balloon project. Now a few years later, he is literally designing the balloons. He had no background in any of that before, but he's fantastic at it. And he was saying, well, maybe it's getting time to hand that over. My team has really developed, and I'd like to go back to the early stages and do some more stuff. And I said, why don't you just join another field ops team that worked for you the first time. Just go get some mud on your boots, jump into a team, even though you're really expert at these things now, they won't know it. And you're probably going to develop a new set of expertise that has nothing to do with balloon design by the time you're done. So don't get wound up about it. Just take that quick step back and you'll rock it forward again. And I think the same is true for everyone in this room, that if you plan for static stability, you're going to be really frustrated. But if you can build the skills of dynamic stability, it's going to be awesome. Steve? I want to amplify that and totally agree. A framework for what Ashton is saying is if you believe, and I think you should, if you're close to science and engineering, that we're in an era of ever accelerating technological change, you think of Moore's laws, one that pitted me of that, then a quarrelary is the lifespan of any given idea, company, technology, product, you name it is, going to become more and more femoral. And so you're a career, you're life of lifelong learning becomes all the more imperative, right? That process learning. How can I learn? How can I engineer better? How can I pivot to something new from what I've done or critical skills? So translating to what that means to hear today, think about methodologies of engine, like that, we had the scientific method. You have methodology of traditional engineering. You have these unusual things like deep learning and machine learning that are closer to an evolutionary algorithm and learning more about that in biology and how it infuses all fields would be important. So if I could take what Christina said, I'd say, everyone here, no matter what, you're studying to learn a little bit about biological systems and how they work and a little bit about computer science, we'll be almost like the connective tissue between almost anything you want to do in your life. Because I think those are the metaphors, the frameworks that will apply to almost everything. And then you might think in terms of what you prioritize, what do you uniquely bring to the table? What quirky background, either academically or what have you, can you combine ways to have insights about solutions to problems or areas of the world to focus on that everyone else in the room isn't also doing? Because it's those interdisciplinary pairings of ideas I think we're true meaningful breakthroughs coming through. And that's frankly, I think you learn. I think that's what a lot of excitement comes from and that's what pushes the world forward. Can I get two more? Please, two super quick examples that just made me think. The sort of COO for Google X, whose name is Tom, who has a lot of the central teams under him. And these are people like strategic sourcing. These are people going to negotiate with our supply chain and say, hey, hey, we'll give you a million dollars if you'll make this totally weird thing that you've actually never made before. And then maybe if we need it, we'll get thousands of them from you. That person, his background is not finance. He didn't work at McKenzie. He was first in his class in computer science at Oxford. And the person who was running, we have the very wide part of our funnel, which is called Rapid Eval team, Rapid Evaluation team, which is all these sort of technical polymaths. When they graduate something from their part of the organization, when they fail to kill it for the first couple of months, the place that it goes next, which is called the Foundry, is run by a woman named Obi. And Obi has no technical background, and yet all of the things that we're doing, she actually was running marketing for about a third of Google before she came to X. And now she's running a bunch of teams that are doing incredibly technical things. And she is perfect for that. You don't know where you're going to end up. And I think it's these weird sort of confluences of the skills that you're picking up and the experiences you're picking up and the style that you have that will end up determining where your best niches are in life, not what your major is. What, one last thing? Speaking, they will set it. Practice it, it's an acquired skill. Everyone can be a good speaker. It's terrifying for us 10 times. Just do it. You'll get better. The other skill I might emphasize is respect for cognitive diversity. Some geeks like myself thought there is a optimistic, high energy, analytical way of thinking about the world, whatever my cognitive style was. And that's clearly right and everything on us is deviant. And in my first few jobs, I really had a tough time with other ways of thinking. Those people were all just weirdos. And once I started to embrace that a team of five people plus or minus two that are very different is going to be better than a team of five experts that think just like myself. Thank you for that wonderful way of describing the importance of diversity. But as I listen to you talk, I get a little worried that maybe domain expertise isn't really needed. You're really talking about those broader skills, learning how to learn. But where does domain expertise fit into this? Christina, you want to take a shot at that? I would say that I think there is value in domain expertise. But really what it is is that from the context of engineering innovation, I believe that you have to have a good understanding of the underlying substrate that you're working with in order to apply and in order to innovate around it. I think the point that's being made, which is also I would agree with, is that the specifics, what is cutting edge now is going to be obsolete 10 years from now. You have to be able to continue to learn. Because if you just think about biology, our models of things 25 years ago or how I was taught, genetics is very different than what it would be like in a genetics class now. Just our understanding of that substrate is very different and the way that we understand it and the way that we interface with it. If you want to continue to be at the forefront of a field, you have to be able. You have to have the plasticity to continue to learn and to continue to adapt. Also, something that I think is challenging for a lot of people that was highlighted here is being able to move between disciplines and not necessarily only putting yourself into one box, but being able to move fluidly between them. Do you both agree with her? Yeah. In my mind, I think process learning and process knowledge is going to become more and more important than product. Knowledge youth could be instantiated in a database. What do we know about the world or the facts of the world? And the process learning, how do we accumulate wisdom? How do we build complex systems? How do I learn over the course of a career? How do I succeed in building a great team? That kind of iterative learning, focusing on the process variables, the correlative success, I think will be increasingly the locus of learning. Perfect. Yeah. I would say maybe ballpark 60% of the people we hire, we have some domain expertise that we need them to have. If we're building a contact lens and we need electrochemistry, work done, we're not going to hire someone who doesn't have an electrochemical background, like that doesn't make any sense. But there are lots of people who have electrochemistry as part of their toolkit that really is like table stakes even for those jobs. And there are people some of whom don't actually have electrochemistry as a major and still have that as their expertise. And all told that's maybe 60% of who we hire. There's a lot of like, Sally is amazing. Let's just get Sally, because we're crazy if we don't have Sally as part of our team. And if that's 40% of everybody, and there's some of the other 60% where you kind of didn't learn soccer from the book, you just ended up playing a lot of soccer, whatever, you know what, a play soccer at the end of the day and that's what we need, great you're hired. I think people focusing on the domains for any reason other than because you love it, is probably not going to get you what you want. So I'm going to just ask one more question to the three of you and then we're going to open it up to the audience. So I just want to put the audience on notice that in a minute I'll turn it over to you. But I had one last question. A lot of the technology Steve that you fun ASTRO that you develop, Christina the potential of technology developing your lab, there are a lot of societal implications and some of them are not always positive. How responsible do you feel for the societal implications of what you invent and invest in? And how do you think about linking technology, innovation and societal responsibility? And you want to start it off Steve? Sure. Yeah, it's a deep question. So in the short and immediate term, you can be responsible by saying, yeah, we're just certain categories and we want to invest things, there's this tasteful. But I think the deeper question is, dangerous, leap powerful technologies, which are all around us and compounding dramatically, as you know, and soon sort of the ultimate vector is heading towards technologies that will be trivial to execute as an undergrad that could kill a bunch of humanity for almost no money. In a world that's a difficult world to imagine the future. So we as humans are pretty static in terms of who we are, our culture evolves, less glacial pace, but still some glacial compared to all these technology advances. And so there can be a bit of a disconnect both in terms of capabilities to do harm, as well as all kinds of ripples through society. So I believe technology is synonymous with progress. It's kind of like, it's hard to detach progress in any sense from advancement of ideas, right? Because the technology could be something like the scientific method itself or a new form of governance. That's a form of technology, but most of what we focus on are the technologies that are accelerating dramatically. And I think it's a net positive, and almost all fronts, I think there are some really big implications, though, as it rends the fabric of society. So we already see how we live very differently today than 50 years ago, culturally, versus 2,000 years ago, it's astounding, how progress we've made. And violence keeps declining, and our future might be bright. But I do worry about things like ever accelerating which poor gap that might be an inevitable byproduct of network economies being part of most information businesses and most business becoming information centric at their core at different rates over time, where they just won't be jobs in agriculture, they won't be jobs driving cars, which is about 20% of paid employment today. That's all clearly going away in the near term, and all those new jobs come. And we'll all become information workers and entertainment workers, and that sounds great for people who don't want to do that. And it's all globally competitive, more than regionally competitive. And so none of this will happen right away, but I think an extra well trend is that we need to understand a world where that will just keep accelerating, not be self-rectifying. But for perhaps policy, but for some waves in philanthropy, which I find encouraging, but there's also a lot of self-reinforcing feedback loops on that. So that's one thing I worry about. I don't know, though, what as an individual and an individual technology area could do about it other than acknowledge the larger trend that's an emergent phenomenon and say, well, there's a big problem I could try to solve as an entrepreneur. Let me think about that future, and let's say, wow, you want to provide for basic human needs for everyone when there are no jobs. Well, how about mezzles hike and need food shelter clothing, health care and education, if mezzles alive today? And let me do an app to provide free health care forever for everyone via a smartphone, because I in the future we have to have that order will be in trouble. There could be no entrepreneurial impetus to solve the problems that are bringing our hands about it. So that's what I'm looking for as an investor to say, technology is going to do what it does. That's exogenous stuff. We're like the best-souls for ideas and a genetic bag, if you will. We're also a medic bag, and we spread ideas promiscuously, and that's just going to happen, and we can't stop it. So how about tilting our efforts to anticipating that future and helping the transition to be a little less cumbersome, as it currently seems to be? Great. Christina? So somebody who develops technologies, and thinks about what technologies we want to develop, so I think it's definitely the case that as engineers, we have a responsibility to think about the broader societal applications of the technologies we develop. This comes back to, part of it comes back to, how do we choose what to work on? I think it's also the case, and I run up against this a lot, and I think we have to acknowledge that there's dual use aspects of almost any technology. And many times in ways that we can't even imagine. I mean, did we envision or imagine that airplanes would be used to fly into buildings? And so you're not going to be able to envision or even predict all the ways that a technology might evolve, and all the ways that someone might take a technology. There are, with many technologies, you can think about short-term or immediate how it might be misused, and then you can come to some conclusion about whether you think, what is the, basically, what are the pros and what are the cons, right, right, the trade-offs, and is the overall good worth the risk? And then I think what plays into it also is you want to think about policy around it. For some potential risk, for some potential dual use, there's a lot that we can do working with regulators, working with government, think about policy that can be developed to ensure that as new technologies are introduced for mitigating what's happening in other societies and making sure that that's being minimized. And thinking again about the culture of how we train our students so that we're training, right, cadres of students and engineers that are going to go forth and innovate and apply things positively. Great, Astro, the final word on that topic. When we're working as scientists, as inventors, as entrepreneurs in any area, obviously, there's a significant responsibility, but that responsibility can't be to control the outcome of society. That's not the job of any of those people. It's not necessarily anyone's job, but if it is anyone's job, it's the job of the public sector, not the private sector. Now, that doesn't waive all responsibility from those people, but it means that their participation in the process is one of transparency and education. That means participating with the public sector by saying, here's what we're working on. Here's what we know about what it's likely to be in the future. You can help or we can help you think through what we might not know and maybe discover some of those things ahead of time. Let's talk about that. I want to make sure you, the public sector, understand as best as possible, and then that's your job, not our job, to control this thing. Because when we pursue any kind of technology from a perspective of fear and secrecy, we are crippling it. We are turning it into something less than it what it otherwise could have been. And we are seeding the real development of that thing to the very people we're most afraid of. So instead of painting these technologies as the poster children for our fears, we should be accepting that the world is changing and doing our job as educators to the public sector of the ramifications of these things, but then continuing to move these things forward without embarrassment. Great. All right, let me now turn it over and I think your hand was first up. So you get the first question. So this is an interesting idea of a generational privacy norms have developed as a result of, say, Facebook sharing photos like you were talking about before. And I wanted to ask you to what extent do you think technology drives our value system and to what extent are the technologies that you've developed and fund a product of the values you would like to foster? And I'm going to ask you to repeat, was that directed at Steve? All three, okay. So to keep it going, we'll just have one panelist answer so that we can get lots of questions. So maybe Steve, but I'm going to ask you to repeat the question because he's not mic'd and this is being taped. Okay, so working backwards, the part I heard at the end is to what extent does a value system infuse the investment process we might go through and also how does technology adjust perhaps our values over time? Is that the gist of the first part of it? Well, the second part, let me start there because it seems a bit more direct. There are absolutely, as I alluded to earlier, technologies that we think are for the good of the world. And it's not just that we feel better about our careers. It also tends to correlate with investment success that if the company invests in is doing good, a lot of good byproducts follow like other people like the company employees, like the company customers, like as opposed to tobacco company or guns or something. So we tend not to invest in guns, not as long as the things we tend not to invest in. But the most anything that you find in Vegas, for example, is a simple category. But the deeper thing is that I've been struck by how some of the most successful companies are purpose-driven companies. So Planet Labs was mentioned, Tesla, you know, in an opening statement of the Q2 report last year, setting a profit or not a priority as the opening line of the quarterly report. And the point was there's a higher mission, I hope, actually an era of the electric mobility. And as the primary goal, there's a sub goal, which is, you know, we're not gonna lead the world to a new era for ourselves profitable and attractive business. So there are, and there are many others like this Google, arguably, as a company like this Facebook, arguably connecting the entire world is the mission and, oh yeah, begrudgingly some revenue and profits might have to come along and so it realizes it's important to, you know, carrying on. So my point is sort of, sort of, the relicanting, or recasting of that is that finding a passion entrepreneur that wants to change the world for the better and that's a value judgment is exactly what we should be doing. And that's also what I try to do in my career is not just try to maximize revenue or investment potential in anyone, but what is gonna push the ball forward over a longer arc of time, which seems to make a more resilient strategy. I think our cultural norms and more are due shift over time. I think our circle of empathy continues to expand and you can look at entrepreneurship itself as a bell weather of that, which is people used to think 20 years ago about US companies and the US serving US companies for US benefits. Now it's clearly global. In the case of Elon Musk, even interplanetary. Let's help out those future Martians. I mean, literally, that scope of ambition is amazing. And I think in a long, a few in history, like the family unit, the tribe, the city state, the globe, all sentient beings, that seems to be how our scope of empathy expands. And I think it's largely by awareness, communication technologies that enable this awareness. And frankly, the cultural evolution that co-volves with our technological evolution. So again, 2000 years ago, rich, genocide, and slavery, we're all fine according to mainstream opinion. Pretty weird. In certain cases, warfare when you need to smoke somebody. That's when smoting is on their menu, then those things are fine. So again, I'm glad about it, but 2000 years ago, humans were the same. Genetically, we're no different, right? I mean, except for some teeth and little smings, and nothing to do with our actual brains, it's cultural evolution. And I think it's largely infused by the inventions of democracy, the scientific method. How do we accumulate ideas over time and discard ones that are bad? That's a form of technology. So maybe the scientific method more than anything else has accelerated the pace of learning progress and betterment. Okay, next question. Young lady in the front row. So, process education is becoming more and more important than maybe domain knowledge for most people. But a lot of students, when they're graduating, don't really know where to find that. So maybe they end up in a job like, until they are banking or somewhere where they pitch a lot of need. But maybe you don't get as much of that as you think. If you were graduating school now or advising someone who were, where would you recommend going to get that process education? Absolutely. But one, repeat the question, please. I will. I mean, the question is, if we're not supposed to learn a skill like computer science, we're supposed to learn these soft, more transportable skills that we've been mentioning up here. But that's exactly what you're taught. And we doesn't say that on your resume, the day that you graduate, where are you supposed to go, both to build those skills or maybe to pick them up in the first place, that's your question. The advice I give to people independent of age is find somewhere that you can be passionate about. Surround yourself with people who are at least as wonderful as you are, who are smarter than you and who you're confident you can learn from. More than anything else, find a manager who can be your mentor. I don't care if they're making smelly soaps or trying to go to Mars or something in between. If you maximize for those things where you're around amazing human beings, trying to work really hard to do something good for the rest of humanity, it's all gonna work out. You can't not learn around those people. You will inevitably learn the skills that you need. And if you're in a place where the mission and the types of people you're around are draining your soul, how are you gonna end up learning process points like how to work in a group? You're gonna try to avoid the people you're around. So I think that the things that we wish were true happen to line up with what's in your best interest in this case, which is to really be around great people. Next question. It's doable clearly. Just, I mean, I was for example. Okay, yeah. Mr. Tyler, what you said about the responsibility for the private sector in terms of the implicated the societal implications of your actions? The first thing all three of you said was what you need to do is you need to figure out how to change society. It's what technology fundamentally does. So if that is your goal to change society, aren't you a little responsible for how society changes as a result of what you do? Doesn't that put more of a pressure on you to see the impacts and deal with them as they come up? I think so. So the question is, if it's our goal to change society or the world in some way, however well-intentioned our goal to change the world is, then doesn't that add some incremental responsibility to us in how the world ends up changing as a result of what we build? I think that's a totally fair question. I make two points. First of all, well, I certainly wouldn't use that to dodge the responsibility. If someone is making a technology, has no idea what it's gonna do in the world and it's just gonna throw it out there without it, even a goal to make the world better in some particular way, I can't see how that's better from a moral perspective than actually seeking to make the world a better place. So if you pick something like, let's say, cars that can drive themselves, you need to work out early on, whether you believe in your heart collectively that that's actually gonna make the world a better place. Now, no technology as she was pointing out is an absolute positive. All technologies are net positives, or at least have the potential to be net positives, but none of them are absolute positive. So you have to go through the math and say, is this a reasonable thing to do? By the way, we probably throw out 30% of our ideas purely on the basis that it's a zero sum game, that we could make money, that it's not even necessarily bad for the world, but that it's not strictly adding value to the world, it's just shifting the value from someone else to us. And even that leaves us cold, and we say, nope, not gonna do that one. So we go through that process, but for example, if just to use self-driving cars, there are going to be people who have new jobs because cars can drive themselves. Surely there are going to be some people who don't have jobs anymore because cars can drive themselves. I'm compassionate about that, but a, I'm not sure that that justifies 1.2 million people a year, dying in car accidents, that we would just maintain the status quo of those jobs. Because the fundamental problem, I believe, is that we are failing the young people of our societies around the world. We are not doing a good job of training them. And let's say in the limit, we were doing an abysmal job, and it might not be much better than that, frankly, of training the young people of the world to be really ready for the future. What should we do? Stop all-forward progress, not cure any more diseases, allow cars to be as inefficient as they still are, just to make up for the public sector, not being able to educate people, that seems like the wrong solution to the problem. So I accept some responsibility, but I think the public sector and society at large has to meet technology's development halfway and take some responsibility, which it frankly does not do a great job of doing, but throws it back at the doorstep of the changes that technology causes, even when those technologies are aimed in this particular way. I think an incredibly well-intentioned way. Maybe one last question over there? Right, what you'll say, maybe you'll have digital immortality in the latest 30 years, so it's a little bit more life. And my question is, is that the end of the situation is you know it? Because we can just copy paste. So can we try to repeat that a little bit more slowly, and it's going towards Christina? Oh, OK. It's a very, very crucial say that we will have a digital immortality in the late. Digital immortality. Digital immortality, very, very good one. Yeah, so at the latest 30 years or no, even 50 years. And my question is, is that the end of education as we know it? Because in 15 years, we can just copy paste the skills that we get from the university first. Is it the end of education we know, if we can upload our conscience to computer? And why do we need to stop learning then? Yeah. Why? No way. Why would that follow? Well, you've got to paste ignorance. I mean, how do you... I think you make that progress. Learning. Thank you. I think we can... Yeah, because for example, still, to buy... To buy... To buy... Or to drive or something like that. It's actually... We can... We can see... No, we can see from the brain how we can do it. You can... You can do all everything online. You can just download. You don't need to go to school. You just read it off the computer. So it's basically why won't online education take over everything? No. No, it's just... You're saying, no, just download it in your brain like the matrix. Oh, I know. So... You got that one, fidgeting. I know it's a jitsuit. Yes, right. Like, reality check. Just because Ray Kurzweil believes in transhumanism does not believe that anybody else believes in that. Right. Like, I'm just... You're not wasting your time going to school and I would be willing to bet your grandkids are not going to be wasting their time going to school. Can I actually... I think it's actually an important reason why that intuition follows. When you grow a brain, a real brain, or you create an equivalently complex neural network or deep learning algorithm, the actual inner workings of it are completely inscrutable. It's only really understandable as interfaces having to do with the way in which those algorithms work. Same is true for evolution and the path of how we get to where we are. So you can't... Even though Jeff Hawking's at the end of his book on intelligence just off... I don't know where it says, we'll cut and paste like French language skills or, you know, between these evolved artifacts. I don't think that's possible at all because we have no example around us in information networks, rich, complex information networks where the evolved product of biological evolution, deep learning, machine learning, any of these is cut and paste the ball. What is much more efficient is just growing on from scratch. And so you'll be learning more than ever before, just more rapidly. Okay. We are at the end of our time. I want to thank people for coming and I especially want to thank our speakers for their very interesting insights. APPLAUSE You have been listening to the Draper Fisher-Jurvis in entrepreneurial thought-leader series, brought to you weekly by the Stanford Technology Ventures Program. You can find additional podcasts and videos of these lectures online at e-corner.stanford.edu.